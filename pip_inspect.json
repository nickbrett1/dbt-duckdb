{
  "version": "1",
  "pip_version": "25.3",
  "installed": [
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "greenlet",
        "version": "3.2.4",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "keywords",
          "license",
          "license-file",
          "maintainer",
          "maintainer-email",
          "platform",
          "project-url",
          "provides-extra",
          "requires-python",
          "summary"
        ],
        "platform": [
          "any"
        ],
        "summary": "Lightweight in-process concurrent programming",
        "description": ".. This file is included into docs/history.rst\n\n\nGreenlets are lightweight coroutines for in-process concurrent\nprogramming.\n\nThe \"greenlet\" package is a spin-off of `Stackless`_, a version of\nCPython that supports micro-threads called \"tasklets\". Tasklets run\npseudo-concurrently (typically in a single or a few OS-level threads)\nand are synchronized with data exchanges on \"channels\".\n\nA \"greenlet\", on the other hand, is a still more primitive notion of\nmicro-thread with no implicit scheduling; coroutines, in other words.\nThis is useful when you want to control exactly when your code runs.\nYou can build custom scheduled micro-threads on top of greenlet;\nhowever, it seems that greenlets are useful on their own as a way to\nmake advanced control flow structures. For example, we can recreate\ngenerators; the difference with Python's own generators is that our\ngenerators can call nested functions and the nested functions can\nyield values too. (Additionally, you don't need a \"yield\" keyword. See\nthe example in `test_generator.py\n<https://github.com/python-greenlet/greenlet/blob/adca19bf1f287b3395896a8f41f3f4fd1797fdc7/src/greenlet/tests/test_generator.py#L1>`_).\n\nGreenlets are provided as a C extension module for the regular unmodified\ninterpreter.\n\n.. _`Stackless`: http://www.stackless.com\n\n\nWho is using Greenlet?\n======================\n\nThere are several libraries that use Greenlet as a more flexible\nalternative to Python's built in coroutine support:\n\n - `Concurrence`_\n - `Eventlet`_\n - `Gevent`_\n\n.. _Concurrence: http://opensource.hyves.org/concurrence/\n.. _Eventlet: http://eventlet.net/\n.. _Gevent: http://www.gevent.org/\n\nGetting Greenlet\n================\n\nThe easiest way to get Greenlet is to install it with pip::\n\n  pip install greenlet\n\n\nSource code archives and binary distributions are available on the\npython package index at https://pypi.org/project/greenlet\n\nThe source code repository is hosted on github:\nhttps://github.com/python-greenlet/greenlet\n\nDocumentation is available on readthedocs.org:\nhttps://greenlet.readthedocs.io\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "greenlet",
          "coroutine",
          "concurrency",
          "threads",
          "cooperative"
        ],
        "home_page": "https://greenlet.readthedocs.io/",
        "author": "Alexey Borzenkov",
        "author_email": "snaury@gmail.com",
        "maintainer": "Jason Madden",
        "maintainer_email": "jason@seecoresoftware.com",
        "license": "MIT AND Python-2.0",
        "license_file": [
          "LICENSE",
          "LICENSE.PSF"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "Programming Language :: C",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Operating System :: OS Independent",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "Sphinx; extra == \"docs\"",
          "furo; extra == \"docs\"",
          "objgraph; extra == \"test\"",
          "psutil; extra == \"test\"",
          "setuptools; extra == \"test\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Bug Tracker, https://github.com/python-greenlet/greenlet/issues",
          "Source Code, https://github.com/python-greenlet/greenlet/",
          "Documentation, https://greenlet.readthedocs.io/",
          "Changes, https://greenlet.readthedocs.io/en/latest/changes.html"
        ],
        "provides_extra": [
          "docs",
          "test"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/greenlet-3.2.4.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "pip",
        "version": "25.3",
        "summary": "The PyPA recommended tool for installing Python packages.",
        "description": "pip - The Python Package Installer\n==================================\n\n.. |pypi-version| image:: https://img.shields.io/pypi/v/pip.svg\n   :target: https://pypi.org/project/pip/\n   :alt: PyPI\n\n.. |python-versions| image:: https://img.shields.io/pypi/pyversions/pip\n   :target: https://pypi.org/project/pip\n   :alt: PyPI - Python Version\n\n.. |docs-badge| image:: https://readthedocs.org/projects/pip/badge/?version=latest\n   :target: https://pip.pypa.io/en/latest\n   :alt: Documentation\n\n|pypi-version| |python-versions| |docs-badge|\n\npip is the `package installer`_ for Python. You can use pip to install packages from the `Python Package Index`_ and other indexes.\n\nPlease take a look at our documentation for how to install and use pip:\n\n* `Installation`_\n* `Usage`_\n\nWe release updates regularly, with a new version every 3 months. Find more details in our documentation:\n\n* `Release notes`_\n* `Release process`_\n\nIf you find bugs, need help, or want to talk to the developers, please use our mailing lists or chat rooms:\n\n* `Issue tracking`_\n* `Discourse channel`_\n* `User IRC`_\n\nIf you want to get involved head over to GitHub to get the source code, look at our development documentation and feel free to jump on the developer mailing lists and chat rooms:\n\n* `GitHub page`_\n* `Development documentation`_\n* `Development IRC`_\n\nCode of Conduct\n---------------\n\nEveryone interacting in the pip project's codebases, issue trackers, chat\nrooms, and mailing lists is expected to follow the `PSF Code of Conduct`_.\n\n.. _package installer: https://packaging.python.org/guides/tool-recommendations/\n.. _Python Package Index: https://pypi.org\n.. _Installation: https://pip.pypa.io/en/stable/installation/\n.. _Usage: https://pip.pypa.io/en/stable/\n.. _Release notes: https://pip.pypa.io/en/stable/news.html\n.. _Release process: https://pip.pypa.io/en/latest/development/release-process/\n.. _GitHub page: https://github.com/pypa/pip\n.. _Development documentation: https://pip.pypa.io/en/latest/development\n.. _Issue tracking: https://github.com/pypa/pip/issues\n.. _Discourse channel: https://discuss.python.org/c/packaging\n.. _User IRC: https://kiwiirc.com/nextclient/#ircs://irc.libera.chat:+6697/pypa\n.. _Development IRC: https://kiwiirc.com/nextclient/#ircs://irc.libera.chat:+6697/pypa-dev\n.. _PSF Code of Conduct: https://github.com/pypa/.github/blob/main/CODE_OF_CONDUCT.md\n\n",
        "description_content_type": "text/x-rst",
        "author_email": "The pip developers <distutils-sig@python.org>",
        "license_expression": "MIT",
        "license_file": [
          "AUTHORS.txt",
          "LICENSE.txt",
          "src/pip/_vendor/cachecontrol/LICENSE.txt",
          "src/pip/_vendor/certifi/LICENSE",
          "src/pip/_vendor/dependency_groups/LICENSE.txt",
          "src/pip/_vendor/distlib/LICENSE.txt",
          "src/pip/_vendor/distro/LICENSE",
          "src/pip/_vendor/idna/LICENSE.md",
          "src/pip/_vendor/msgpack/COPYING",
          "src/pip/_vendor/packaging/LICENSE",
          "src/pip/_vendor/packaging/LICENSE.APACHE",
          "src/pip/_vendor/packaging/LICENSE.BSD",
          "src/pip/_vendor/pkg_resources/LICENSE",
          "src/pip/_vendor/platformdirs/LICENSE",
          "src/pip/_vendor/pygments/LICENSE",
          "src/pip/_vendor/pyproject_hooks/LICENSE",
          "src/pip/_vendor/requests/LICENSE",
          "src/pip/_vendor/resolvelib/LICENSE",
          "src/pip/_vendor/rich/LICENSE",
          "src/pip/_vendor/tomli/LICENSE",
          "src/pip/_vendor/tomli_w/LICENSE",
          "src/pip/_vendor/truststore/LICENSE",
          "src/pip/_vendor/urllib3/LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Topic :: Software Development :: Build Tools",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Changelog, https://pip.pypa.io/en/stable/news/",
          "Documentation, https://pip.pypa.io",
          "Homepage, https://pip.pypa.io/",
          "Source, https://github.com/pypa/pip"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/pip-25.3.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "playwright",
        "version": "1.55.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "A high-level API to automate web browsers",
        "description": "# ðŸŽ­ [Playwright](https://playwright.dev) for Python [![PyPI version](https://badge.fury.io/py/playwright.svg)](https://pypi.python.org/pypi/playwright/) [![Anaconda version](https://img.shields.io/conda/v/microsoft/playwright)](https://anaconda.org/Microsoft/playwright) [![Join Discord](https://img.shields.io/badge/join-discord-infomational)](https://aka.ms/playwright/discord)\n\nPlaywright is a Python library to automate [Chromium](https://www.chromium.org/Home), [Firefox](https://www.mozilla.org/en-US/firefox/new/) and [WebKit](https://webkit.org/) browsers with a single API. Playwright delivers automation that is **ever-green**, **capable**, **reliable** and **fast**. [See how Playwright is better](https://playwright.dev/python).\n\n|          | Linux | macOS | Windows |\n|   :---   | :---: | :---: | :---:   |\n| Chromium <!-- GEN:chromium-version -->140.0.7339.16<!-- GEN:stop --> | âœ… | âœ… | âœ… |\n| WebKit <!-- GEN:webkit-version -->26.0<!-- GEN:stop --> | âœ… | âœ… | âœ… |\n| Firefox <!-- GEN:firefox-version -->141.0<!-- GEN:stop --> | âœ… | âœ… | âœ… |\n\n## Documentation\n\n[https://playwright.dev/python/docs/intro](https://playwright.dev/python/docs/intro)\n\n## API Reference\n\n[https://playwright.dev/python/docs/api/class-playwright](https://playwright.dev/python/docs/api/class-playwright)\n\n## Example\n\n```py\nfrom playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    for browser_type in [p.chromium, p.firefox, p.webkit]:\n        browser = browser_type.launch()\n        page = browser.new_page()\n        page.goto('http://playwright.dev')\n        page.screenshot(path=f'example-{browser_type.name}.png')\n        browser.close()\n```\n\n```py\nimport asyncio\nfrom playwright.async_api import async_playwright\n\nasync def main():\n    async with async_playwright() as p:\n        for browser_type in [p.chromium, p.firefox, p.webkit]:\n            browser = await browser_type.launch()\n            page = await browser.new_page()\n            await page.goto('http://playwright.dev')\n            await page.screenshot(path=f'example-{browser_type.name}.png')\n            await browser.close()\n\nasyncio.run(main())\n```\n\n## Other languages\n\nMore comfortable in another programming language? [Playwright](https://playwright.dev) is also available in\n- [Node.js (JavaScript / TypeScript)](https://playwright.dev/docs/intro),\n- [.NET](https://playwright.dev/dotnet/docs/intro),\n- [Java](https://playwright.dev/java/docs/intro).\n",
        "description_content_type": "text/markdown",
        "author": "Microsoft Corporation",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Topic :: Software Development :: Testing",
          "Topic :: Internet :: WWW/HTTP :: Browsers",
          "Intended Audience :: Developers",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Operating System :: OS Independent"
        ],
        "requires_dist": [
          "pyee<14,>=13",
          "greenlet<4.0.0,>=3.1.1"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "homepage, https://github.com/Microsoft/playwright-python",
          "Release notes, https://github.com/microsoft/playwright-python/releases"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/playwright-1.55.0.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.2",
        "name": "pyee",
        "version": "13.0.0",
        "summary": "A rough port of Node.js's EventEmitter to Python with a few tricks of its own",
        "description": "# pyee\n\n[![Documentation Status](https://readthedocs.org/projects/pyee/badge/?version=latest)](https://pyee.readthedocs.io/en/latest/?badge=latest)\n\npyee supplies a `EventEmitter` object that is similar to the\n`EventEmitter` class from Node.js. It also supplies a number of subclasses\nwith added support for async and threaded programming in python, such as\nasync/await.\n\n## Docs\n\nAutogenerated API docs, including basic installation directions and examples,\ncan be found at <https://pyee.readthedocs.io>.\n\n## Development\n\nSee [DEVELOPMENT.md](./DEVELOPMENT.md).\n\n## Changelog\n\nSee [CHANGELOG.md](./CHANGELOG.md).\n\n## Contributors\n\nSee [CONTRIBUTORS.md](./CONTRIBUTORS.md).\n\n## License\n\nMIT/X11, see [LICENSE](./LICENSE).\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "events",
          "emitter",
          "node.js",
          "node",
          "eventemitter",
          "event_emitter"
        ],
        "author_email": "Josh Holbrook <josh.holbrook@gmail.com>",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Programming Language :: Python",
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Other/Nonlisted Topic"
        ],
        "requires_dist": [
          "typing-extensions",
          "build; extra == \"dev\"",
          "flake8; extra == \"dev\"",
          "flake8-black; extra == \"dev\"",
          "pytest; extra == \"dev\"",
          "pytest-asyncio; python_version >= \"3.4\" and extra == \"dev\"",
          "pytest-trio; python_version >= \"3.7\" and extra == \"dev\"",
          "black; extra == \"dev\"",
          "isort; extra == \"dev\"",
          "jupyter-console; extra == \"dev\"",
          "mkdocs; extra == \"dev\"",
          "mkdocs-include-markdown-plugin; extra == \"dev\"",
          "mkdocstrings[python]; extra == \"dev\"",
          "mypy; extra == \"dev\"",
          "sphinx; extra == \"dev\"",
          "toml; extra == \"dev\"",
          "tox; extra == \"dev\"",
          "trio; extra == \"dev\"",
          "trio; python_version > \"3.6\" and extra == \"dev\"",
          "trio-typing; python_version > \"3.6\" and extra == \"dev\"",
          "twine; extra == \"dev\"",
          "twisted; extra == \"dev\"",
          "validate-pyproject[all]; extra == \"dev\""
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Repository, https://github.com/jfhbrook/pyee",
          "Documentation, https://pyee.readthedocs.io"
        ],
        "provides_extra": [
          "dev"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/pyee-13.0.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "typing_extensions",
        "version": "4.15.0",
        "summary": "Backported and Experimental Type Hints for Python 3.9+",
        "description": "# Typing Extensions\n\n[![Chat at https://gitter.im/python/typing](https://badges.gitter.im/python/typing.svg)](https://gitter.im/python/typing)\n\n[Documentation](https://typing-extensions.readthedocs.io/en/latest/#) â€“\n[PyPI](https://pypi.org/project/typing-extensions/)\n\n## Overview\n\nThe `typing_extensions` module serves two related purposes:\n\n- Enable use of new type system features on older Python versions. For example,\n  `typing.TypeGuard` is new in Python 3.10, but `typing_extensions` allows\n  users on previous Python versions to use it too.\n- Enable experimentation with new type system PEPs before they are accepted and\n  added to the `typing` module.\n\n`typing_extensions` is treated specially by static type checkers such as\nmypy and pyright. Objects defined in `typing_extensions` are treated the same\nway as equivalent forms in `typing`.\n\n`typing_extensions` uses\n[Semantic Versioning](https://semver.org/). The\nmajor version will be incremented only for backwards-incompatible changes.\nTherefore, it's safe to depend\non `typing_extensions` like this: `typing_extensions ~=x.y`,\nwhere `x.y` is the first version that includes all features you need.\n[This](https://packaging.python.org/en/latest/specifications/version-specifiers/#compatible-release)\nis equivalent to `typing_extensions >=x.y, <(x+1)`. Do not depend on `~= x.y.z`\nunless you really know what you're doing; that defeats the purpose of\nsemantic versioning.\n\n## Included items\n\nSee [the documentation](https://typing-extensions.readthedocs.io/en/latest/#) for a\ncomplete listing of module contents.\n\n## Contributing\n\nSee [CONTRIBUTING.md](https://github.com/python/typing_extensions/blob/main/CONTRIBUTING.md)\nfor how to contribute to `typing_extensions`.\n\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "annotations",
          "backport",
          "checker",
          "checking",
          "function",
          "hinting",
          "hints",
          "type",
          "typechecking",
          "typehinting",
          "typehints",
          "typing"
        ],
        "author_email": "\"Guido van Rossum, Jukka Lehtosalo, Åukasz Langa, Michael Lee\" <levkivskyi@gmail.com>",
        "license_expression": "PSF-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Software Development"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Bug Tracker, https://github.com/python/typing_extensions/issues",
          "Changes, https://github.com/python/typing_extensions/blob/main/CHANGELOG.md",
          "Documentation, https://typing-extensions.readthedocs.io/",
          "Home, https://github.com/python/typing_extensions",
          "Q & A, https://github.com/python/typing/discussions",
          "Repository, https://github.com/python/typing_extensions"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/typing_extensions-4.15.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "Jinja2",
        "version": "3.1.6",
        "summary": "A very fast and expressive template engine.",
        "description": "# Jinja\n\nJinja is a fast, expressive, extensible templating engine. Special\nplaceholders in the template allow writing code similar to Python\nsyntax. Then the template is passed data to render the final document.\n\nIt includes:\n\n-   Template inheritance and inclusion.\n-   Define and import macros within templates.\n-   HTML templates can use autoescaping to prevent XSS from untrusted\n    user input.\n-   A sandboxed environment can safely render untrusted templates.\n-   AsyncIO support for generating templates and calling async\n    functions.\n-   I18N support with Babel.\n-   Templates are compiled to optimized Python code just-in-time and\n    cached, or can be compiled ahead-of-time.\n-   Exceptions point to the correct line in templates to make debugging\n    easier.\n-   Extensible filters, tests, functions, and even syntax.\n\nJinja's philosophy is that while application logic belongs in Python if\npossible, it shouldn't make the template designer's job difficult by\nrestricting functionality too much.\n\n\n## In A Nutshell\n\n```jinja\n{% extends \"base.html\" %}\n{% block title %}Members{% endblock %}\n{% block content %}\n  <ul>\n  {% for user in users %}\n    <li><a href=\"{{ user.url }}\">{{ user.username }}</a></li>\n  {% endfor %}\n  </ul>\n{% endblock %}\n```\n\n## Donate\n\nThe Pallets organization develops and supports Jinja and other popular\npackages. In order to grow the community of contributors and users, and\nallow the maintainers to devote more time to the projects, [please\ndonate today][].\n\n[please donate today]: https://palletsprojects.com/donate\n\n## Contributing\n\nSee our [detailed contributing documentation][contrib] for many ways to\ncontribute, including reporting issues, requesting features, asking or answering\nquestions, and making PRs.\n\n[contrib]: https://palletsprojects.com/contributing/\n\n",
        "description_content_type": "text/markdown",
        "maintainer_email": "Pallets <contact@palletsprojects.com>",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Topic :: Internet :: WWW/HTTP :: Dynamic Content",
          "Topic :: Text Processing :: Markup :: HTML",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "MarkupSafe>=2.0",
          "Babel>=2.7 ; extra == \"i18n\""
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Changes, https://jinja.palletsprojects.com/changes/",
          "Chat, https://discord.gg/pallets",
          "Documentation, https://jinja.palletsprojects.com/",
          "Donate, https://palletsprojects.com/donate",
          "Source, https://github.com/pallets/jinja/"
        ],
        "provides_extra": [
          "i18n"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/jinja2-3.1.6.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "importlib_metadata",
        "version": "8.7.1",
        "dynamic": [
          "license-file"
        ],
        "summary": "Read metadata from Python packages",
        "description": ".. image:: https://img.shields.io/pypi/v/importlib_metadata.svg\n   :target: https://pypi.org/project/importlib_metadata\n\n.. image:: https://img.shields.io/pypi/pyversions/importlib_metadata.svg\n\n.. image:: https://github.com/python/importlib_metadata/actions/workflows/main.yml/badge.svg\n   :target: https://github.com/python/importlib_metadata/actions?query=workflow%3A%22tests%22\n   :alt: tests\n\n.. image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json\n    :target: https://github.com/astral-sh/ruff\n    :alt: Ruff\n\n.. image:: https://readthedocs.org/projects/importlib-metadata/badge/?version=latest\n   :target: https://importlib-metadata.readthedocs.io/en/latest/?badge=latest\n\n.. image:: https://img.shields.io/badge/skeleton-2025-informational\n   :target: https://blog.jaraco.com/skeleton\n\n.. image:: https://tidelift.com/badges/package/pypi/importlib-metadata\n   :target: https://tidelift.com/subscription/pkg/pypi-importlib-metadata?utm_source=pypi-importlib-metadata&utm_medium=readme\n\nLibrary to access the metadata for a Python package.\n\nThis package supplies third-party access to the functionality of\n`importlib.metadata <https://docs.python.org/3/library/importlib.metadata.html>`_\nincluding improvements added to subsequent Python versions.\n\n\nCompatibility\n=============\n\nNew features are introduced in this third-party library and later merged\ninto CPython. The following table indicates which versions of this library\nwere contributed to different versions in the standard library:\n\n.. list-table::\n   :header-rows: 1\n\n   * - importlib_metadata\n     - stdlib\n   * - 7.0\n     - 3.13\n   * - 6.5\n     - 3.12\n   * - 4.13\n     - 3.11\n   * - 4.6\n     - 3.10\n   * - 1.4\n     - 3.8\n\n\nUsage\n=====\n\nSee the `online documentation <https://importlib-metadata.readthedocs.io/>`_\nfor usage details.\n\n`Finder authors\n<https://docs.python.org/3/reference/import.html#finders-and-loaders>`_ can\nalso add support for custom package installers.  See the above documentation\nfor details.\n\n\nCaveats\n=======\n\nThis project primarily supports third-party packages installed by PyPA\ntools (or other conforming packages). It does not support:\n\n- Packages in the stdlib.\n- Packages installed without metadata.\n\nProject details\n===============\n\n * Project home: https://github.com/python/importlib_metadata\n * Report bugs at: https://github.com/python/importlib_metadata/issues\n * Code hosting: https://github.com/python/importlib_metadata\n * Documentation: https://importlib-metadata.readthedocs.io/\n\nFor Enterprise\n==============\n\nAvailable as part of the Tidelift Subscription.\n\nThis project and the maintainers of thousands of other packages are working with Tidelift to deliver one enterprise subscription that covers all of the open source you use.\n\n`Learn more <https://tidelift.com/subscription/pkg/pypi-importlib-metadata?utm_source=pypi-importlib-metadata&utm_medium=referral&utm_campaign=github>`_.\n",
        "description_content_type": "text/x-rst",
        "author_email": "\"Jason R. Coombs\" <jaraco@jaraco.com>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only"
        ],
        "requires_dist": [
          "zipp>=3.20",
          "pytest!=8.1.*,>=6; extra == \"test\"",
          "packaging; extra == \"test\"",
          "pyfakefs; extra == \"test\"",
          "flufl.flake8; extra == \"test\"",
          "pytest-perf>=0.9.2; extra == \"test\"",
          "jaraco.test>=5.4; extra == \"test\"",
          "sphinx>=3.5; extra == \"doc\"",
          "jaraco.packaging>=9.3; extra == \"doc\"",
          "rst.linker>=1.9; extra == \"doc\"",
          "furo; extra == \"doc\"",
          "sphinx-lint; extra == \"doc\"",
          "jaraco.tidelift>=1.4; extra == \"doc\"",
          "ipython; extra == \"perf\"",
          "pytest-checkdocs>=2.4; extra == \"check\"",
          "pytest-ruff>=0.2.1; sys_platform != \"cygwin\" and extra == \"check\"",
          "pytest-cov; extra == \"cover\"",
          "pytest-enabler>=3.4; extra == \"enabler\"",
          "pytest-mypy>=1.0.1; extra == \"type\"",
          "mypy<1.19; platform_python_implementation == \"PyPy\" and extra == \"type\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Source, https://github.com/python/importlib_metadata"
        ],
        "provides_extra": [
          "test",
          "doc",
          "perf",
          "check",
          "cover",
          "enabler",
          "type"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/importlib_metadata-8.7.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.0",
        "name": "pytimeparse",
        "version": "1.1.8",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "Time expression parser",
        "description": "=====================================\n pytimeparse: time expression parser\n=====================================\n\n.. image:: https://travis-ci.org/wroberts/pytimeparse.svg?branch=master\n    :target: https://travis-ci.org/wroberts/pytimeparse\n    :alt: Travis CI build status\n\n.. image:: https://coveralls.io/repos/wroberts/pytimeparse/badge.svg\n    :target: https://coveralls.io/r/wroberts/pytimeparse\n    :alt: Test code coverage\n\n.. image:: https://img.shields.io/pypi/v/pytimeparse.svg\n    :target: https://pypi.python.org/pypi/pytimeparse/\n    :alt: Latest Version\n\nCopyright (c) 2014 Will Roberts <wildwilhelm@gmail.com>\n\nLicensed under the MIT License (see source file ``timeparse.py`` for\ndetails).\n\nA small Python library to parse various kinds of time expressions,\ninspired by\n`this StackOverflow question <http://stackoverflow.com/questions/4628122/how-to-construct-a-timedelta-object-from-a-simple-string>`_.\n\nThe single function ``pytimeparse.timeparse.timeparse`` defined in the\nlibrary (also available as ``pytimeparse.parse``) parses time\nexpressions like the following:\n\n- ``32m``\n- ``2h32m``\n- ``3d2h32m``\n- ``1w3d2h32m``\n- ``1w 3d 2h 32m``\n- ``1 w 3 d 2 h 32 m``\n- ``4:13``\n- ``4:13:02``\n- ``4:13:02.266``\n- ``2:04:13:02.266``\n- ``2 days,  4:13:02`` (``uptime`` format)\n- ``2 days,  4:13:02.266``\n- ``5hr34m56s``\n- ``5 hours, 34 minutes, 56 seconds``\n- ``5 hrs, 34 mins, 56 secs``\n- ``2 days, 5 hours, 34 minutes, 56 seconds``\n- ``1.2 m``\n- ``1.2 min``\n- ``1.2 mins``\n- ``1.2 minute``\n- ``1.2 minutes``\n- ``172 hours``\n- ``172 hr``\n- ``172 h``\n- ``172 hrs``\n- ``172 hour``\n- ``1.24 days``\n- ``5 d``\n- ``5 day``\n- ``5 days``\n- ``5.6 wk``\n- ``5.6 week``\n- ``5.6 weeks``\n\nIt returns the time as a number of seconds (an integer value if\npossible, otherwise a floating-point number)::\n\n    >>> from pytimeparse import parse\n    >>> parse('1.2 minutes')\n    72\n\nA number of seconds can be converted back into a string using the\n``datetime`` module in the standard library, as noted in\n`this other StackOverflow question <http://stackoverflow.com/questions/538666/python-format-timedelta-to-string>`_::\n\n    >>> from pytimeparse import parse\n    >>> import datetime\n    >>> parse('1 day, 14:20:16')\n    138016\n    >>> str(datetime.timedelta(seconds=138016))\n    '1 day, 14:20:16'\n\nFuture work\n-----------\n\n1. Give the user more flexibility over which characters to use as\n   separators between fields in a time expression (e.g., ``+`` might\n   be useful).\n2. Internationalisation?\n3. Wow, https://github.com/bear/parsedatetime .\n\n\n",
        "keywords": [
          "time",
          "parsing",
          "parser"
        ],
        "home_page": "https://github.com/wroberts/pytimeparse",
        "author": "Will Roberts",
        "author_email": "wildwilhelm@gmail.com",
        "license": "License :: OSI Approved :: MIT License",
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "Topic :: Text Processing",
          "Natural Language :: English",
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.2",
          "Programming Language :: Python :: 3.3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/pytimeparse-1.1.8.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "jsonschema-specifications",
        "version": "2025.9.1",
        "summary": "The JSON Schema meta-schemas and vocabularies, exposed as a Registry",
        "description": "=============================\n``jsonschema-specifications``\n=============================\n\n|PyPI| |Pythons| |CI| |ReadTheDocs|\n\nJSON support files from the `JSON Schema Specifications <https://json-schema.org/specification.html>`_ (metaschemas, vocabularies, etc.), packaged for runtime access from Python as a `referencing-based Schema Registry <https://referencing.readthedocs.io/en/stable/api/#referencing.Registry>`_.\n\n.. |PyPI| image:: https://img.shields.io/pypi/v/jsonschema-specifications.svg\n  :alt: PyPI version\n  :target: https://pypi.org/project/jsonschema-specifications/\n\n.. |Pythons| image:: https://img.shields.io/pypi/pyversions/jsonschema-specifications.svg\n  :alt: Supported Python versions\n  :target: https://pypi.org/project/jsonschema-specifications/\n\n.. |CI| image:: https://github.com/python-jsonschema/jsonschema-specifications/workflows/CI/badge.svg\n  :alt: Build status\n  :target: https://github.com/python-jsonschema/jsonschema-specifications/actions?query=workflow%3ACI\n\n.. |ReadTheDocs| image:: https://readthedocs.org/projects/jsonschema-specifications/badge/?version=stable&style=flat\n  :alt: ReadTheDocs status\n  :target: https://jsonschema-specifications.readthedocs.io/en/stable/\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "data validation",
          "json",
          "json schema",
          "jsonschema",
          "validation"
        ],
        "author_email": "Julian Berman <Julian+jsonschema-specifications@GrayVines.com>",
        "license_expression": "MIT",
        "license_file": [
          "COPYING"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: File Formats :: JSON",
          "Topic :: File Formats :: JSON :: JSON Schema"
        ],
        "requires_dist": [
          "referencing>=0.31.0"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Documentation, https://jsonschema-specifications.readthedocs.io/",
          "Homepage, https://github.com/python-jsonschema/jsonschema-specifications",
          "Issues, https://github.com/python-jsonschema/jsonschema-specifications/issues/",
          "Funding, https://github.com/sponsors/Julian",
          "Tidelift, https://tidelift.com/subscription/pkg/pypi-jsonschema-specifications?utm_source=pypi-jsonschema-specifications&utm_medium=referral&utm_campaign=pypi-link",
          "Source, https://github.com/python-jsonschema/jsonschema-specifications"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/jsonschema_specifications-2025.9.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "deepdiff",
        "version": "8.6.1",
        "summary": "Deep Difference and Search of any Python object/data. Recreate objects by adding adding deltas to each other.",
        "description": "# DeepDiff v 8.6.1\n\n![Downloads](https://img.shields.io/pypi/dm/deepdiff.svg?style=flat)\n![Python Versions](https://img.shields.io/pypi/pyversions/deepdiff.svg?style=flat)\n![License](https://img.shields.io/pypi/l/deepdiff.svg?version=latest)\n[![Build Status](https://github.com/seperman/deepdiff/workflows/Unit%20Tests/badge.svg)](https://github.com/seperman/deepdiff/actions)\n[![codecov](https://codecov.io/gh/seperman/deepdiff/branch/master/graph/badge.svg?token=KkHZ3siA3m)](https://codecov.io/gh/seperman/deepdiff)\n\n## Modules\n\n- [DeepDiff](https://zepworks.com/deepdiff/current/diff.html): Deep Difference of dictionaries, iterables, strings, and ANY other object.\n- [DeepSearch](https://zepworks.com/deepdiff/current/dsearch.html): Search for objects within other objects.\n- [DeepHash](https://zepworks.com/deepdiff/current/deephash.html): Hash any object based on their content.\n- [Delta](https://zepworks.com/deepdiff/current/delta.html): Store the difference of objects and apply them to other objects.\n- [Extract](https://zepworks.com/deepdiff/current/extract.html): Extract an item from a nested Python object using its path.\n- [commandline](https://zepworks.com/deepdiff/current/commandline.html): Use DeepDiff from commandline.\n\nTested on Python 3.9+ and PyPy3.\n\n- **[Documentation](https://zepworks.com/deepdiff/8.6.1/)**\n\n## What is new?\n\nPlease check the [ChangeLog](CHANGELOG.md) file for the detailed information.\n\nDeepDiff 8-6-1\n- Patched security vulnerability in the Delta class which was vulnerable to class pollution via its constructor, and when combined with a gadget available in DeltaDiff itself, it could lead to Denial of Service and Remote Code Execution (via insecure Pickle deserialization).\n\nDeepDiff 8-6-0\n\n- Added Colored View thanks to @mauvilsa \n- Added support for applying deltas to NamedTuple thanks to @paulsc \n- Fixed test_delta.py with Python 3.14 thanks to @Romain-Geissler-1A\n- Added python property serialization to json\n- Added ip address serialization\n- Switched to UV from pip\n- Added Claude.md\n- Added uuid hashing thanks to @akshat62\n- Added `ignore_uuid_types` flag to DeepDiff to avoid type reports when comparing UUID and string.\n- Added comprehensive type hints across the codebase (multiple commits for better type safety)\n- Added support for memoryview serialization\n- Added support for bytes serialization (non-UTF8 compatible)\n- Fixed bug where group_by with numbers would leak type info into group path reports\n- Fixed bug in `_get_clean_to_keys_mapping without` explicit significant digits\n- Added support for python dict key serialization\n- Enhanced support for IP address serialization with safe module imports\n- Added development tooling improvements (pyright config, .envrc example)\n- Updated documentation and development instructions\n\n\nDeepDiff 8-5-0\n\n- Updating deprecated pydantic calls\n- Switching to pyproject.toml\n- Fix for moving nested tables when using iterable_compare_func.  by \n- Fix recursion depth limit when hashing numpy.datetime64\n- Moving from legacy setuptools use to pyproject.toml\n\n\nDeepDiff 8-4-2\n\n- fixes the type hints for the base\n- fixes summarize so if json dumps fails, we can still get a repr of the results\n- adds ipaddress support\n\n\n## Installation\n\n### Install from PyPi:\n\n`pip install deepdiff`\n\nIf you want to use DeepDiff from commandline:\n\n`pip install \"deepdiff[cli]\"`\n\nIf you want to improve the performance of DeepDiff with certain functionalities such as improved json serialization:\n\n`pip install \"deepdiff[optimize]\"`\n\nInstall optional packages:\n- [yaml](https://pypi.org/project/PyYAML/)\n- [tomli](https://pypi.org/project/tomli/) (python 3.10 and older) and [tomli-w](https://pypi.org/project/tomli-w/) for writing\n- [clevercsv](https://pypi.org/project/clevercsv/) for more rubust CSV parsing\n- [orjson](https://pypi.org/project/orjson/) for speed and memory optimized parsing\n- [pydantic](https://pypi.org/project/pydantic/)\n\n\n# Documentation\n\n<https://zepworks.com/deepdiff/current/>\n\n### A message from Sep, the creator of DeepDiff\n\n> ðŸ‘‹ Hi there,\n>\n> Thank you for using DeepDiff!\n> As an engineer, I understand the frustration of wrestling with **unruly data** in pipelines.\n> That's why I developed a new tool - [Qluster](https://qluster.ai/solution) to empower non-engineers to control and resolve data issues at scale autonomously and **stop bugging the engineers**! ðŸ› ï¸\n>\n> If you are going through this pain now, I would love to give you [early access](https://www.qluster.ai/try-qluster) to Qluster and get your feedback.\n\n\n# ChangeLog\n\nPlease take a look at the [CHANGELOG](CHANGELOG.md) file.\n\n# Survey\n\n:mega: **Please fill out our [fast 5-question survey](https://forms.gle/E6qXexcgjoKnSzjB8)** so that we can learn how & why you use DeepDiff, and what improvements we should make. Thank you! :dancers:\n\n# Local dev\n\n1. Clone the repo\n2. Switch to the dev branch\n3. Create your own branch\n4. Install dependencies\n\n    - Method 1: Use [`uv`](https://github.com/astral-sh/uv) to install the dependencies:  `uv sync --all-extras`.\n    - Method 2: Use pip: `pip install -e \".[cli,coverage,dev,docs,static,test]\"`\n5. Build `flit build`\n\n# Contribute\n\n1. Please make your PR against the dev branch\n2. Please make sure that your PR has tests. Since DeepDiff is used in many sensitive data driven projects, we strive to maintain around 100% test coverage on the code.\n\nPlease run `pytest --cov=deepdiff --runslow` to see the coverage report. Note that the `--runslow` flag will run some slow tests too. In most cases you only want to run the fast tests which so you wont add the `--runslow` flag.\n\nOr to see a more user friendly version, please run: `pytest --cov=deepdiff --cov-report term-missing --runslow`.\n\nThank you!\n\n# Authors\n\nPlease take a look at the [AUTHORS](AUTHORS.md) file.\n\n",
        "description_content_type": "text/markdown",
        "keywords": [],
        "author_email": "Seperman <sep@zepworks.com>",
        "maintainer_email": "Seperman <sep@zepworks.com>",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Topic :: Software Development",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Development Status :: 5 - Production/Stable",
          "License :: OSI Approved :: MIT License"
        ],
        "requires_dist": [
          "orderly-set>=5.4.1,<6",
          "click~=8.1.0 ; extra == \"cli\"",
          "pyyaml~=6.0.0 ; extra == \"cli\"",
          "coverage~=7.6.0 ; extra == \"coverage\"",
          "bump2version~=1.0.0 ; extra == \"dev\"",
          "jsonpickle~=4.0.0 ; extra == \"dev\"",
          "ipdb~=0.13.0 ; extra == \"dev\"",
          "numpy~=2.2.0 ; extra == \"dev\" and ( python_version >= '3.10')",
          "numpy~=2.0 ; extra == \"dev\" and ( python_version < '3.10')",
          "python-dateutil~=2.9.0 ; extra == \"dev\"",
          "orjson~=3.10.0 ; extra == \"dev\"",
          "tomli~=2.2.0 ; extra == \"dev\"",
          "tomli-w~=1.2.0 ; extra == \"dev\"",
          "pandas~=2.2.0 ; extra == \"dev\"",
          "polars~=1.21.0 ; extra == \"dev\"",
          "nox==2025.5.1 ; extra == \"dev\"",
          "uuid6==2025.0.1 ; extra == \"dev\"",
          "Sphinx~=6.2.0 ; extra == \"docs\"",
          "sphinx-sitemap~=2.6.0 ; extra == \"docs\"",
          "sphinxemoji~=0.3.0 ; extra == \"docs\"",
          "orjson ; extra == \"optimize\"",
          "flake8~=7.1.0 ; extra == \"static\"",
          "flake8-pyproject~=1.2.3 ; extra == \"static\"",
          "pydantic~=2.10.0 ; extra == \"static\"",
          "pytest~=8.3.0 ; extra == \"test\"",
          "pytest-benchmark~=5.1.0 ; extra == \"test\"",
          "pytest-cov~=6.0.0 ; extra == \"test\"",
          "python-dotenv~=1.0.0 ; extra == \"test\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Documentation, https://zepworks.com/deepdiff/",
          "Homepage, https://zepworks.com/deepdiff/",
          "Issues, https://github.com/seperman/deepdiff/issues",
          "Repository, https://github.com/seperman/deepdiff"
        ],
        "provides_extra": [
          "cli",
          "coverage",
          "dev",
          "docs",
          "optimize",
          "static",
          "test"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/deepdiff-8.6.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "pandas",
        "version": "2.3.3",
        "summary": "Powerful data structures for data analysis, time series, and statistics",
        "description": "<div align=\"center\">\n  <img src=\"https://pandas.pydata.org/static/img/pandas.svg\"><br>\n</div>\n\n-----------------\n\n# pandas: powerful Python data analysis toolkit\n\n| | |\n| --- | --- |\n| Testing | [![CI - Test](https://github.com/pandas-dev/pandas/actions/workflows/unit-tests.yml/badge.svg)](https://github.com/pandas-dev/pandas/actions/workflows/unit-tests.yml) [![Coverage](https://codecov.io/github/pandas-dev/pandas/coverage.svg?branch=main)](https://codecov.io/gh/pandas-dev/pandas) |\n| Package | [![PyPI Latest Release](https://img.shields.io/pypi/v/pandas.svg)](https://pypi.org/project/pandas/) [![PyPI Downloads](https://img.shields.io/pypi/dm/pandas.svg?label=PyPI%20downloads)](https://pypi.org/project/pandas/) [![Conda Latest Release](https://anaconda.org/conda-forge/pandas/badges/version.svg)](https://anaconda.org/conda-forge/pandas) [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/pandas.svg?label=Conda%20downloads)](https://anaconda.org/conda-forge/pandas) |\n| Meta | [![Powered by NumFOCUS](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A)](https://numfocus.org) [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3509134.svg)](https://doi.org/10.5281/zenodo.3509134) [![License - BSD 3-Clause](https://img.shields.io/pypi/l/pandas.svg)](https://github.com/pandas-dev/pandas/blob/main/LICENSE) [![Slack](https://img.shields.io/badge/join_Slack-information-brightgreen.svg?logo=slack)](https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack) |\n\n\n## What is it?\n\n**pandas** is a Python package that provides fast, flexible, and expressive data\nstructures designed to make working with \"relational\" or \"labeled\" data both\neasy and intuitive. It aims to be the fundamental high-level building block for\ndoing practical, **real world** data analysis in Python. Additionally, it has\nthe broader goal of becoming **the most powerful and flexible open source data\nanalysis / manipulation tool available in any language**. It is already well on\nits way towards this goal.\n\n## Table of Contents\n\n- [Main Features](#main-features)\n- [Where to get it](#where-to-get-it)\n- [Dependencies](#dependencies)\n- [Installation from sources](#installation-from-sources)\n- [License](#license)\n- [Documentation](#documentation)\n- [Background](#background)\n- [Getting Help](#getting-help)\n- [Discussion and Development](#discussion-and-development)\n- [Contributing to pandas](#contributing-to-pandas)\n\n## Main Features\nHere are just a few of the things that pandas does well:\n\n  - Easy handling of [**missing data**][missing-data] (represented as\n    `NaN`, `NA`, or `NaT`) in floating point as well as non-floating point data\n  - Size mutability: columns can be [**inserted and\n    deleted**][insertion-deletion] from DataFrame and higher dimensional\n    objects\n  - Automatic and explicit [**data alignment**][alignment]: objects can\n    be explicitly aligned to a set of labels, or the user can simply\n    ignore the labels and let `Series`, `DataFrame`, etc. automatically\n    align the data for you in computations\n  - Powerful, flexible [**group by**][groupby] functionality to perform\n    split-apply-combine operations on data sets, for both aggregating\n    and transforming data\n  - Make it [**easy to convert**][conversion] ragged,\n    differently-indexed data in other Python and NumPy data structures\n    into DataFrame objects\n  - Intelligent label-based [**slicing**][slicing], [**fancy\n    indexing**][fancy-indexing], and [**subsetting**][subsetting] of\n    large data sets\n  - Intuitive [**merging**][merging] and [**joining**][joining] data\n    sets\n  - Flexible [**reshaping**][reshape] and [**pivoting**][pivot-table] of\n    data sets\n  - [**Hierarchical**][mi] labeling of axes (possible to have multiple\n    labels per tick)\n  - Robust IO tools for loading data from [**flat files**][flat-files]\n    (CSV and delimited), [**Excel files**][excel], [**databases**][db],\n    and saving/loading data from the ultrafast [**HDF5 format**][hdfstore]\n  - [**Time series**][timeseries]-specific functionality: date range\n    generation and frequency conversion, moving window statistics,\n    date shifting and lagging\n\n\n   [missing-data]: https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html\n   [insertion-deletion]: https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#column-selection-addition-deletion\n   [alignment]: https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html?highlight=alignment#intro-to-data-structures\n   [groupby]: https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#group-by-split-apply-combine\n   [conversion]: https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#dataframe\n   [slicing]: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#slicing-ranges\n   [fancy-indexing]: https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#advanced\n   [subsetting]: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing\n   [merging]: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#database-style-dataframe-or-named-series-joining-merging\n   [joining]: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#joining-on-index\n   [reshape]: https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html\n   [pivot-table]: https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html\n   [mi]: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#hierarchical-indexing-multiindex\n   [flat-files]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#csv-text-files\n   [excel]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#excel-files\n   [db]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#sql-queries\n   [hdfstore]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#hdf5-pytables\n   [timeseries]: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#time-series-date-functionality\n\n## Where to get it\nThe source code is currently hosted on GitHub at:\nhttps://github.com/pandas-dev/pandas\n\nBinary installers for the latest released version are available at the [Python\nPackage Index (PyPI)](https://pypi.org/project/pandas) and on [Conda](https://docs.conda.io/en/latest/).\n\n```sh\n# conda\nconda install -c conda-forge pandas\n```\n\n```sh\n# or PyPI\npip install pandas\n```\n\nThe list of changes to pandas between each release can be found\n[here](https://pandas.pydata.org/pandas-docs/stable/whatsnew/index.html). For full\ndetails, see the commit logs at https://github.com/pandas-dev/pandas.\n\n## Dependencies\n- [NumPy - Adds support for large, multi-dimensional arrays, matrices and high-level mathematical functions to operate on these arrays](https://www.numpy.org)\n- [python-dateutil - Provides powerful extensions to the standard datetime module](https://dateutil.readthedocs.io/en/stable/index.html)\n- [pytz - Brings the Olson tz database into Python which allows accurate and cross platform timezone calculations](https://github.com/stub42/pytz)\n\nSee the [full installation instructions](https://pandas.pydata.org/pandas-docs/stable/install.html#dependencies) for minimum supported versions of required, recommended and optional dependencies.\n\n## Installation from sources\nTo install pandas from source you need [Cython](https://cython.org/) in addition to the normal\ndependencies above. Cython can be installed from PyPI:\n\n```sh\npip install cython\n```\n\nIn the `pandas` directory (same one where you found this file after\ncloning the git repo), execute:\n\n```sh\npip install .\n```\n\nor for installing in [development mode](https://pip.pypa.io/en/latest/cli/pip_install/#install-editable):\n\n\n```sh\npython -m pip install -ve . --no-build-isolation --config-settings=editable-verbose=true\n```\n\nSee the full instructions for [installing from source](https://pandas.pydata.org/docs/dev/development/contributing_environment.html).\n\n## License\n[BSD 3](LICENSE)\n\n## Documentation\nThe official documentation is hosted on [PyData.org](https://pandas.pydata.org/pandas-docs/stable/).\n\n## Background\nWork on ``pandas`` started at [AQR](https://www.aqr.com/) (a quantitative hedge fund) in 2008 and\nhas been under active development since then.\n\n## Getting Help\n\nFor usage questions, the best place to go to is [StackOverflow](https://stackoverflow.com/questions/tagged/pandas).\nFurther, general questions and discussions can also take place on the [pydata mailing list](https://groups.google.com/forum/?fromgroups#!forum/pydata).\n\n## Discussion and Development\nMost development discussions take place on GitHub in this repo, via the [GitHub issue tracker](https://github.com/pandas-dev/pandas/issues).\n\nFurther, the [pandas-dev mailing list](https://mail.python.org/mailman/listinfo/pandas-dev) can also be used for specialized discussions or design issues, and a [Slack channel](https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack) is available for quick development related questions.\n\nThere are also frequent [community meetings](https://pandas.pydata.org/docs/dev/development/community.html#community-meeting) for project maintainers open to the community as well as monthly [new contributor meetings](https://pandas.pydata.org/docs/dev/development/community.html#new-contributor-meeting) to help support new contributors.\n\nAdditional information on the communication channels can be found on the [contributor community](https://pandas.pydata.org/docs/development/community.html) page.\n\n## Contributing to pandas\n\n[![Open Source Helpers](https://www.codetriage.com/pandas-dev/pandas/badges/users.svg)](https://www.codetriage.com/pandas-dev/pandas)\n\nAll contributions, bug reports, bug fixes, documentation improvements, enhancements, and ideas are welcome.\n\nA detailed overview on how to contribute can be found in the **[contributing guide](https://pandas.pydata.org/docs/dev/development/contributing.html)**.\n\nIf you are simply looking to start working with the pandas codebase, navigate to the [GitHub \"issues\" tab](https://github.com/pandas-dev/pandas/issues) and start looking through interesting issues. There are a number of issues listed under [Docs](https://github.com/pandas-dev/pandas/issues?labels=Docs&sort=updated&state=open) and [good first issue](https://github.com/pandas-dev/pandas/issues?labels=good+first+issue&sort=updated&state=open) where you could start out.\n\nYou can also triage issues which may include reproducing bug reports, or asking for vital information such as version numbers or reproduction instructions. If you would like to start triaging issues, one easy way to get started is to [subscribe to pandas on CodeTriage](https://www.codetriage.com/pandas-dev/pandas).\n\nOr maybe through using pandas you have an idea of your own or are looking for something in the documentation and thinking â€˜this can be improvedâ€™...you can do something about it!\n\nFeel free to ask questions on the [mailing list](https://groups.google.com/forum/?fromgroups#!forum/pydata) or on [Slack](https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack).\n\nAs contributors and maintainers to this project, you are expected to abide by pandas' code of conduct. More information can be found at: [Contributor Code of Conduct](https://github.com/pandas-dev/.github/blob/master/CODE_OF_CONDUCT.md)\n\n<hr>\n\n[Go to Top](#table-of-contents)\n",
        "description_content_type": "text/markdown",
        "author_email": "The Pandas Development Team <pandas-dev@python.org>",
        "license": "BSD 3-Clause License\n\n Copyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team\n All rights reserved.\n\n Copyright (c) 2011-2023, Open source contributors.\n\n Redistribution and use in source and binary forms, with or without\n modification, are permitted provided that the following conditions are met:\n\n * Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n * Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n * Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\n THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n Copyright (c) 2010-2019 Keith Goodman\n Copyright (c) 2019 Bottleneck Developers\n All rights reserved.\n\n Redistribution and use in source and binary forms, with or without\n modification, are permitted provided that the following conditions are met:\n\n     * Redistributions of source code must retain the above copyright notice,\n       this list of conditions and the following disclaimer.\n\n     * Redistributions in binary form must reproduce the above copyright\n       notice, this list of conditions and the following disclaimer in the\n       documentation and/or other materials provided with the distribution.\n\n THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n POSSIBILITY OF SUCH DAMAGE.Copyright 2017- Paul Ganssle <paul@ganssle.io>\n Copyright 2017- dateutil contributors (see AUTHORS file)\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n        http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n\n The above license applies to all contributions after 2017-12-01, as well as\n all contributions that have been re-licensed (see AUTHORS file for the list of\n contributors who have re-licensed their code).\n --------------------------------------------------------------------------------\n dateutil - Extensions to the standard Python datetime module.\n\n Copyright (c) 2003-2011 - Gustavo Niemeyer <gustavo@niemeyer.net>\n Copyright (c) 2012-2014 - Tomi PievilÃ¤inen <tomi.pievilainen@iki.fi>\n Copyright (c) 2014-2016 - Yaron de Leeuw <me@jarondl.net>\n Copyright (c) 2015-     - Paul Ganssle <paul@ganssle.io>\n Copyright (c) 2015-     - dateutil contributors (see AUTHORS file)\n\n All rights reserved.\n\n Redistribution and use in source and binary forms, with or without\n modification, are permitted provided that the following conditions are met:\n\n     * Redistributions of source code must retain the above copyright notice,\n       this list of conditions and the following disclaimer.\n     * Redistributions in binary form must reproduce the above copyright notice,\n       this list of conditions and the following disclaimer in the documentation\n       and/or other materials provided with the distribution.\n     * Neither the name of the copyright holder nor the names of its\n       contributors may be used to endorse or promote products derived from\n       this software without specific prior written permission.\n\n THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR\n CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n The above BSD License Applies to all code, even that also covered by Apache 2.0.# MIT License\n\n Copyright (c) 2019 Hadley Wickham; RStudio; and Evan Miller\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in all\n copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n SOFTWARE.\n Based on http://opensource.org/licenses/MIT\n\n This is a template. Complete and ship as file LICENSE the following 2\n lines (only)\n\n YEAR:\n COPYRIGHT HOLDER:\n\n and specify as\n\n License: MIT + file LICENSE\n\n Copyright (c) <YEAR>, <COPYRIGHT HOLDER>\n\n Permission is hereby granted, free of charge, to any person obtaining\n a copy of this software and associated documentation files (the\n \"Software\"), to deal in the Software without restriction, including\n without limitation the rights to use, copy, modify, merge, publish,\n distribute, sublicense, and/or sell copies of the Software, and to\n permit persons to whom the Software is furnished to do so, subject to\n the following conditions:\n\n The above copyright notice and this permission notice shall be\n included in all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n The MIT License\n\n Copyright (c) 2008-     Attractive Chaos <attractor@live.co.uk>\n\n Permission is hereby granted, free of charge, to any person obtaining\n a copy of this software and associated documentation files (the\n \"Software\"), to deal in the Software without restriction, including\n without limitation the rights to use, copy, modify, merge, publish,\n distribute, sublicense, and/or sell copies of the Software, and to\n permit persons to whom the Software is furnished to do so, subject to\n the following conditions:\n\n The above copyright notice and this permission notice shall be\n included in all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n SOFTWARE.musl as a whole is licensed under the following standard MIT license:\n\n ----------------------------------------------------------------------\n Copyright Â© 2005-2020 Rich Felker, et al.\n\n Permission is hereby granted, free of charge, to any person obtaining\n a copy of this software and associated documentation files (the\n \"Software\"), to deal in the Software without restriction, including\n without limitation the rights to use, copy, modify, merge, publish,\n distribute, sublicense, and/or sell copies of the Software, and to\n permit persons to whom the Software is furnished to do so, subject to\n the following conditions:\n\n The above copyright notice and this permission notice shall be\n included in all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\n CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n ----------------------------------------------------------------------\n\n Authors/contributors include:\n\n A. Wilcox\n Ada Worcester\n Alex Dowad\n Alex Suykov\n Alexander Monakov\n Andre McCurdy\n Andrew Kelley\n Anthony G. Basile\n Aric Belsito\n Arvid Picciani\n Bartosz Brachaczek\n Benjamin Peterson\n Bobby Bingham\n Boris Brezillon\n Brent Cook\n Chris Spiegel\n ClÃ©ment Vasseur\n Daniel Micay\n Daniel Sabogal\n Daurnimator\n David Carlier\n David Edelsohn\n Denys Vlasenko\n Dmitry Ivanov\n Dmitry V. Levin\n Drew DeVault\n Emil Renner Berthing\n Fangrui Song\n Felix Fietkau\n Felix Janda\n Gianluca Anzolin\n Hauke Mehrtens\n He X\n Hiltjo Posthuma\n Isaac Dunham\n Jaydeep Patil\n Jens Gustedt\n Jeremy Huntwork\n Jo-Philipp Wich\n Joakim Sindholt\n John Spencer\n Julien Ramseier\n Justin Cormack\n Kaarle Ritvanen\n Khem Raj\n Kylie McClain\n Leah Neukirchen\n Luca Barbato\n Luka Perkov\n M Farkas-Dyck (Strake)\n Mahesh Bodapati\n Markus Wichmann\n Masanori Ogino\n Michael Clark\n Michael Forney\n Mikhail Kremnyov\n Natanael Copa\n Nicholas J. Kain\n orc\n Pascal Cuoq\n Patrick Oppenlander\n Petr Hosek\n Petr Skocik\n Pierre Carrier\n Reini Urban\n Rich Felker\n Richard Pennington\n Ryan Fairfax\n Samuel Holland\n Segev Finer\n Shiz\n sin\n Solar Designer\n Stefan Kristiansson\n Stefan O'Rear\n Szabolcs Nagy\n Timo TerÃ¤s\n Trutz Behn\n Valentin Ochs\n Will Dietz\n William Haddon\n William Pitcock\n\n Portions of this software are derived from third-party works licensed\n under terms compatible with the above MIT license:\n\n The TRE regular expression implementation (src/regex/reg* and\n src/regex/tre*) is Copyright Â© 2001-2008 Ville Laurikari and licensed\n under a 2-clause BSD license (license text in the source files). The\n included version has been heavily modified by Rich Felker in 2012, in\n the interests of size, simplicity, and namespace cleanliness.\n\n Much of the math library code (src/math/* and src/complex/*) is\n Copyright Â© 1993,2004 Sun Microsystems or\n Copyright Â© 2003-2011 David Schultz or\n Copyright Â© 2003-2009 Steven G. Kargl or\n Copyright Â© 2003-2009 Bruce D. Evans or\n Copyright Â© 2008 Stephen L. Moshier or\n Copyright Â© 2017-2018 Arm Limited\n and labelled as such in comments in the individual source files. All\n have been licensed under extremely permissive terms.\n\n The ARM memcpy code (src/string/arm/memcpy.S) is Copyright Â© 2008\n The Android Open Source Project and is licensed under a two-clause BSD\n license. It was taken from Bionic libc, used on Android.\n\n The AArch64 memcpy and memset code (src/string/aarch64/*) are\n Copyright Â© 1999-2019, Arm Limited.\n\n The implementation of DES for crypt (src/crypt/crypt_des.c) is\n Copyright Â© 1994 David Burren. It is licensed under a BSD license.\n\n The implementation of blowfish crypt (src/crypt/crypt_blowfish.c) was\n originally written by Solar Designer and placed into the public\n domain. The code also comes with a fallback permissive license for use\n in jurisdictions that may not recognize the public domain.\n\n The smoothsort implementation (src/stdlib/qsort.c) is Copyright Â© 2011\n Valentin Ochs and is licensed under an MIT-style license.\n\n The x86_64 port was written by Nicholas J. Kain and is licensed under\n the standard MIT terms.\n\n The mips and microblaze ports were originally written by Richard\n Pennington for use in the ellcc project. The original code was adapted\n by Rich Felker for build system and code conventions during upstream\n integration. It is licensed under the standard MIT terms.\n\n The mips64 port was contributed by Imagination Technologies and is\n licensed under the standard MIT terms.\n\n The powerpc port was also originally written by Richard Pennington,\n and later supplemented and integrated by John Spencer. It is licensed\n under the standard MIT terms.\n\n All other files which have no copyright comments are original works\n produced specifically for use as part of this library, written either\n by Rich Felker, the main author of the library, or by one or more\n contibutors listed above. Details on authorship of individual files\n can be found in the git version control history of the project. The\n omission of copyright and license comments in each file is in the\n interest of source tree size.\n\n In addition, permission is hereby granted for all public header files\n (include/* and arch/*/bits/*) and crt files intended to be linked into\n applications (crt/*, ldso/dlstart.c, and arch/*/crt_arch.h) to omit\n the copyright notice and permission notice otherwise required by the\n license, and to use these files without any requirement of\n attribution. These files include substantial contributions from:\n\n Bobby Bingham\n John Spencer\n Nicholas J. Kain\n Rich Felker\n Richard Pennington\n Stefan Kristiansson\n Szabolcs Nagy\n\n all of whom have explicitly granted such permission.\n\n This file previously contained text expressing a belief that most of\n the files covered by the above exception were sufficiently trivial not\n to be subject to copyright, resulting in confusion over whether it\n negated the permissions granted in the license. In the spirit of\n permissive licensing, and of not having licensing issues being an\n obstacle to adoption, that text has been removed.Copyright (c) 2005-2023, NumPy Developers.\n All rights reserved.\n\n Redistribution and use in source and binary forms, with or without\n modification, are permitted provided that the following conditions are\n met:\n\n     * Redistributions of source code must retain the above copyright\n        notice, this list of conditions and the following disclaimer.\n\n     * Redistributions in binary form must reproduce the above\n        copyright notice, this list of conditions and the following\n        disclaimer in the documentation and/or other materials provided\n        with the distribution.\n\n     * Neither the name of the NumPy Developers nor the names of any\n        contributors may be used to endorse or promote products derived\n        from this software without specific prior written permission.\n\n THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n                                  Apache License\n                            Version 2.0, January 2004\n                         http://www.apache.org/licenses/\n\n    TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n    1. Definitions.\n\n       \"License\" shall mean the terms and conditions for use, reproduction,\n       and distribution as defined by Sections 1 through 9 of this document.\n\n       \"Licensor\" shall mean the copyright owner or entity authorized by\n       the copyright owner that is granting the License.\n\n       \"Legal Entity\" shall mean the union of the acting entity and all\n       other entities that control, are controlled by, or are under common\n       control with that entity. For the purposes of this definition,\n       \"control\" means (i) the power, direct or indirect, to cause the\n       direction or management of such entity, whether by contract or\n       otherwise, or (ii) ownership of fifty percent (50%) or more of the\n       outstanding shares, or (iii) beneficial ownership of such entity.\n\n       \"You\" (or \"Your\") shall mean an individual or Legal Entity\n       exercising permissions granted by this License.\n\n       \"Source\" form shall mean the preferred form for making modifications,\n       including but not limited to software source code, documentation\n       source, and configuration files.\n\n       \"Object\" form shall mean any form resulting from mechanical\n       transformation or translation of a Source form, including but\n       not limited to compiled object code, generated documentation,\n       and conversions to other media types.\n\n       \"Work\" shall mean the work of authorship, whether in Source or\n       Object form, made available under the License, as indicated by a\n       copyright notice that is included in or attached to the work\n       (an example is provided in the Appendix below).\n\n       \"Derivative Works\" shall mean any work, whether in Source or Object\n       form, that is based on (or derived from) the Work and for which the\n       editorial revisions, annotations, elaborations, or other modifications\n       represent, as a whole, an original work of authorship. For the purposes\n       of this License, Derivative Works shall not include works that remain\n       separable from, or merely link (or bind by name) to the interfaces of,\n       the Work and Derivative Works thereof.\n\n       \"Contribution\" shall mean any work of authorship, including\n       the original version of the Work and any modifications or additions\n       to that Work or Derivative Works thereof, that is intentionally\n       submitted to Licensor for inclusion in the Work by the copyright owner\n       or by an individual or Legal Entity authorized to submit on behalf of\n       the copyright owner. For the purposes of this definition, \"submitted\"\n       means any form of electronic, verbal, or written communication sent\n       to the Licensor or its representatives, including but not limited to\n       communication on electronic mailing lists, source code control systems,\n       and issue tracking systems that are managed by, or on behalf of, the\n       Licensor for the purpose of discussing and improving the Work, but\n       excluding communication that is conspicuously marked or otherwise\n       designated in writing by the copyright owner as \"Not a Contribution.\"\n\n       \"Contributor\" shall mean Licensor and any individual or Legal Entity\n       on behalf of whom a Contribution has been received by Licensor and\n       subsequently incorporated within the Work.\n\n    2. Grant of Copyright License. Subject to the terms and conditions of\n       this License, each Contributor hereby grants to You a perpetual,\n       worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n       copyright license to reproduce, prepare Derivative Works of,\n       publicly display, publicly perform, sublicense, and distribute the\n       Work and such Derivative Works in Source or Object form.\n\n    3. Grant of Patent License. Subject to the terms and conditions of\n       this License, each Contributor hereby grants to You a perpetual,\n       worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n       (except as stated in this section) patent license to make, have made,\n       use, offer to sell, sell, import, and otherwise transfer the Work,\n       where such license applies only to those patent claims licensable\n       by such Contributor that are necessarily infringed by their\n       Contribution(s) alone or by combination of their Contribution(s)\n       with the Work to which such Contribution(s) was submitted. If You\n       institute patent litigation against any entity (including a\n       cross-claim or counterclaim in a lawsuit) alleging that the Work\n       or a Contribution incorporated within the Work constitutes direct\n       or contributory patent infringement, then any patent licenses\n       granted to You under this License for that Work shall terminate\n       as of the date such litigation is filed.\n\n    4. Redistribution. You may reproduce and distribute copies of the\n       Work or Derivative Works thereof in any medium, with or without\n       modifications, and in Source or Object form, provided that You\n       meet the following conditions:\n\n       (a) You must give any other recipients of the Work or\n           Derivative Works a copy of this License; and\n\n       (b) You must cause any modified files to carry prominent notices\n           stating that You changed the files; and\n\n       (c) You must retain, in the Source form of any Derivative Works\n           that You distribute, all copyright, patent, trademark, and\n           attribution notices from the Source form of the Work,\n           excluding those notices that do not pertain to any part of\n           the Derivative Works; and\n\n       (d) If the Work includes a \"NOTICE\" text file as part of its\n           distribution, then any Derivative Works that You distribute must\n           include a readable copy of the attribution notices contained\n           within such NOTICE file, excluding those notices that do not\n           pertain to any part of the Derivative Works, in at least one\n           of the following places: within a NOTICE text file distributed\n           as part of the Derivative Works; within the Source form or\n           documentation, if provided along with the Derivative Works; or,\n           within a display generated by the Derivative Works, if and\n           wherever such third-party notices normally appear. The contents\n           of the NOTICE file are for informational purposes only and\n           do not modify the License. You may add Your own attribution\n           notices within Derivative Works that You distribute, alongside\n           or as an addendum to the NOTICE text from the Work, provided\n           that such additional attribution notices cannot be construed\n           as modifying the License.\n\n       You may add Your own copyright statement to Your modifications and\n       may provide additional or different license terms and conditions\n       for use, reproduction, or distribution of Your modifications, or\n       for any such Derivative Works as a whole, provided Your use,\n       reproduction, and distribution of the Work otherwise complies with\n       the conditions stated in this License.\n\n    5. Submission of Contributions. Unless You explicitly state otherwise,\n       any Contribution intentionally submitted for inclusion in the Work\n       by You to the Licensor shall be under the terms and conditions of\n       this License, without any additional terms or conditions.\n       Notwithstanding the above, nothing herein shall supersede or modify\n       the terms of any separate license agreement you may have executed\n       with Licensor regarding such Contributions.\n\n    6. Trademarks. This License does not grant permission to use the trade\n       names, trademarks, service marks, or product names of the Licensor,\n       except as required for reasonable and customary use in describing the\n       origin of the Work and reproducing the content of the NOTICE file.\n\n    7. Disclaimer of Warranty. Unless required by applicable law or\n       agreed to in writing, Licensor provides the Work (and each\n       Contributor provides its Contributions) on an \"AS IS\" BASIS,\n       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n       implied, including, without limitation, any warranties or conditions\n       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n       PARTICULAR PURPOSE. You are solely responsible for determining the\n       appropriateness of using or redistributing the Work and assume any\n       risks associated with Your exercise of permissions under this License.\n\n    8. Limitation of Liability. In no event and under no legal theory,\n       whether in tort (including negligence), contract, or otherwise,\n       unless required by applicable law (such as deliberate and grossly\n       negligent acts) or agreed to in writing, shall any Contributor be\n       liable to You for damages, including any direct, indirect, special,\n       incidental, or consequential damages of any character arising as a\n       result of this License or out of the use or inability to use the\n       Work (including but not limited to damages for loss of goodwill,\n       work stoppage, computer failure or malfunction, or any and all\n       other commercial damages or losses), even if such Contributor\n       has been advised of the possibility of such damages.\n\n    9. Accepting Warranty or Additional Liability. While redistributing\n       the Work or Derivative Works thereof, You may choose to offer,\n       and charge a fee for, acceptance of support, warranty, indemnity,\n       or other liability obligations and/or rights consistent with this\n       License. However, in accepting such obligations, You may act only\n       on Your own behalf and on Your sole responsibility, not on behalf\n       of any other Contributor, and only if You agree to indemnify,\n       defend, and hold each Contributor harmless for any liability\n       incurred by, or claims asserted against, such Contributor by reason\n       of your accepting any such warranty or additional liability.\n\n    END OF TERMS AND CONDITIONS\n\n\n Copyright (c) Donald Stufft and individual contributors.\n All rights reserved.\n\n Redistribution and use in source and binary forms, with or without\n modification, are permitted provided that the following conditions are met:\n\n     1. Redistributions of source code must retain the above copyright notice,\n        this list of conditions and the following disclaimer.\n\n     2. Redistributions in binary form must reproduce the above copyright\n        notice, this list of conditions and the following disclaimer in the\n        documentation and/or other materials provided with the distribution.\n\n THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.A. HISTORY OF THE SOFTWARE\n ==========================\n\n Python was created in the early 1990s by Guido van Rossum at Stichting\n Mathematisch Centrum (CWI, see https://www.cwi.nl) in the Netherlands\n as a successor of a language called ABC.  Guido remains Python's\n principal author, although it includes many contributions from others.\n\n In 1995, Guido continued his work on Python at the Corporation for\n National Research Initiatives (CNRI, see https://www.cnri.reston.va.us)\n in Reston, Virginia where he released several versions of the\n software.\n\n In May 2000, Guido and the Python core development team moved to\n BeOpen.com to form the BeOpen PythonLabs team.  In October of the same\n year, the PythonLabs team moved to Digital Creations, which became\n Zope Corporation.  In 2001, the Python Software Foundation (PSF, see\n https://www.python.org/psf/) was formed, a non-profit organization\n created specifically to own Python-related Intellectual Property.\n Zope Corporation was a sponsoring member of the PSF.\n\n All Python releases are Open Source (see https://opensource.org for\n the Open Source Definition).  Historically, most, but not all, Python\n releases have also been GPL-compatible; the table below summarizes\n the various releases.\n\n     Release         Derived     Year        Owner       GPL-\n                     from                                compatible? (1)\n\n     0.9.0 thru 1.2              1991-1995   CWI         yes\n     1.3 thru 1.5.2  1.2         1995-1999   CNRI        yes\n     1.6             1.5.2       2000        CNRI        no\n     2.0             1.6         2000        BeOpen.com  no\n     1.6.1           1.6         2001        CNRI        yes (2)\n     2.1             2.0+1.6.1   2001        PSF         no\n     2.0.1           2.0+1.6.1   2001        PSF         yes\n     2.1.1           2.1+2.0.1   2001        PSF         yes\n     2.1.2           2.1.1       2002        PSF         yes\n     2.1.3           2.1.2       2002        PSF         yes\n     2.2 and above   2.1.1       2001-now    PSF         yes\n\n Footnotes:\n\n (1) GPL-compatible doesn't mean that we're distributing Python under\n     the GPL.  All Python licenses, unlike the GPL, let you distribute\n     a modified version without making your changes open source.  The\n     GPL-compatible licenses make it possible to combine Python with\n     other software that is released under the GPL; the others don't.\n\n (2) According to Richard Stallman, 1.6.1 is not GPL-compatible,\n     because its license has a choice of law clause.  According to\n     CNRI, however, Stallman's lawyer has told CNRI's lawyer that 1.6.1\n     is \"not incompatible\" with the GPL.\n\n Thanks to the many outside volunteers who have worked under Guido's\n direction to make these releases possible.\n\n\n B. TERMS AND CONDITIONS FOR ACCESSING OR OTHERWISE USING PYTHON\n ===============================================================\n\n Python software and documentation are licensed under the\n Python Software Foundation License Version 2.\n\n Starting with Python 3.8.6, examples, recipes, and other code in\n the documentation are dual licensed under the PSF License Version 2\n and the Zero-Clause BSD license.\n\n Some software incorporated into Python is under different licenses.\n The licenses are listed with code falling under that license.\n\n\n PYTHON SOFTWARE FOUNDATION LICENSE VERSION 2\n --------------------------------------------\n\n 1. This LICENSE AGREEMENT is between the Python Software Foundation\n (\"PSF\"), and the Individual or Organization (\"Licensee\") accessing and\n otherwise using this software (\"Python\") in source or binary form and\n its associated documentation.\n\n 2. Subject to the terms and conditions of this License Agreement, PSF hereby\n grants Licensee a nonexclusive, royalty-free, world-wide license to reproduce,\n analyze, test, perform and/or display publicly, prepare derivative works,\n distribute, and otherwise use Python alone or in any derivative version,\n provided, however, that PSF's License Agreement and PSF's notice of copyright,\n i.e., \"Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,\n 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023 Python Software Foundation;\n All Rights Reserved\" are retained in Python alone or in any derivative version\n prepared by Licensee.\n\n 3. In the event Licensee prepares a derivative work that is based on\n or incorporates Python or any part thereof, and wants to make\n the derivative work available to others as provided herein, then\n Licensee hereby agrees to include in any such work a brief summary of\n the changes made to Python.\n\n 4. PSF is making Python available to Licensee on an \"AS IS\"\n basis.  PSF MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\n IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, PSF MAKES NO AND\n DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\n FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON WILL NOT\n INFRINGE ANY THIRD PARTY RIGHTS.\n\n 5. PSF SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON\n FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS\n A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON,\n OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.\n\n 6. This License Agreement will automatically terminate upon a material\n breach of its terms and conditions.\n\n 7. Nothing in this License Agreement shall be deemed to create any\n relationship of agency, partnership, or joint venture between PSF and\n Licensee.  This License Agreement does not grant permission to use PSF\n trademarks or trade name in a trademark sense to endorse or promote\n products or services of Licensee, or any third party.\n\n 8. By copying, installing or otherwise using Python, Licensee\n agrees to be bound by the terms and conditions of this License\n Agreement.\n\n\n BEOPEN.COM LICENSE AGREEMENT FOR PYTHON 2.0\n -------------------------------------------\n\n BEOPEN PYTHON OPEN SOURCE LICENSE AGREEMENT VERSION 1\n\n 1. This LICENSE AGREEMENT is between BeOpen.com (\"BeOpen\"), having an\n office at 160 Saratoga Avenue, Santa Clara, CA 95051, and the\n Individual or Organization (\"Licensee\") accessing and otherwise using\n this software in source or binary form and its associated\n documentation (\"the Software\").\n\n 2. Subject to the terms and conditions of this BeOpen Python License\n Agreement, BeOpen hereby grants Licensee a non-exclusive,\n royalty-free, world-wide license to reproduce, analyze, test, perform\n and/or display publicly, prepare derivative works, distribute, and\n otherwise use the Software alone or in any derivative version,\n provided, however, that the BeOpen Python License is retained in the\n Software, alone or in any derivative version prepared by Licensee.\n\n 3. BeOpen is making the Software available to Licensee on an \"AS IS\"\n basis.  BEOPEN MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\n IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, BEOPEN MAKES NO AND\n DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\n FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF THE SOFTWARE WILL NOT\n INFRINGE ANY THIRD PARTY RIGHTS.\n\n 4. BEOPEN SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF THE\n SOFTWARE FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS\n AS A RESULT OF USING, MODIFYING OR DISTRIBUTING THE SOFTWARE, OR ANY\n DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.\n\n 5. This License Agreement will automatically terminate upon a material\n breach of its terms and conditions.\n\n 6. This License Agreement shall be governed by and interpreted in all\n respects by the law of the State of California, excluding conflict of\n law provisions.  Nothing in this License Agreement shall be deemed to\n create any relationship of agency, partnership, or joint venture\n between BeOpen and Licensee.  This License Agreement does not grant\n permission to use BeOpen trademarks or trade names in a trademark\n sense to endorse or promote products or services of Licensee, or any\n third party.  As an exception, the \"BeOpen Python\" logos available at\n http://www.pythonlabs.com/logos.html may be used according to the\n permissions granted on that web page.\n\n 7. By copying, installing or otherwise using the software, Licensee\n agrees to be bound by the terms and conditions of this License\n Agreement.\n\n\n CNRI LICENSE AGREEMENT FOR PYTHON 1.6.1\n ---------------------------------------\n\n 1. This LICENSE AGREEMENT is between the Corporation for National\n Research Initiatives, having an office at 1895 Preston White Drive,\n Reston, VA 20191 (\"CNRI\"), and the Individual or Organization\n (\"Licensee\") accessing and otherwise using Python 1.6.1 software in\n source or binary form and its associated documentation.\n\n 2. Subject to the terms and conditions of this License Agreement, CNRI\n hereby grants Licensee a nonexclusive, royalty-free, world-wide\n license to reproduce, analyze, test, perform and/or display publicly,\n prepare derivative works, distribute, and otherwise use Python 1.6.1\n alone or in any derivative version, provided, however, that CNRI's\n License Agreement and CNRI's notice of copyright, i.e., \"Copyright (c)\n 1995-2001 Corporation for National Research Initiatives; All Rights\n Reserved\" are retained in Python 1.6.1 alone or in any derivative\n version prepared by Licensee.  Alternately, in lieu of CNRI's License\n Agreement, Licensee may substitute the following text (omitting the\n quotes): \"Python 1.6.1 is made available subject to the terms and\n conditions in CNRI's License Agreement.  This Agreement together with\n Python 1.6.1 may be located on the internet using the following\n unique, persistent identifier (known as a handle): 1895.22/1013.  This\n Agreement may also be obtained from a proxy server on the internet\n using the following URL: http://hdl.handle.net/1895.22/1013\".\n\n 3. In the event Licensee prepares a derivative work that is based on\n or incorporates Python 1.6.1 or any part thereof, and wants to make\n the derivative work available to others as provided herein, then\n Licensee hereby agrees to include in any such work a brief summary of\n the changes made to Python 1.6.1.\n\n 4. CNRI is making Python 1.6.1 available to Licensee on an \"AS IS\"\n basis.  CNRI MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\n IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, CNRI MAKES NO AND\n DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\n FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON 1.6.1 WILL NOT\n INFRINGE ANY THIRD PARTY RIGHTS.\n\n 5. CNRI SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON\n 1.6.1 FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS\n A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON 1.6.1,\n OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.\n\n 6. This License Agreement will automatically terminate upon a material\n breach of its terms and conditions.\n\n 7. This License Agreement shall be governed by the federal\n intellectual property law of the United States, including without\n limitation the federal copyright law, and, to the extent such\n U.S. federal law does not apply, by the law of the Commonwealth of\n Virginia, excluding Virginia's conflict of law provisions.\n Notwithstanding the foregoing, with regard to derivative works based\n on Python 1.6.1 that incorporate non-separable material that was\n previously distributed under the GNU General Public License (GPL), the\n law of the Commonwealth of Virginia shall govern this License\n Agreement only as to issues arising under or with respect to\n Paragraphs 4, 5, and 7 of this License Agreement.  Nothing in this\n License Agreement shall be deemed to create any relationship of\n agency, partnership, or joint venture between CNRI and Licensee.  This\n License Agreement does not grant permission to use CNRI trademarks or\n trade name in a trademark sense to endorse or promote products or\n services of Licensee, or any third party.\n\n 8. By clicking on the \"ACCEPT\" button where indicated, or by copying,\n installing or otherwise using Python 1.6.1, Licensee agrees to be\n bound by the terms and conditions of this License Agreement.\n\n         ACCEPT\n\n\n CWI LICENSE AGREEMENT FOR PYTHON 0.9.0 THROUGH 1.2\n --------------------------------------------------\n\n Copyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam,\n The Netherlands.  All rights reserved.\n\n Permission to use, copy, modify, and distribute this software and its\n documentation for any purpose and without fee is hereby granted,\n provided that the above copyright notice appear in all copies and that\n both that copyright notice and this permission notice appear in\n supporting documentation, and that the name of Stichting Mathematisch\n Centrum or CWI not be used in advertising or publicity pertaining to\n distribution of the software without specific, written prior\n permission.\n\n STICHTING MATHEMATISCH CENTRUM DISCLAIMS ALL WARRANTIES WITH REGARD TO\n THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n FITNESS, IN NO EVENT SHALL STICHTING MATHEMATISCH CENTRUM BE LIABLE\n FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT\n OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n ZERO-CLAUSE BSD LICENSE FOR CODE IN THE PYTHON DOCUMENTATION\n ----------------------------------------------------------------------\n\n Permission to use, copy, modify, and/or distribute this software for any\n purpose with or without fee is hereby granted.\n\n THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\n AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\n INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\n LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\n OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\n PERFORMANCE OF THIS SOFTWARE.\n Copyright (c) 2014, Al Sweigart\n All rights reserved.\n\n Redistribution and use in source and binary forms, with or without\n modification, are permitted provided that the following conditions are met:\n\n * Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n * Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n * Neither the name of the {organization} nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\n THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.Copyright (c) 2017 Anthony Sottile\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.Copyright (c) 2015-2019 Jared Hobbs\n\n Permission is hereby granted, free of charge, to any person obtaining a copy of\n this software and associated documentation files (the \"Software\"), to deal in\n the Software without restriction, including without limitation the rights to\n use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n of the Software, and to permit persons to whom the Software is furnished to do\n so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in all\n copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n SOFTWARE.Developed by ESN, an Electronic Arts Inc. studio.\n Copyright (c) 2014, Electronic Arts Inc.\n All rights reserved.\n\n Redistribution and use in source and binary forms, with or without\n modification, are permitted provided that the following conditions are met:\n * Redistributions of source code must retain the above copyright\n notice, this list of conditions and the following disclaimer.\n * Redistributions in binary form must reproduce the above copyright\n notice, this list of conditions and the following disclaimer in the\n documentation and/or other materials provided with the distribution.\n * Neither the name of ESN, Electronic Arts Inc. nor the\n names of its contributors may be used to endorse or promote products\n derived from this software without specific prior written permission.\n\n THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n DISCLAIMED. IN NO EVENT SHALL ELECTRONIC ARTS INC. BE LIABLE\n FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n ----\n\n Portions of code from MODP_ASCII - Ascii transformations (upper/lower, etc)\n https://github.com/client9/stringencoders\n\n   Copyright 2005, 2006, 2007\n   Nick Galbreath -- nickg [at] modp [dot] com\n   All rights reserved.\n\n   Redistribution and use in source and binary forms, with or without\n   modification, are permitted provided that the following conditions are\n   met:\n\n     Redistributions of source code must retain the above copyright\n     notice, this list of conditions and the following disclaimer.\n\n     Redistributions in binary form must reproduce the above copyright\n     notice, this list of conditions and the following disclaimer in the\n     documentation and/or other materials provided with the distribution.\n\n     Neither the name of the modp.com nor the names of its\n     contributors may be used to endorse or promote products derived from\n     this software without specific prior written permission.\n\n   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n   \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n   This is the standard \"new\" BSD license:\n   http://www.opensource.org/licenses/bsd-license.php\n\n https://github.com/client9/stringencoders/blob/cfd5c1507325ae497ea9bacdacba12c0ffd79d30/COPYING\n\n ----\n\n Numeric decoder derived from from TCL library\n https://opensource.apple.com/source/tcl/tcl-14/tcl/license.terms\n  * Copyright (c) 1988-1993 The Regents of the University of California.\n  * Copyright (c) 1994 Sun Microsystems, Inc.\n\n   This software is copyrighted by the Regents of the University of\n   California, Sun Microsystems, Inc., Scriptics Corporation, ActiveState\n   Corporation and other parties.  The following terms apply to all files\n   associated with the software unless explicitly disclaimed in\n   individual files.\n\n   The authors hereby grant permission to use, copy, modify, distribute,\n   and license this software and its documentation for any purpose, provided\n   that existing copyright notices are retained in all copies and that this\n   notice is included verbatim in any distributions. No written agreement,\n   license, or royalty fee is required for any of the authorized uses.\n   Modifications to this software may be copyrighted by their authors\n   and need not follow the licensing terms described here, provided that\n   the new terms are clearly indicated on the first page of each file where\n   they apply.\n\n   IN NO EVENT SHALL THE AUTHORS OR DISTRIBUTORS BE LIABLE TO ANY PARTY\n   FOR DIRECT, INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES\n   ARISING OUT OF THE USE OF THIS SOFTWARE, ITS DOCUMENTATION, OR ANY\n   DERIVATIVES THEREOF, EVEN IF THE AUTHORS HAVE BEEN ADVISED OF THE\n   POSSIBILITY OF SUCH DAMAGE.\n\n   THE AUTHORS AND DISTRIBUTORS SPECIFICALLY DISCLAIM ANY WARRANTIES,\n   INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY,\n   FITNESS FOR A PARTICULAR PURPOSE, AND NON-INFRINGEMENT.  THIS SOFTWARE\n   IS PROVIDED ON AN \"AS IS\" BASIS, AND THE AUTHORS AND DISTRIBUTORS HAVE\n   NO OBLIGATION TO PROVIDE MAINTENANCE, SUPPORT, UPDATES, ENHANCEMENTS, OR\n   MODIFICATIONS.\n\n   GOVERNMENT USE: If you are acquiring this software on behalf of the\n   U.S. government, the Government shall have only \"Restricted Rights\"\n   in the software and related documentation as defined in the Federal\n   Acquisition Regulations (FARs) in Clause 52.227.19 (c) (2).  If you\n   are acquiring the software on behalf of the Department of Defense, the\n   software shall be classified as \"Commercial Computer Software\" and the\n   Government shall have only \"Restricted Rights\" as defined in Clause\n   252.227-7013 (c) (1) of DFARs.  Notwithstanding the foregoing, the\n   authors grant the U.S. Government and others acting in its behalf\n   permission to use and distribute the software in accordance with the\n   terms specified in this license.Apache License\n Version 2.0, January 2004\n http://www.apache.org/licenses/\n\n TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n 1. Definitions.\n\n \"License\" shall mean the terms and conditions for use, reproduction, and\n distribution as defined by Sections 1 through 9 of this document.\n\n \"Licensor\" shall mean the copyright owner or entity authorized by the copyright\n owner that is granting the License.\n\n \"Legal Entity\" shall mean the union of the acting entity and all other entities\n that control, are controlled by, or are under common control with that entity.\n For the purposes of this definition, \"control\" means (i) the power, direct or\n indirect, to cause the direction or management of such entity, whether by\n contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the\n outstanding shares, or (iii) beneficial ownership of such entity.\n\n \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising\n permissions granted by this License.\n\n \"Source\" form shall mean the preferred form for making modifications, including\n but not limited to software source code, documentation source, and configuration\n files.\n\n \"Object\" form shall mean any form resulting from mechanical transformation or\n translation of a Source form, including but not limited to compiled object code,\n generated documentation, and conversions to other media types.\n\n \"Work\" shall mean the work of authorship, whether in Source or Object form, made\n available under the License, as indicated by a copyright notice that is included\n in or attached to the work (an example is provided in the Appendix below).\n\n \"Derivative Works\" shall mean any work, whether in Source or Object form, that\n is based on (or derived from) the Work and for which the editorial revisions,\n annotations, elaborations, or other modifications represent, as a whole, an\n original work of authorship. For the purposes of this License, Derivative Works\n shall not include works that remain separable from, or merely link (or bind by\n name) to the interfaces of, the Work and Derivative Works thereof.\n\n \"Contribution\" shall mean any work of authorship, including the original version\n of the Work and any modifications or additions to that Work or Derivative Works\n thereof, that is intentionally submitted to Licensor for inclusion in the Work\n by the copyright owner or by an individual or Legal Entity authorized to submit\n on behalf of the copyright owner. For the purposes of this definition,\n \"submitted\" means any form of electronic, verbal, or written communication sent\n to the Licensor or its representatives, including but not limited to\n communication on electronic mailing lists, source code control systems, and\n issue tracking systems that are managed by, or on behalf of, the Licensor for\n the purpose of discussing and improving the Work, but excluding communication\n that is conspicuously marked or otherwise designated in writing by the copyright\n owner as \"Not a Contribution.\"\n\n \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf\n of whom a Contribution has been received by Licensor and subsequently\n incorporated within the Work.\n\n 2. Grant of Copyright License.\n\n Subject to the terms and conditions of this License, each Contributor hereby\n grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free,\n irrevocable copyright license to reproduce, prepare Derivative Works of,\n publicly display, publicly perform, sublicense, and distribute the Work and such\n Derivative Works in Source or Object form.\n\n 3. Grant of Patent License.\n\n Subject to the terms and conditions of this License, each Contributor hereby\n grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free,\n irrevocable (except as stated in this section) patent license to make, have\n made, use, offer to sell, sell, import, and otherwise transfer the Work, where\n such license applies only to those patent claims licensable by such Contributor\n that are necessarily infringed by their Contribution(s) alone or by combination\n of their Contribution(s) with the Work to which such Contribution(s) was\n submitted. If You institute patent litigation against any entity (including a\n cross-claim or counterclaim in a lawsuit) alleging that the Work or a\n Contribution incorporated within the Work constitutes direct or contributory\n patent infringement, then any patent licenses granted to You under this License\n for that Work shall terminate as of the date such litigation is filed.\n\n 4. Redistribution.\n\n You may reproduce and distribute copies of the Work or Derivative Works thereof\n in any medium, with or without modifications, and in Source or Object form,\n provided that You meet the following conditions:\n\n You must give any other recipients of the Work or Derivative Works a copy of\n this License; and\n You must cause any modified files to carry prominent notices stating that You\n changed the files; and\n You must retain, in the Source form of any Derivative Works that You distribute,\n all copyright, patent, trademark, and attribution notices from the Source form\n of the Work, excluding those notices that do not pertain to any part of the\n Derivative Works; and\n If the Work includes a \"NOTICE\" text file as part of its distribution, then any\n Derivative Works that You distribute must include a readable copy of the\n attribution notices contained within such NOTICE file, excluding those notices\n that do not pertain to any part of the Derivative Works, in at least one of the\n following places: within a NOTICE text file distributed as part of the\n Derivative Works; within the Source form or documentation, if provided along\n with the Derivative Works; or, within a display generated by the Derivative\n Works, if and wherever such third-party notices normally appear. The contents of\n the NOTICE file are for informational purposes only and do not modify the\n License. You may add Your own attribution notices within Derivative Works that\n You distribute, alongside or as an addendum to the NOTICE text from the Work,\n provided that such additional attribution notices cannot be construed as\n modifying the License.\n You may add Your own copyright statement to Your modifications and may provide\n additional or different license terms and conditions for use, reproduction, or\n distribution of Your modifications, or for any such Derivative Works as a whole,\n provided Your use, reproduction, and distribution of the Work otherwise complies\n with the conditions stated in this License.\n\n 5. Submission of Contributions.\n\n Unless You explicitly state otherwise, any Contribution intentionally submitted\n for inclusion in the Work by You to the Licensor shall be under the terms and\n conditions of this License, without any additional terms or conditions.\n Notwithstanding the above, nothing herein shall supersede or modify the terms of\n any separate license agreement you may have executed with Licensor regarding\n such Contributions.\n\n 6. Trademarks.\n\n This License does not grant permission to use the trade names, trademarks,\n service marks, or product names of the Licensor, except as required for\n reasonable and customary use in describing the origin of the Work and\n reproducing the content of the NOTICE file.\n\n 7. Disclaimer of Warranty.\n\n Unless required by applicable law or agreed to in writing, Licensor provides the\n Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied,\n including, without limitation, any warranties or conditions of TITLE,\n NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are\n solely responsible for determining the appropriateness of using or\n redistributing the Work and assume any risks associated with Your exercise of\n permissions under this License.\n\n 8. Limitation of Liability.\n\n In no event and under no legal theory, whether in tort (including negligence),\n contract, or otherwise, unless required by applicable law (such as deliberate\n and grossly negligent acts) or agreed to in writing, shall any Contributor be\n liable to You for damages, including any direct, indirect, special, incidental,\n or consequential damages of any character arising as a result of this License or\n out of the use or inability to use the Work (including but not limited to\n damages for loss of goodwill, work stoppage, computer failure or malfunction, or\n any and all other commercial damages or losses), even if such Contributor has\n been advised of the possibility of such damages.\n\n 9. Accepting Warranty or Additional Liability.\n\n While redistributing the Work or Derivative Works thereof, You may choose to\n offer, and charge a fee for, acceptance of support, warranty, indemnity, or\n other liability obligations and/or rights consistent with this License. However,\n in accepting such obligations, You may act only on Your own behalf and on Your\n sole responsibility, not on behalf of any other Contributor, and only if You\n agree to indemnify, defend, and hold each Contributor harmless for any liability\n incurred by, or claims asserted against, such Contributor by reason of your\n accepting any such warranty or additional liability.\n\n END OF TERMS AND CONDITIONS\n\n APPENDIX: How to apply the Apache License to your work\n\n To apply the Apache License to your work, attach the following boilerplate\n notice, with the fields enclosed by brackets \"[]\" replaced with your own\n identifying information. (Don't include the brackets!) The text should be\n enclosed in the appropriate comment syntax for the file format. We also\n recommend that a file or class name and description of purpose be included on\n the same \"printed page\" as the copyright notice for easier identification within\n third-party archives.\n\n    Copyright [yyyy] [name of copyright owner]\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n      http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Science/Research",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Cython",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Topic :: Scientific/Engineering"
        ],
        "requires_dist": [
          "numpy>=1.22.4; python_version < \"3.11\"",
          "numpy>=1.23.2; python_version == \"3.11\"",
          "numpy>=1.26.0; python_version >= \"3.12\"",
          "python-dateutil>=2.8.2",
          "pytz>=2020.1",
          "tzdata>=2022.7",
          "hypothesis>=6.46.1; extra == \"test\"",
          "pytest>=7.3.2; extra == \"test\"",
          "pytest-xdist>=2.2.0; extra == \"test\"",
          "pyarrow>=10.0.1; extra == \"pyarrow\"",
          "bottleneck>=1.3.6; extra == \"performance\"",
          "numba>=0.56.4; extra == \"performance\"",
          "numexpr>=2.8.4; extra == \"performance\"",
          "scipy>=1.10.0; extra == \"computation\"",
          "xarray>=2022.12.0; extra == \"computation\"",
          "fsspec>=2022.11.0; extra == \"fss\"",
          "s3fs>=2022.11.0; extra == \"aws\"",
          "gcsfs>=2022.11.0; extra == \"gcp\"",
          "pandas-gbq>=0.19.0; extra == \"gcp\"",
          "odfpy>=1.4.1; extra == \"excel\"",
          "openpyxl>=3.1.0; extra == \"excel\"",
          "python-calamine>=0.1.7; extra == \"excel\"",
          "pyxlsb>=1.0.10; extra == \"excel\"",
          "xlrd>=2.0.1; extra == \"excel\"",
          "xlsxwriter>=3.0.5; extra == \"excel\"",
          "pyarrow>=10.0.1; extra == \"parquet\"",
          "pyarrow>=10.0.1; extra == \"feather\"",
          "tables>=3.8.0; extra == \"hdf5\"",
          "pyreadstat>=1.2.0; extra == \"spss\"",
          "SQLAlchemy>=2.0.0; extra == \"postgresql\"",
          "psycopg2>=2.9.6; extra == \"postgresql\"",
          "adbc-driver-postgresql>=0.8.0; extra == \"postgresql\"",
          "SQLAlchemy>=2.0.0; extra == \"mysql\"",
          "pymysql>=1.0.2; extra == \"mysql\"",
          "SQLAlchemy>=2.0.0; extra == \"sql-other\"",
          "adbc-driver-postgresql>=0.8.0; extra == \"sql-other\"",
          "adbc-driver-sqlite>=0.8.0; extra == \"sql-other\"",
          "beautifulsoup4>=4.11.2; extra == \"html\"",
          "html5lib>=1.1; extra == \"html\"",
          "lxml>=4.9.2; extra == \"html\"",
          "lxml>=4.9.2; extra == \"xml\"",
          "matplotlib>=3.6.3; extra == \"plot\"",
          "jinja2>=3.1.2; extra == \"output-formatting\"",
          "tabulate>=0.9.0; extra == \"output-formatting\"",
          "PyQt5>=5.15.9; extra == \"clipboard\"",
          "qtpy>=2.3.0; extra == \"clipboard\"",
          "zstandard>=0.19.0; extra == \"compression\"",
          "dataframe-api-compat>=0.1.7; extra == \"consortium-standard\"",
          "adbc-driver-postgresql>=0.8.0; extra == \"all\"",
          "adbc-driver-sqlite>=0.8.0; extra == \"all\"",
          "beautifulsoup4>=4.11.2; extra == \"all\"",
          "bottleneck>=1.3.6; extra == \"all\"",
          "dataframe-api-compat>=0.1.7; extra == \"all\"",
          "fastparquet>=2022.12.0; extra == \"all\"",
          "fsspec>=2022.11.0; extra == \"all\"",
          "gcsfs>=2022.11.0; extra == \"all\"",
          "html5lib>=1.1; extra == \"all\"",
          "hypothesis>=6.46.1; extra == \"all\"",
          "jinja2>=3.1.2; extra == \"all\"",
          "lxml>=4.9.2; extra == \"all\"",
          "matplotlib>=3.6.3; extra == \"all\"",
          "numba>=0.56.4; extra == \"all\"",
          "numexpr>=2.8.4; extra == \"all\"",
          "odfpy>=1.4.1; extra == \"all\"",
          "openpyxl>=3.1.0; extra == \"all\"",
          "pandas-gbq>=0.19.0; extra == \"all\"",
          "psycopg2>=2.9.6; extra == \"all\"",
          "pyarrow>=10.0.1; extra == \"all\"",
          "pymysql>=1.0.2; extra == \"all\"",
          "PyQt5>=5.15.9; extra == \"all\"",
          "pyreadstat>=1.2.0; extra == \"all\"",
          "pytest>=7.3.2; extra == \"all\"",
          "pytest-xdist>=2.2.0; extra == \"all\"",
          "python-calamine>=0.1.7; extra == \"all\"",
          "pyxlsb>=1.0.10; extra == \"all\"",
          "qtpy>=2.3.0; extra == \"all\"",
          "scipy>=1.10.0; extra == \"all\"",
          "s3fs>=2022.11.0; extra == \"all\"",
          "SQLAlchemy>=2.0.0; extra == \"all\"",
          "tables>=3.8.0; extra == \"all\"",
          "tabulate>=0.9.0; extra == \"all\"",
          "xarray>=2022.12.0; extra == \"all\"",
          "xlrd>=2.0.1; extra == \"all\"",
          "xlsxwriter>=3.0.5; extra == \"all\"",
          "zstandard>=0.19.0; extra == \"all\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "homepage, https://pandas.pydata.org",
          "documentation, https://pandas.pydata.org/docs/",
          "repository, https://github.com/pandas-dev/pandas"
        ],
        "provides_extra": [
          "test",
          "pyarrow",
          "performance",
          "computation",
          "fss",
          "aws",
          "gcp",
          "excel",
          "parquet",
          "feather",
          "hdf5",
          "spss",
          "postgresql",
          "mysql",
          "sql-other",
          "html",
          "xml",
          "plot",
          "output-formatting",
          "clipboard",
          "compression",
          "consortium-standard",
          "all"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/pandas-2.3.3.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "snowplow-tracker",
        "version": "1.1.0",
        "summary": "Snowplow event tracker for Python. Add analytics to your Python and Django apps, webapps and games",
        "description": "Python Analytics for Snowplow\n=============================\n\n[![Early Release](https://img.shields.io/static/v1?style=flat&label=Snowplow&message=Early%20Release&color=014477&labelColor=9ba0aa&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAAeFBMVEVMaXGXANeYANeXANZbAJmXANeUANSQAM+XANeMAMpaAJhZAJeZANiXANaXANaOAM2WANVnAKWXANZ9ALtmAKVaAJmXANZaAJlXAJZdAJxaAJlZAJdbAJlbAJmQAM+UANKZANhhAJ+EAL+BAL9oAKZnAKVjAKF1ALNBd8J1AAAAKHRSTlMAa1hWXyteBTQJIEwRgUh2JjJon21wcBgNfmc+JlOBQjwezWF2l5dXzkW3/wAAAHpJREFUeNokhQOCA1EAxTL85hi7dXv/E5YPCYBq5DeN4pcqV1XbtW/xTVMIMAZE0cBHEaZhBmIQwCFofeprPUHqjmD/+7peztd62dWQRkvrQayXkn01f/gWp2CrxfjY7rcZ5V7DEMDQgmEozFpZqLUYDsNwOqbnMLwPAJEwCopZxKttAAAAAElFTkSuQmCC)](https://docs.snowplow.io/docs/collecting-data/collecting-from-own-applications/tracker-maintenance-classification/)[![Build Status](https://github.com/snowplow/snowplow-python-tracker/actions/workflows/ci.yml/badge.svg)](https://github.com/snowplow/snowplow-python-tracker/actions)[![Test Coverage](https://img.shields.io/coveralls/github/snowplow/snowplow-python-tracker)](https://coveralls.io/github/snowplow/snowplow-python-tracker?branch=master) [![image](http://img.shields.io/badge/license-Apache--2-blue.svg?style=flat)](http://www.apache.org/licenses/LICENSE-2.0)\n\n\n[![Pypi Snowplow Tracker](https://img.shields.io/pypi/v/snowplow-tracker)](https://pypi.org/project/snowplow-tracker/)[![Python Versions](https://img.shields.io/pypi/pyversions/snowplow-tracker)](https://pypi.org/project/snowplow-tracker/)[![Monthly Downloads](https://img.shields.io/pypi/dm/snowplow-tracker)](https://pypi.org/project/snowplow-tracker/)\n\nOverview\n--------\n\nAdd analytics to your Python apps and Python games with the\n[Snowplow](http://snowplow.io) event tracker for\n[Python](http://python.org).\n\nWith this tracker you can collect event data from your Python-based\napplications, games or Python web servers/frameworks.\n\nFind out more\n-------------\n\n  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\n  | Snowplow Docs | API Docs  | Contributing |\n  |     :----:     |     :----:   |     :----:   |\n  | ![techdocs](https://d3i6fms1cm1j0i.cloudfront.net/github/images/techdocs.png) | ![setup](https://d3i6fms1cm1j0i.cloudfront.net/github/images/setup.png) |                                                ![contributing](https://d3i6fms1cm1j0i.cloudfront.net/github/images/contributing.png) |\n  | [Snowplow Docs](https://docs.snowplow.io/docs/collecting-data/collecting-from-own-applications/python-tracker/) | [API Docs](https://snowplow.github.io/snowplow-python-tracker/index.html)| [Contributing](https://github.com/snowplow/snowplow-python-tracker/blob/master/CONTRIBUTING.md) |                                                                              \n  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nPython Support\n--------------\n\n| Python version | snowplow-tracker version |\n|     :----:     |     :----:               |\n| \\>=3.8         | > 1.1.0                 |\n| \\>=3.5         | > 0.10.0                 |\n| 2.7            | > 0.9.1                  |\n\nMaintainer Quickstart\n---------------------\n\nAssuming [docker](https://www.docker.com/) is installed\n\n    host$ git clone git@github.com:snowplow/snowplow-python-tracker.git\n    host$ cd snowplow-python-tracker\n    host$ docker build -t snowplow-python-tracker . && docker run snowplow-python-tracker\n\nCopyright and license\n---------------------\n\nThe Snowplow Python Tracker is copyright 2013-2023 Snowplow Analytics\nLtd.\n\nLicensed under the [Apache License, Version\n2.0](http://www.apache.org/licenses/LICENSE-2.0) (the \\\"License\\\"); you\nmay not use this software except in compliance with the License.\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \\\"AS IS\\\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n",
        "description_content_type": "text/markdown",
        "home_page": "http://snowplow.io",
        "author": "Anuj More, Alexander Dean, Fred Blundun, Paul Boocock, Matus Tomlein, Jack Keene",
        "author_email": "support@snowplow.io",
        "license": "Apache License 2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Operating System :: OS Independent"
        ],
        "requires_dist": [
          "requests<3.0,>=2.25.1",
          "typing-extensions>=3.7.4",
          "mypy>=0.971; extra == \"typing\"",
          "types-requests<3.0,>=2.25.1; extra == \"typing\""
        ],
        "provides_extra": [
          "typing"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/snowplow_tracker-1.1.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "parsedatetime",
        "version": "2.6",
        "platform": [
          "Any"
        ],
        "summary": "Parse human-readable date/time text.",
        "description": "parsedatetime\n=============\n\nParse human-readable date/time strings.\n\nPython 2.6 or greater is required for parsedatetime version 1.0 or greater.\n\nWhile we still test with Python 2.6 we cannot guarantee that future changes will not break under 2.6\n\n.. image:: https://img.shields.io/pypi/v/parsedatetime.svg\n    :target: https://pypi.python.org/pypi/parsedatetime/\n    :alt: Downloads\n\n.. image:: https://travis-ci.org/bear/parsedatetime.svg?branch=master\n    :target: https://travis-ci.org/bear/parsedatetime\n    :alt: Travis CI\n\n.. image:: http://codecov.io/github/bear/parsedatetime/coverage.svg?branch=master\n    :target: http://codecov.io/github/bear/parsedatetime\n    :alt: Codecov\n\n.. image:: https://requires.io/github/bear/parsedatetime/requirements.svg?branch=master\n     :target: https://requires.io/github/bear/parsedatetime/requirements/?branch=master\n     :alt: Requirements Status\n\n.. image:: https://dependencyci.com/github/bear/parsedatetime/badge\n     :target: https://dependencyci.com/github/bear/parsedatetime\n     :alt: Dependency Status\n\n==========\nInstalling\n==========\n\nYou can install parsedatetime using::\n\n    pip install parsedatetime\n\n=============\nRunning Tests\n=============\n\nFrom the source directory::\n\n    make test\n\nTo run tests on several python versions, type ``make tox``::\n\n  $ make tox\n  [... tox creates a virtualenv for every python version and runs tests inside of each]\n  py27: commands succeeded\n  py35: commands succeeded\n\nThis assumes that you have the versions you want to test under installed as part of your\nPyEnv environment::\n\n    pyenv install -s 2.6.9\n    pyenv install -s 2.7.11\n    pyenv install -s 3.5.2\n    pyenv install -s pypy-5.3\n    pyenv global 2.7.11 3.5.2 2.6.9 pypy-5.3\n\nThe tests depend on PyICU being installed using the `pyicu-binary` package which removes the source build step. PyICU depends on icu4c which on macOS requires homebrew::\n\n    brew install icu4c\n\nThe Makefile contains the macOS default values for them so you may need to tweak them.\n\n===================\nUsing parsedatetime\n===================\n\nAn example of how to use parsedatetime:\n\n\n.. code:: python\n\n    import parsedatetime\n\n    cal = parsedatetime.Calendar()\n\n    cal.parse(\"tomorrow\")\n\nTo get it to a Python ``datetime`` object:\n\n\n.. code:: python\n\n    from datetime import datetime\n\n    time_struct, parse_status = cal.parse(\"tomorrow\")\n\n    datetime(*time_struct[:6])\n\nParse datetime with timezone support (using pytz package):\n\n.. code:: python\n\n    import parsedatetime\n    import pytz\n    from pytz import timezone\n\n    cal = parsedatetime.Calendar()\n\n    datetime_obj, _ = cal.parseDT(datetimeString=\"tomorrow\", tzinfo=timezone(\"US/Pacific\"))\n\nMore detailed examples can be found in the examples directory.\n\n=============\nDocumentation\n=============\n\nThe generated documentation is included by default in the docs directory and can also be viewed online at https://bear.im/code/parsedatetime/docs/index.html\n\nThe docs can be generated by running::\n\n    make docs\n\n=====\nNotes\n=====\n\nThe ``Calendar`` class has a member property named ``ptc`` which is created during the class init method to be an instance\nof ``parsedatetime_consts.CalendarConstants()``.\n\n=======\nHistory\n=======\n\nThe code in parsedatetime has been implemented over the years in many different languages (C, Clipper, Delphi) as part of different custom/proprietary systems I've worked on.  Sadly the previous code is not \"open\" in any sense of that word.\n\nWhen I went to work for Open Source Applications Foundation and realized that the Chandler project could benefit from my experience with parsing of date/time text I decided to start from scratch and implement the code using Python and make it truly open.\n\nAfter working on the initial concept and creating something that could be shown to the Chandler folks, the code has now evolved to its current state with the help of the Chandler folks, most especially Darshana.\n\n\n",
        "home_page": "https://github.com/bear/parsedatetime",
        "download_url": "https://pypi.python.org/pypi/parsedatetime",
        "author": "Mike Taylor",
        "author_email": "bear@bear.im",
        "license": "Apache License 2.0",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Operating System :: OS Independent",
          "Topic :: Text Processing",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/parsedatetime-2.6.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "orderly-set",
        "version": "5.5.0",
        "summary": "Orderly set",
        "description": "# Orderly Set 5.5.0\n\nOrderly Set is a package containing multiple implementations of Ordered Set.\n\n\n## OrderlySet\n\nThis implementation keeps the order in all set operations except set difference operations.\nAs a result, it can do set difference operations much faster than other implementations. Still 2X slower than of Python's built-in set.\n\n\n## StableSet\n\nA StableSet is a mutable set that remembers its insertion order.\nFeaturing: Fast O(1) insertion, deletion, iteration and membership testing.\nBut slow O(N) Index Lookup.\n\n## StableSetEq\n\nSame as StableSet but the order of items doesn't matter for equality comparisons.\n\n## OrderedSet\n\nAn OrderedSet is a mutable data structure that is a hybrid of a list and a set.\nIt remembers its insertion order so that every entry has an index that can be looked up. \nFeaturing: O(1) Index lookup, insertion, iteration and membership testing.\nBut slow O(N) Deletion.\n\n\n## SortedSet\n\nSortedSet is basically set but when printed, turned into string, or iterated over, returns the items in alphabetical order.\n\n# Installation\n\n`pip install orderly-set`\n\n# Usage examples\n\nAn OrderedSet is created and used like a set:\n\n    >>> from orderly_set import OrderedSet\n\n    >>> letters = OrderedSet('abracadabra')\n\n    >>> letters\n    OrderedSet(['a', 'b', 'r', 'c', 'd'])\n\n    >>> 'r' in letters\n    True\n\nIt is efficient to find the index of an entry in an OrderedSet, or find an\nentry by its index. To help with this use case, the `.add()` method returns\nthe index of the added item, whether it was already in the set or not.\n\n    >>> letters.index('r')\n    2\n\n    >>> letters[2]\n    'r'\n\n    >>> letters.add('r')\n    2\n\n    >>> letters.add('x')\n    5\n\nOrderedSets implement the union (`|`), intersection (`&`), and difference (`-`)\noperators like sets do.\n\n    >>> letters |= OrderedSet('shazam')\n\n    >>> letters\n    OrderedSet(['a', 'b', 'r', 'c', 'd', 'x', 's', 'h', 'z', 'm'])\n\n    >>> letters & set('aeiou')\n    OrderedSet(['a'])\n\n    >>> letters -= 'abcd'\n\n    >>> letters\n    OrderedSet(['r', 'x', 's', 'h', 'z', 'm'])\n\nThe `__getitem__()` method has been extended to accept any\niterable except a string, returning a list, to perform NumPy-like \"fancy\nindexing\".\n\n    >>> letters = OrderedSet('abracadabra')\n\n    >>> letters[[0, 2, 3]]\n    ['a', 'r', 'c']\n\n    >>> letters.indexes(['a', 'r', 'c'])\n    [0, 2, 3]\n\nOrderedSet implements `__getstate__` and `__setstate__` so it can be pickled,\nand implements the abstract base classes `collections.MutableSet` and\n`collections.Sequence`.\n\nOrderedSet can be used as a generic collection type, similar to the collections\nin the `typing` module like List, Dict, and Set. For example, you can annotate\na variable as having the type `OrderedSet[str]` or `OrderedSet[Tuple[int,\nstr]]`.\n\n\n# Authors\n\nPlease check the [Authors](AUTHORS.md) file.\n\n# Comparisons\n\n```\n-- initialize a set --\nUsing Python dict time: 4.13\nset time: 2.98\nordered_set.OrderedSet time: 15.77\norderly_set.OrderedSet time: 15.25\nStableSet time: 4.78\nOrderlySet time: 4.38\nSortedSet time: 3.09\n\n-- update a set --\nUsing Python dict: 6.77\nset time: 2.46\nordered_set.OrderedSet time: 10.17\norderly_set.OrderedSet time: 10.06\nStableSet time: 7.16\nOrderlySet time: 6.77\nSortedSet time: 2.46\n\n-- update a set and get item --\nordered_set.OrderedSet time: 29.98\norderly_set.OrderedSet time: 29.57\nStableSet time: 14.31\nOrderlySet time: 14.23\nSortedSet time: 9.03\n\n-- set symmetric difference (xor) --\nset time: 5.368663903005654\nordered_set.OrderedSet time: 39.25\norderly_set.OrderedSet time: 80.31\nStableSet time: 42.81\nOrderlySet time: 11.44\nSortedSet time: 3.87\n\n-- set difference (-) --\nset time: 3.7398674299911363\nordered_set.OrderedSet time: 22.39\norderly_set.OrderedSet time: 38.00\nStableSet time: 22.30\nOrderlySet time: 8.92\nSortedSet time: 3.03\n```\n\nDespite what you see in the benchmarks, in DeepDiff OrderlySet performed better than SortedSet.\n\n\nA StableSet is a mutable set that remembers its insertion order.\nFeaturing: Fast O(1) insertion, deletion, iteration and membership testing.\nBut slow O(N) Index Lookup.\n\nAn OrderedSet is a mutable data structure that is a hybrid of a list and a set.\nIt remembers its insertion order so that every entry has an index that can be looked up. \nFeaturing: O(1) Index lookup, insertion, iteration and membership testing.\nBut slow O(N) Deletion.\n\nBoth have similar interfaces but differ in respect of their implementation and performance.\n\nThe original implementation of OrderedSet was a [recipe posted to ActiveState\nRecipes][recipe] by Raymond Hettiger, released under the MIT license.\n\n[recipe]: https://code.activestate.com/recipes/576694-orderedset/\n\nHettiger's implementation kept its content in a doubly-linked list referenced by a\ndict. As a result, looking up an item by its index was an O(N) operation, while\ndeletion was O(1).\n\nThis version of OrderedSet makes different trade-offs for the sake of efficient lookups. \nIts content is a standard Python list instead of a doubly-linked list. This\nprovides O(1) lookups by index at the expense of O(N) deletion, as well as\nslightly faster iteration.\n\n",
        "description_content_type": "text/markdown",
        "author_email": "Seperman <sep@zepworks.com>",
        "license_file": [
          "MIT-LICENSE"
        ],
        "classifier": [
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Topic :: Software Development",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Development Status :: 5 - Production/Stable",
          "License :: OSI Approved :: MIT License"
        ],
        "requires_dist": [
          "coverage~=7.6.0 ; extra == \"coverage\"",
          "bump2version~=1.0.0 ; extra == \"dev\"",
          "ipdb~=0.13.0 ; extra == \"dev\"",
          "orjson ; extra == \"optimize\"",
          "flake8~=7.1.0 ; extra == \"static\"",
          "flake8-pyproject~=1.2.3 ; extra == \"static\"",
          "pytest~=8.3.0 ; extra == \"test\"",
          "pytest-benchmark~=5.1.0 ; extra == \"test\"",
          "pytest-cov~=6.0.0 ; extra == \"test\"",
          "python-dotenv~=1.0.0 ; extra == \"test\""
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Download, https://github.com/seperman/orderly-set/tarball/master",
          "Homepage, https://github.com/seperman/orderly-set"
        ],
        "provides_extra": [
          "coverage",
          "dev",
          "optimize",
          "static",
          "test"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/orderly_set-5.5.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "pydantic_core",
        "version": "2.41.5",
        "summary": "Core functionality for Pydantic validation and serialization",
        "description": "# pydantic-core\n\n[![CI](https://github.com/pydantic/pydantic-core/workflows/ci/badge.svg?event=push)](https://github.com/pydantic/pydantic-core/actions?query=event%3Apush+branch%3Amain+workflow%3Aci)\n[![Coverage](https://codecov.io/gh/pydantic/pydantic-core/branch/main/graph/badge.svg)](https://codecov.io/gh/pydantic/pydantic-core)\n[![pypi](https://img.shields.io/pypi/v/pydantic-core.svg)](https://pypi.python.org/pypi/pydantic-core)\n[![versions](https://img.shields.io/pypi/pyversions/pydantic-core.svg)](https://github.com/pydantic/pydantic-core)\n[![license](https://img.shields.io/github/license/pydantic/pydantic-core.svg)](https://github.com/pydantic/pydantic-core/blob/main/LICENSE)\n\nThis package provides the core functionality for [pydantic](https://docs.pydantic.dev) validation and serialization.\n\nPydantic-core is currently around 17x faster than pydantic V1.\nSee [`tests/benchmarks/`](./tests/benchmarks/) for details.\n\n## Example of direct usage\n\n_NOTE: You should not need to use pydantic-core directly; instead, use pydantic, which in turn uses pydantic-core._\n\n```py\nfrom pydantic_core import SchemaValidator, ValidationError\n\n\nv = SchemaValidator(\n    {\n        'type': 'typed-dict',\n        'fields': {\n            'name': {\n                'type': 'typed-dict-field',\n                'schema': {\n                    'type': 'str',\n                },\n            },\n            'age': {\n                'type': 'typed-dict-field',\n                'schema': {\n                    'type': 'int',\n                    'ge': 18,\n                },\n            },\n            'is_developer': {\n                'type': 'typed-dict-field',\n                'schema': {\n                    'type': 'default',\n                    'schema': {'type': 'bool'},\n                    'default': True,\n                },\n            },\n        },\n    }\n)\n\nr1 = v.validate_python({'name': 'Samuel', 'age': 35})\nassert r1 == {'name': 'Samuel', 'age': 35, 'is_developer': True}\n\n# pydantic-core can also validate JSON directly\nr2 = v.validate_json('{\"name\": \"Samuel\", \"age\": 35}')\nassert r1 == r2\n\ntry:\n    v.validate_python({'name': 'Samuel', 'age': 11})\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for model\n    age\n      Input should be greater than or equal to 18\n      [type=greater_than_equal, context={ge: 18}, input_value=11, input_type=int]\n    \"\"\"\n```\n\n## Getting Started\n\n### Prerequisites\n\nYou'll need:\n1. **[Rust](https://rustup.rs/)** - Rust stable (or nightly for coverage)\n2. **[uv](https://docs.astral.sh/uv/getting-started/installation/)** - Fast Python package manager (will install Python 3.9+ automatically)\n3. **[git](https://git-scm.com/)** - For version control\n4. **[make](https://www.gnu.org/software/make/)** - For running development commands (or use `nmake` on Windows)\n\n### Quick Start\n\n```bash\n# Clone the repository (or from your fork)\ngit clone git@github.com:pydantic/pydantic-core.git\ncd pydantic-core\n\n# Install all dependencies using uv, setup pre-commit hooks, and build the development version\nmake install\n```\n\nVerify your installation by running:\n\n```bash\nmake\n```\n\nThis runs a full development cycle: formatting, building, linting, and testing\n\n### Development Commands\n\nRun `make help` to see all available commands, or use these common ones:\n\n```bash\nmake build-dev    # to build the package during development\nmake build-prod   # to perform an optimised build for benchmarking\nmake test         # to run the tests\nmake testcov      # to run the tests and generate a coverage report\nmake lint         # to run the linter\nmake format       # to format python and rust code\nmake all          # to run to run build-dev + format + lint + test\n```\n\n### Useful Resources\n\n* [`python/pydantic_core/_pydantic_core.pyi`](./python/pydantic_core/_pydantic_core.pyi) - Python API types\n* [`python/pydantic_core/core_schema.py`](./python/pydantic_core/core_schema.py) - Core schema definitions\n* [`tests/`](./tests) - Comprehensive usage examples\n\n## Profiling\n\nIt's possible to profile the code using the [`flamegraph` utility from `flamegraph-rs`](https://github.com/flamegraph-rs/flamegraph). (Tested on Linux.) You can install this with `cargo install flamegraph`.\n\nRun `make build-profiling` to install a release build with debugging symbols included (needed for profiling).\n\nOnce that is built, you can profile pytest benchmarks with (e.g.):\n\n```bash\nflamegraph -- pytest tests/benchmarks/test_micro_benchmarks.py -k test_list_of_ints_core_py --benchmark-enable\n```\nThe `flamegraph` command will produce an interactive SVG at `flamegraph.svg`.\n\n## Releasing\n\n1. Bump package version locally. Do not just edit `Cargo.toml` on Github, you need both `Cargo.toml` and `Cargo.lock` to be updated.\n2. Make a PR for the version bump and merge it.\n3. Go to https://github.com/pydantic/pydantic-core/releases and click \"Draft a new release\"\n4. In the \"Choose a tag\" dropdown enter the new tag `v<the.new.version>` and select \"Create new tag on publish\" when the option appears.\n5. Enter the release title in the form \"v<the.new.version> <YYYY-MM-DD>\"\n6. Click Generate release notes button\n7. Click Publish release\n8. Go to https://github.com/pydantic/pydantic-core/actions and ensure that all build for release are done successfully.\n9. Go to https://pypi.org/project/pydantic-core/ and ensure that the latest release is published.\n10. Done ðŸŽ‰\n\n",
        "description_content_type": "text/markdown; charset=UTF-8; variant=GFM",
        "home_page": "https://github.com/pydantic/pydantic-core",
        "author_email": "Samuel Colvin <s@muelcolvin.com>, Adrian Garcia Badaracco <1755071+adriangb@users.noreply.github.com>, David Montague <david@pydantic.dev>, David Hewitt <mail@davidhewitt.dev>, Sydney Runkle <sydneymarierunkle@gmail.com>, Victorien Plot <contact@vctrn.dev>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Programming Language :: Python :: Implementation :: GraalPy",
          "Programming Language :: Rust",
          "Framework :: Pydantic",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "Operating System :: POSIX :: Linux",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: MacOS",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "typing-extensions>=4.14.1"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/pydantic/pydantic-core",
          "Funding, https://github.com/sponsors/samuelcolvin",
          "Source, https://github.com/pydantic/pydantic-core"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/pydantic_core-2.41.5.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "typing-inspection",
        "version": "0.4.2",
        "summary": "Runtime typing introspection tools",
        "description": "# typing-inspection\n\n[![CI](https://img.shields.io/github/actions/workflow/status/pydantic/typing-inspection/ci.yml?branch=main&logo=github&label=CI)](https://github.com/pydantic/typing-inspection/actions?query=event%3Apush+branch%3Amain+workflow%3ACI)\n[![Coverage](https://coverage-badge.samuelcolvin.workers.dev/pydantic/typing-inspection.svg)](https://coverage-badge.samuelcolvin.workers.dev/redirect/pydantic/typing-inspection)\n[![PyPI](https://img.shields.io/pypi/v/typing-inspection.svg)](https://pypi.org/project/typing-inspection/)\n[![Versions](https://img.shields.io/pypi/pyversions/typing-inspection.svg)](https://github.com/pydantic/typing-inspection)\n[![License](https://img.shields.io/github/license/pydantic/typing-inspection.svg)](https://github.com/pydantic/typing-inspection/blob/main/LICENSE)\n[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)\n\n`typing-inspection` provides tools to inspect type annotations at runtime.\n\n## Installation\n\nFrom [PyPI](https://pypi.org/project/typing-inspection/):\n\n```bash\npip install typing-inspection\n```\n\nThe library can be imported from the `typing_inspection` module.\n",
        "description_content_type": "text/markdown",
        "author_email": "Victorien Plot <contact@vctrn.dev>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Intended Audience :: Developers",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "typing-extensions>=4.12.0"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/pydantic/typing-inspection",
          "Documentation, https://pydantic.github.io/typing-inspection/dev/",
          "Source, https://github.com/pydantic/typing-inspection",
          "Changelog, https://github.com/pydantic/typing-inspection/blob/main/HISTORY.md"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/typing_inspection-0.4.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.0",
        "name": "text-unidecode",
        "version": "1.3",
        "platform": [
          "UNKNOWN"
        ],
        "summary": "The most basic Text::Unidecode port",
        "description": "Text-Unidecode\n==============\n\n.. image:: https://travis-ci.org/kmike/text-unidecode.svg?branch=master\n    :target: https://travis-ci.org/kmike/text-unidecode\n    :alt: Build Status\n\ntext-unidecode is the most basic port of the\n`Text::Unidecode <http://search.cpan.org/~sburke/Text-Unidecode-0.04/lib/Text/Unidecode.pm>`_\nPerl library.\n\nThere are other Python ports of Text::Unidecode (unidecode_\nand isounidecode_). unidecode_ is GPL; isounidecode_ uses too much memory,\nand it didn't support Python 3 when this package was created.\n\nYou can redistribute it and/or modify this port under the terms of either:\n\n* `Artistic License`_, or\n* GPL or GPLv2+\n\nIf you're OK with GPL-only, use unidecode_ (it has better memory usage and\nbetter transliteration quality).\n\n``text-unidecode`` supports Python 2.7 and 3.4+.\n\n.. _unidecode: https://pypi.python.org/pypi/Unidecode/\n.. _isounidecode: https://pypi.python.org/pypi/isounidecode/\n.. _Artistic License: https://opensource.org/licenses/Artistic-Perl-1.0\n\nInstallation\n------------\n\n::\n\n    pip install text-unidecode\n\nUsage\n-----\n\n::\n\n    >>> from text_unidecode import unidecode\n    >>> unidecode(u'ÐºÐ°ÐºÐ¾Ð¹-Ñ‚Ð¾ Ñ‚ÐµÐºÑÑ‚')\n    'kakoi-to tekst'\n\n\n",
        "home_page": "https://github.com/kmike/text-unidecode/",
        "author": "Mikhail Korobov",
        "author_email": "kmike84@gmail.com",
        "license": "Artistic License",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Artistic License",
          "License :: OSI Approved :: GNU General Public License (GPL)",
          "License :: OSI Approved :: GNU General Public License v2 or later (GPLv2+)",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Text Processing :: Linguistic"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/text_unidecode-1.3.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.2",
        "name": "babel",
        "version": "2.17.0",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "home-page",
          "license",
          "maintainer",
          "maintainer-email",
          "project-url",
          "provides-extra",
          "requires-dist",
          "requires-python",
          "summary"
        ],
        "summary": "Internationalization utilities",
        "description": "A collection of tools for internationalizing Python applications.\n",
        "home_page": "https://babel.pocoo.org/",
        "author": "Armin Ronacher",
        "author_email": "armin.ronacher@active-4.com",
        "maintainer": "Aarni Koskela",
        "maintainer_email": "akx@iki.fi",
        "license": "BSD-3-Clause",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "pytz>=2015.7; python_version < \"3.9\"",
          "tzdata; sys_platform == \"win32\" and extra == \"dev\"",
          "backports.zoneinfo; python_version < \"3.9\" and extra == \"dev\"",
          "freezegun~=1.0; extra == \"dev\"",
          "jinja2>=3.0; extra == \"dev\"",
          "pytest-cov; extra == \"dev\"",
          "pytest>=6.0; extra == \"dev\"",
          "pytz; extra == \"dev\"",
          "setuptools; extra == \"dev\""
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Source, https://github.com/python-babel/babel"
        ],
        "provides_extra": [
          "dev"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/babel-2.17.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "pytz",
        "version": "2025.2",
        "platform": [
          "Independent"
        ],
        "summary": "World timezone definitions, modern and historical",
        "description": "pytz - World Timezone Definitions for Python\n============================================\n\n:Author: Stuart Bishop <stuart@stuartbishop.net>\n\nIntroduction\n~~~~~~~~~~~~\n\npytz brings the Olson tz database into Python. This library allows\naccurate and cross platform timezone calculations using Python 2.4\nor higher. It also solves the issue of ambiguous times at the end\nof daylight saving time, which you can read more about in the Python\nLibrary Reference (``datetime.tzinfo``).\n\nAlmost all of the Olson timezones are supported.\n\n.. note::\n\n    Projects using Python 3.9 or later should be using the support\n    now included as part of the standard library, and third party\n    packages work with it such as `tzdata <https://pypi.org/project/tzdata/>`_.\n    pytz offers no advantages beyond backwards compatibility with\n    code written for earlier versions of Python.\n\n.. note::\n\n    This library differs from the documented Python API for\n    tzinfo implementations; if you want to create local wallclock\n    times you need to use the ``localize()`` method documented in this\n    document. In addition, if you perform date arithmetic on local\n    times that cross DST boundaries, the result may be in an incorrect\n    timezone (ie. subtract 1 minute from 2002-10-27 1:00 EST and you get\n    2002-10-27 0:59 EST instead of the correct 2002-10-27 1:59 EDT). A\n    ``normalize()`` method is provided to correct this. Unfortunately these\n    issues cannot be resolved without modifying the Python datetime\n    implementation (see PEP-431).\n\n\nInstallation\n~~~~~~~~~~~~\n\nThis package can either be installed using ``pip`` or from a tarball using the\nstandard Python distutils.\n\nIf you are installing using ``pip``, you don't need to download anything as the\nlatest version will be downloaded for you from PyPI::\n\n    pip install pytz\n\nIf you are installing from a tarball, run the following command as an\nadministrative user::\n\n    python setup.py install\n\n\npytz for Enterprise\n~~~~~~~~~~~~~~~~~~~\n\nAvailable as part of the Tidelift Subscription.\n\nThe maintainers of pytz and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. `Learn more. <https://tidelift.com/subscription/pkg/pypi-pytz?utm_source=pypi-pytz&utm_medium=referral&utm_campaign=enterprise&utm_term=repo>`_.\n\n\nExample & Usage\n~~~~~~~~~~~~~~~\n\nLocalized times and date arithmetic\n-----------------------------------\n\n>>> from datetime import datetime, timedelta\n>>> from pytz import timezone\n>>> import pytz\n>>> utc = pytz.utc\n>>> utc.zone\n'UTC'\n>>> eastern = timezone('US/Eastern')\n>>> eastern.zone\n'US/Eastern'\n>>> amsterdam = timezone('Europe/Amsterdam')\n>>> fmt = '%Y-%m-%d %H:%M:%S %Z%z'\n\nThis library only supports two ways of building a localized time. The\nfirst is to use the ``localize()`` method provided by the pytz library.\nThis is used to localize a naive datetime (datetime with no timezone\ninformation):\n\n>>> loc_dt = eastern.localize(datetime(2002, 10, 27, 6, 0, 0))\n>>> print(loc_dt.strftime(fmt))\n2002-10-27 06:00:00 EST-0500\n\nThe second way of building a localized time is by converting an existing\nlocalized time using the standard ``astimezone()`` method:\n\n>>> ams_dt = loc_dt.astimezone(amsterdam)\n>>> ams_dt.strftime(fmt)\n'2002-10-27 12:00:00 CET+0100'\n\nUnfortunately using the tzinfo argument of the standard datetime\nconstructors ''does not work'' with pytz for many timezones.\n\n>>> datetime(2002, 10, 27, 12, 0, 0, tzinfo=amsterdam).strftime(fmt)  # /!\\ Does not work this way!\n'2002-10-27 12:00:00 LMT+0018'\n\nIt is safe for timezones without daylight saving transitions though, such\nas UTC:\n\n>>> datetime(2002, 10, 27, 12, 0, 0, tzinfo=pytz.utc).strftime(fmt)  # /!\\ Not recommended except for UTC\n'2002-10-27 12:00:00 UTC+0000'\n\nThe preferred way of dealing with times is to always work in UTC,\nconverting to localtime only when generating output to be read\nby humans.\n\n>>> utc_dt = datetime(2002, 10, 27, 6, 0, 0, tzinfo=utc)\n>>> loc_dt = utc_dt.astimezone(eastern)\n>>> loc_dt.strftime(fmt)\n'2002-10-27 01:00:00 EST-0500'\n\nThis library also allows you to do date arithmetic using local\ntimes, although it is more complicated than working in UTC as you\nneed to use the ``normalize()`` method to handle daylight saving time\nand other timezone transitions. In this example, ``loc_dt`` is set\nto the instant when daylight saving time ends in the US/Eastern\ntimezone.\n\n>>> before = loc_dt - timedelta(minutes=10)\n>>> before.strftime(fmt)\n'2002-10-27 00:50:00 EST-0500'\n>>> eastern.normalize(before).strftime(fmt)\n'2002-10-27 01:50:00 EDT-0400'\n>>> after = eastern.normalize(before + timedelta(minutes=20))\n>>> after.strftime(fmt)\n'2002-10-27 01:10:00 EST-0500'\n\nCreating local times is also tricky, and the reason why working with\nlocal times is not recommended. Unfortunately, you cannot just pass\na ``tzinfo`` argument when constructing a datetime (see the next\nsection for more details)\n\n>>> dt = datetime(2002, 10, 27, 1, 30, 0)\n>>> dt1 = eastern.localize(dt, is_dst=True)\n>>> dt1.strftime(fmt)\n'2002-10-27 01:30:00 EDT-0400'\n>>> dt2 = eastern.localize(dt, is_dst=False)\n>>> dt2.strftime(fmt)\n'2002-10-27 01:30:00 EST-0500'\n\nConverting between timezones is more easily done, using the\nstandard astimezone method.\n\n>>> utc_dt = datetime.fromtimestamp(1143408899, tz=utc)\n>>> utc_dt.strftime(fmt)\n'2006-03-26 21:34:59 UTC+0000'\n>>> au_tz = timezone('Australia/Sydney')\n>>> au_dt = utc_dt.astimezone(au_tz)\n>>> au_dt.strftime(fmt)\n'2006-03-27 08:34:59 AEDT+1100'\n>>> utc_dt2 = au_dt.astimezone(utc)\n>>> utc_dt2.strftime(fmt)\n'2006-03-26 21:34:59 UTC+0000'\n>>> utc_dt == utc_dt2\nTrue\n\nYou can take shortcuts when dealing with the UTC side of timezone\nconversions. ``normalize()`` and ``localize()`` are not really\nnecessary when there are no daylight saving time transitions to\ndeal with.\n\n>>> utc_dt = datetime.fromtimestamp(1143408899, tz=utc)\n>>> utc_dt.strftime(fmt)\n'2006-03-26 21:34:59 UTC+0000'\n>>> au_tz = timezone('Australia/Sydney')\n>>> au_dt = au_tz.normalize(utc_dt.astimezone(au_tz))\n>>> au_dt.strftime(fmt)\n'2006-03-27 08:34:59 AEDT+1100'\n>>> utc_dt2 = au_dt.astimezone(utc)\n>>> utc_dt2.strftime(fmt)\n'2006-03-26 21:34:59 UTC+0000'\n\n\n``tzinfo`` API\n--------------\n\nThe ``tzinfo`` instances returned by the ``timezone()`` function have\nbeen extended to cope with ambiguous times by adding an ``is_dst``\nparameter to the ``utcoffset()``, ``dst()`` && ``tzname()`` methods.\n\n>>> tz = timezone('America/St_Johns')\n\n>>> normal = datetime(2009, 9, 1)\n>>> ambiguous = datetime(2009, 10, 31, 23, 30)\n\nThe ``is_dst`` parameter is ignored for most timestamps. It is only used\nduring DST transition ambiguous periods to resolve that ambiguity.\n\n>>> print(tz.utcoffset(normal, is_dst=True))\n-1 day, 21:30:00\n>>> print(tz.dst(normal, is_dst=True))\n1:00:00\n>>> tz.tzname(normal, is_dst=True)\n'NDT'\n\n>>> print(tz.utcoffset(ambiguous, is_dst=True))\n-1 day, 21:30:00\n>>> print(tz.dst(ambiguous, is_dst=True))\n1:00:00\n>>> tz.tzname(ambiguous, is_dst=True)\n'NDT'\n\n>>> print(tz.utcoffset(normal, is_dst=False))\n-1 day, 21:30:00\n>>> tz.dst(normal, is_dst=False).seconds\n3600\n>>> tz.tzname(normal, is_dst=False)\n'NDT'\n\n>>> print(tz.utcoffset(ambiguous, is_dst=False))\n-1 day, 20:30:00\n>>> tz.dst(ambiguous, is_dst=False)\ndatetime.timedelta(0)\n>>> tz.tzname(ambiguous, is_dst=False)\n'NST'\n\nIf ``is_dst`` is not specified, ambiguous timestamps will raise\nan ``pytz.exceptions.AmbiguousTimeError`` exception.\n\n>>> print(tz.utcoffset(normal))\n-1 day, 21:30:00\n>>> print(tz.dst(normal))\n1:00:00\n>>> tz.tzname(normal)\n'NDT'\n\n>>> import pytz.exceptions\n>>> try:\n...     tz.utcoffset(ambiguous)\n... except pytz.exceptions.AmbiguousTimeError:\n...     print('pytz.exceptions.AmbiguousTimeError: %s' % ambiguous)\npytz.exceptions.AmbiguousTimeError: 2009-10-31 23:30:00\n>>> try:\n...     tz.dst(ambiguous)\n... except pytz.exceptions.AmbiguousTimeError:\n...     print('pytz.exceptions.AmbiguousTimeError: %s' % ambiguous)\npytz.exceptions.AmbiguousTimeError: 2009-10-31 23:30:00\n>>> try:\n...     tz.tzname(ambiguous)\n... except pytz.exceptions.AmbiguousTimeError:\n...     print('pytz.exceptions.AmbiguousTimeError: %s' % ambiguous)\npytz.exceptions.AmbiguousTimeError: 2009-10-31 23:30:00\n\n\nProblems with Localtime\n~~~~~~~~~~~~~~~~~~~~~~~\n\nThe major problem we have to deal with is that certain datetimes\nmay occur twice in a year. For example, in the US/Eastern timezone\non the last Sunday morning in October, the following sequence\nhappens:\n\n    - 01:00 EDT occurs\n    - 1 hour later, instead of 2:00am the clock is turned back 1 hour\n      and 01:00 happens again (this time 01:00 EST)\n\nIn fact, every instant between 01:00 and 02:00 occurs twice. This means\nthat if you try and create a time in the 'US/Eastern' timezone\nthe standard datetime syntax, there is no way to specify if you meant\nbefore of after the end-of-daylight-saving-time transition. Using the\npytz custom syntax, the best you can do is make an educated guess:\n\n>>> loc_dt = eastern.localize(datetime(2002, 10, 27, 1, 30, 00))\n>>> loc_dt.strftime(fmt)\n'2002-10-27 01:30:00 EST-0500'\n\nAs you can see, the system has chosen one for you and there is a 50%\nchance of it being out by one hour. For some applications, this does\nnot matter. However, if you are trying to schedule meetings with people\nin different timezones or analyze log files it is not acceptable.\n\nThe best and simplest solution is to stick with using UTC.  The pytz\npackage encourages using UTC for internal timezone representation by\nincluding a special UTC implementation based on the standard Python\nreference implementation in the Python documentation.\n\nThe UTC timezone unpickles to be the same instance, and pickles to a\nsmaller size than other pytz tzinfo instances.  The UTC implementation\ncan be obtained as pytz.utc, pytz.UTC, or pytz.timezone('UTC').\n\n>>> import pickle, pytz\n>>> dt = datetime(2005, 3, 1, 14, 13, 21, tzinfo=utc)\n>>> naive = dt.replace(tzinfo=None)\n>>> p = pickle.dumps(dt, 1)\n>>> naive_p = pickle.dumps(naive, 1)\n>>> len(p) - len(naive_p)\n17\n>>> new = pickle.loads(p)\n>>> new == dt\nTrue\n>>> new is dt\nFalse\n>>> new.tzinfo is dt.tzinfo\nTrue\n>>> pytz.utc is pytz.UTC is pytz.timezone('UTC')\nTrue\n\nNote that some other timezones are commonly thought of as the same (GMT,\nGreenwich, Universal, etc.). The definition of UTC is distinct from these\nother timezones, and they are not equivalent. For this reason, they will\nnot compare the same in Python.\n\n>>> utc == pytz.timezone('GMT')\nFalse\n\nSee the section `What is UTC`_, below.\n\nIf you insist on working with local times, this library provides a\nfacility for constructing them unambiguously:\n\n>>> loc_dt = datetime(2002, 10, 27, 1, 30, 00)\n>>> est_dt = eastern.localize(loc_dt, is_dst=True)\n>>> edt_dt = eastern.localize(loc_dt, is_dst=False)\n>>> print(est_dt.strftime(fmt) + ' / ' + edt_dt.strftime(fmt))\n2002-10-27 01:30:00 EDT-0400 / 2002-10-27 01:30:00 EST-0500\n\nIf you pass None as the is_dst flag to localize(), pytz will refuse to\nguess and raise exceptions if you try to build ambiguous or non-existent\ntimes.\n\nFor example, 1:30am on 27th Oct 2002 happened twice in the US/Eastern\ntimezone when the clocks where put back at the end of Daylight Saving\nTime:\n\n>>> dt = datetime(2002, 10, 27, 1, 30, 00)\n>>> try:\n...     eastern.localize(dt, is_dst=None)\n... except pytz.exceptions.AmbiguousTimeError:\n...     print('pytz.exceptions.AmbiguousTimeError: %s' % dt)\npytz.exceptions.AmbiguousTimeError: 2002-10-27 01:30:00\n\nSimilarly, 2:30am on 7th April 2002 never happened at all in the\nUS/Eastern timezone, as the clocks where put forward at 2:00am skipping\nthe entire hour:\n\n>>> dt = datetime(2002, 4, 7, 2, 30, 00)\n>>> try:\n...     eastern.localize(dt, is_dst=None)\n... except pytz.exceptions.NonExistentTimeError:\n...     print('pytz.exceptions.NonExistentTimeError: %s' % dt)\npytz.exceptions.NonExistentTimeError: 2002-04-07 02:30:00\n\nBoth of these exceptions share a common base class to make error handling\neasier:\n\n>>> isinstance(pytz.AmbiguousTimeError(), pytz.InvalidTimeError)\nTrue\n>>> isinstance(pytz.NonExistentTimeError(), pytz.InvalidTimeError)\nTrue\n\n\nA special case is where countries change their timezone definitions\nwith no daylight savings time switch. For example, in 1915 Warsaw\nswitched from Warsaw time to Central European time with no daylight savings\ntransition. So at the stroke of midnight on August 5th 1915 the clocks\nwere wound back 24 minutes creating an ambiguous time period that cannot\nbe specified without referring to the timezone abbreviation or the\nactual UTC offset. In this case midnight happened twice, neither time\nduring a daylight saving time period. pytz handles this transition by\ntreating the ambiguous period before the switch as daylight savings\ntime, and the ambiguous period after as standard time.\n\n\n>>> warsaw = pytz.timezone('Europe/Warsaw')\n>>> amb_dt1 = warsaw.localize(datetime(1915, 8, 4, 23, 59, 59), is_dst=True)\n>>> amb_dt1.strftime(fmt)\n'1915-08-04 23:59:59 WMT+0124'\n>>> amb_dt2 = warsaw.localize(datetime(1915, 8, 4, 23, 59, 59), is_dst=False)\n>>> amb_dt2.strftime(fmt)\n'1915-08-04 23:59:59 CET+0100'\n>>> switch_dt = warsaw.localize(datetime(1915, 8, 5, 00, 00, 00), is_dst=False)\n>>> switch_dt.strftime(fmt)\n'1915-08-05 00:00:00 CET+0100'\n>>> str(switch_dt - amb_dt1)\n'0:24:01'\n>>> str(switch_dt - amb_dt2)\n'0:00:01'\n\nThe best way of creating a time during an ambiguous time period is\nby converting from another timezone such as UTC:\n\n>>> utc_dt = datetime(1915, 8, 4, 22, 36, tzinfo=pytz.utc)\n>>> utc_dt.astimezone(warsaw).strftime(fmt)\n'1915-08-04 23:36:00 CET+0100'\n\nThe standard Python way of handling all these ambiguities is not to\nhandle them, such as demonstrated in this example using the US/Eastern\ntimezone definition from the Python documentation (Note that this\nimplementation only works for dates between 1987 and 2006 - it is\nincluded for tests only!):\n\n>>> from pytz.reference import Eastern # pytz.reference only for tests\n>>> dt = datetime(2002, 10, 27, 0, 30, tzinfo=Eastern)\n>>> str(dt)\n'2002-10-27 00:30:00-04:00'\n>>> str(dt + timedelta(hours=1))\n'2002-10-27 01:30:00-05:00'\n>>> str(dt + timedelta(hours=2))\n'2002-10-27 02:30:00-05:00'\n>>> str(dt + timedelta(hours=3))\n'2002-10-27 03:30:00-05:00'\n\nNotice the first two results? At first glance you might think they are\ncorrect, but taking the UTC offset into account you find that they are\nactually two hours appart instead of the 1 hour we asked for.\n\n>>> from pytz.reference import UTC # pytz.reference only for tests\n>>> str(dt.astimezone(UTC))\n'2002-10-27 04:30:00+00:00'\n>>> str((dt + timedelta(hours=1)).astimezone(UTC))\n'2002-10-27 06:30:00+00:00'\n\n\nCountry Information\n~~~~~~~~~~~~~~~~~~~\n\nA mechanism is provided to access the timezones commonly in use\nfor a particular country, looked up using the ISO 3166 country code.\nIt returns a list of strings that can be used to retrieve the relevant\ntzinfo instance using ``pytz.timezone()``:\n\n>>> print(' '.join(pytz.country_timezones['nz']))\nPacific/Auckland Pacific/Chatham\n\nThe Olson database comes with a ISO 3166 country code to English country\nname mapping that pytz exposes as a dictionary:\n\n>>> print(pytz.country_names['nz'])\nNew Zealand\n\n\nWhat is UTC\n~~~~~~~~~~~\n\n'UTC' is `Coordinated Universal Time`_. It is a successor to, but distinct\nfrom, Greenwich Mean Time (GMT) and the various definitions of Universal\nTime. UTC is now the worldwide standard for regulating clocks and time\nmeasurement.\n\nAll other timezones are defined relative to UTC, and include offsets like\nUTC+0800 - hours to add or subtract from UTC to derive the local time. No\ndaylight saving time occurs in UTC, making it a useful timezone to perform\ndate arithmetic without worrying about the confusion and ambiguities caused\nby daylight saving time transitions, your country changing its timezone, or\nmobile computers that roam through multiple timezones.\n\n..  _Coordinated Universal Time: https://en.wikipedia.org/wiki/Coordinated_Universal_Time\n\n\nHelpers\n~~~~~~~\n\nThere are two lists of timezones provided.\n\n``all_timezones`` is the exhaustive list of the timezone names that can\nbe used.\n\n>>> from pytz import all_timezones\n>>> len(all_timezones) >= 500\nTrue\n>>> 'Etc/Greenwich' in all_timezones\nTrue\n\n``common_timezones`` is a list of useful, current timezones. It doesn't\ncontain deprecated zones or historical zones, except for a few I've\ndeemed in common usage, such as US/Eastern (open a bug report if you\nthink other timezones are deserving of being included here). It is also\na sequence of strings.\n\n>>> from pytz import common_timezones\n>>> len(common_timezones) < len(all_timezones)\nTrue\n>>> 'Etc/Greenwich' in common_timezones\nFalse\n>>> 'Australia/Melbourne' in common_timezones\nTrue\n>>> 'US/Eastern' in common_timezones\nTrue\n>>> 'Canada/Eastern' in common_timezones\nTrue\n>>> 'Australia/Yancowinna' in all_timezones\nTrue\n>>> 'Australia/Yancowinna' in common_timezones\nFalse\n\nBoth ``common_timezones`` and ``all_timezones`` are alphabetically\nsorted:\n\n>>> common_timezones_dupe = common_timezones[:]\n>>> common_timezones_dupe.sort()\n>>> common_timezones == common_timezones_dupe\nTrue\n>>> all_timezones_dupe = all_timezones[:]\n>>> all_timezones_dupe.sort()\n>>> all_timezones == all_timezones_dupe\nTrue\n\n``all_timezones`` and ``common_timezones`` are also available as sets.\n\n>>> from pytz import all_timezones_set, common_timezones_set\n>>> 'US/Eastern' in all_timezones_set\nTrue\n>>> 'US/Eastern' in common_timezones_set\nTrue\n>>> 'Australia/Victoria' in common_timezones_set\nFalse\n\nYou can also retrieve lists of timezones used by particular countries\nusing the ``country_timezones()`` function. It requires an ISO-3166\ntwo letter country code.\n\n>>> from pytz import country_timezones\n>>> print(' '.join(country_timezones('ch')))\nEurope/Zurich\n>>> print(' '.join(country_timezones('CH')))\nEurope/Zurich\n\n\nInternationalization - i18n/l10n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nPytz is an interface to the IANA database, which uses ASCII names. The `Unicode  Consortium's Unicode Locales (CLDR) <http://cldr.unicode.org>`_\nproject provides translations. Python packages such as\n`Babel <https://babel.pocoo.org/en/latest/api/dates.html#timezone-functionality>`_\nand Thomas Khyn's `l18n <https://pypi.org/project/l18n/>`_ package can be used\nto access these translations from Python.\n\n\nLicense\n~~~~~~~\n\nMIT license.\n\nThis code is also available as part of Zope 3 under the Zope Public\nLicense,  Version 2.1 (ZPL).\n\nI'm happy to relicense this code if necessary for inclusion in other\nopen source projects.\n\n\nLatest Versions\n~~~~~~~~~~~~~~~\n\nThis package will be updated after releases of the Olson timezone\ndatabase.  The latest version can be downloaded from the `Python Package\nIndex <https://pypi.org/project/pytz/>`_.  The code that is used\nto generate this distribution is hosted on Github and available\nusing git::\n\n    git clone https://github.com/stub42/pytz.git\n\nAnnouncements of new releases are made on\n`Launchpad <https://launchpad.net/pytz>`_, and the\n`Atom feed <http://feeds.launchpad.net/pytz/announcements.atom>`_\nhosted there.\n\n\nBugs, Feature Requests & Patches\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nBugs should be reported on `Github <https://github.com/stub42/pytz/issues>`_.\nFeature requests are unlikely to be considered, and efforts instead directed\nto timezone support now built into Python or packages that work with it.\n\n\nSecurity Issues\n~~~~~~~~~~~~~~~\n\nReports about security issues can be made via `Tidelift <https://tidelift.com/security>`_.\n\n\nIssues & Limitations\n~~~~~~~~~~~~~~~~~~~~\n\n- This project is in maintenance mode. Projects using Python 3.9 or later\n  are best served by using the timezone functionaly now included in core\n  Python and packages that work with it such as `tzdata <https://pypi.org/project/tzdata/>`_.\n\n- Offsets from UTC are rounded to the nearest whole minute, so timezones\n  such as Europe/Amsterdam pre 1937 will be up to 30 seconds out. This\n  was a limitation of the Python datetime library.\n\n- If you think a timezone definition is incorrect, I probably can't fix\n  it. pytz is a direct translation of the Olson timezone database, and\n  changes to the timezone definitions need to be made to this source.\n  If you find errors they should be reported to the time zone mailing\n  list, linked from http://www.iana.org/time-zones.\n\n\nFurther Reading\n~~~~~~~~~~~~~~~\n\nMore info than you want to know about timezones:\nhttps://data.iana.org/time-zones/tz-link.html\n\n\nContact\n~~~~~~~\n\nStuart Bishop <stuart@stuartbishop.net>\n",
        "keywords": [
          "timezone",
          "tzinfo",
          "datetime",
          "olson",
          "time"
        ],
        "home_page": "http://pythonhosted.org/pytz",
        "download_url": "https://pypi.org/project/pytz/",
        "author": "Stuart Bishop",
        "author_email": "stuart@stuartbishop.net",
        "maintainer": "Stuart Bishop",
        "maintainer_email": "stuart@stuartbishop.net",
        "license": "MIT",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 6 - Mature",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.4",
          "Programming Language :: Python :: 2.5",
          "Programming Language :: Python :: 2.6",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.1",
          "Programming Language :: Python :: 3.2",
          "Programming Language :: Python :: 3.3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/pytz-2025.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "dbt-duckdb",
        "version": "1.10.0",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "keywords",
          "license",
          "license-file",
          "provides-extra",
          "summary"
        ],
        "summary": "The duckdb adapter plugin for dbt (data build tool)",
        "description": "## dbt-duckdb\n\n[DuckDB](http://duckdb.org) is an embedded database, similar to SQLite, but designed for OLAP-style analytics.\nIt is crazy fast and allows you to read and write data stored in CSV, JSON, and Parquet files directly, without requiring you to load\nthem into the database first.\n\n[dbt](http://getdbt.com) is the best way to manage a collection of data transformations written in SQL or Python for analytics\nand data science. `dbt-duckdb` is the project that ties DuckDB and dbt together, allowing you to create a [Modern Data Stack In\nA Box](https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html) or a simple and powerful data lakehouse with Python.\n\n### Installation\n\nThis project is hosted on PyPI, so you should be able to install it and the necessary dependencies via:\n\n`pip3 install dbt-duckdb`\n\nThe latest supported version targets `dbt-core` versions >= 1.8.x and `duckdb` version 1.1.x, but we work hard to ensure that newer\nversions of DuckDB will continue to work with the adapter as they are released.\n\n### Configuring Your Profile\n\nA super-minimal dbt-duckdb profile only needs *one* setting:\n\n````\ndefault:\n  outputs:\n    dev:\n      type: duckdb\n  target: dev\n````\n\nThis will run your dbt-duckdb pipeline against an in-memory DuckDB database that will not be persisted after your run completes. This may\nnot seem very useful at first, but it turns out to be a powerful tool for a) testing out data pipelines, either locally or in CI jobs and\nb) running data pipelines that operate purely on external CSV, Parquet, or JSON files. More details on how to work with external data files\nin dbt-duckdb are provided in the docs on [reading and writing external files](#reading-and-writing-external-files).\n\nTo have your dbt pipeline persist relations in a DuckDB file, set the `path` field in your profile to the path\nof the DuckDB file that you would like to read and write on your local filesystem. (For in-memory pipelines, the `path`\nis automatically set to the special value `:memory:`). By default, the `path` is relative to your `profiles.yml` file location.\nIf the database doesn't exist at the specified `path`, DuckDB will automatically create it.\n\n`dbt-duckdb` also supports common profile fields like `schema` and `threads`, but the `database` property is special: its value is automatically set\nto the basename of the file in the `path` argument with the suffix removed. For example, if the `path` is `/tmp/a/dbfile.duckdb`, the `database`\nfield will be set to `dbfile`. If you are running in in-memory mode, then the `database` property will be automatically set to `memory`.\n\n#### Using MotherDuck\n\nAs of `dbt-duckdb` 1.5.2, you can connect to a DuckDB instance running on [MotherDuck](http://www.motherduck.com) by setting your `path` to use a [md:<database> connection string](https://motherduck.com/docs/getting-started/connect-query-from-python/installation-authentication), just as you would with the DuckDB CLI\nor the Python API.\n\nMotherDuck databases generally work the same way as local DuckDB databases from the perspective of dbt, but\nthere are a [few differences to be aware of](https://motherduck.com/docs/architecture-and-capabilities#considerations-and-limitations):\n1. MotherDuck is compatible with client DuckDB versions 0.10.2 and older.\n1. MotherDuck preloads a set of the most common DuckDB extensions for you, but does not support loading custom extensions or user-defined functions.\n\nAs of `dbt-duckdb` 1.9.6, you can also connect to a DuckDB instance running [hosted DuckLake on MotherDuck](https://motherduck.com/blog/ducklake-motherduck/) by creating a DuckLake on MotherDuck and then setting `is_ducklake: true` in your `profiles.yml`.\n\n```sql\n-- to use create your own database in MotherDuck first\nCREATE DATABASE my_ducklake\n  (TYPE ducklake, DATA_PATH 's3://...')\n```\n\nAn example profile is show below under \"Attaching Additional Databases\". DuckLake must be identified so that safe DDL operations are applied by dbt.\n\n#### DuckDB Extensions, Settings, and Filesystems\n\nYou can install and load any core [DuckDB extensions](https://duckdb.org/docs/extensions/overview) by listing them in\nthe `extensions` field in your profile as a string. You can also set any additional [DuckDB configuration options](https://duckdb.org/docs/sql/configuration)\nvia the `settings` field, including options that are supported in the loaded extensions. You can also configure extensions from outside of the core\nextension repository (e.g., a community extension) by configuring the extension as a `name`/`repo` pair:\n\n```\ndefault:\n  outputs:\n    dev:\n      type: duckdb\n      path: /tmp/dbt.duckdb\n      extensions:\n        - httpfs\n        - parquet\n        - name: h3\n          repo: community\n        - name: uc_catalog\n          repo: core_nightly\n  target: dev\n```\n\nTo use the [DuckDB Secrets Manager](https://duckdb.org/docs/configuration/secrets_manager.html), you can use the `secrets` field. For example, to be able to connect to S3 and read/write\nParquet files using an AWS access key and secret, your profile would look something like this:\n\n```\ndefault:\n  outputs:\n    dev:\n      type: duckdb\n      path: /tmp/dbt.duckdb\n      extensions:\n        - httpfs\n        - parquet\n      secrets:\n        - type: s3\n          region: my-aws-region\n          key_id: \"{{ env_var('S3_ACCESS_KEY_ID') }}\"\n          secret: \"{{ env_var('S3_SECRET_ACCESS_KEY') }}\"\n  target: dev\n```\n\nAs of version `1.4.1`, we have added (experimental!) support for DuckDB's (experimental!) support for filesystems\nimplemented via [fsspec](https://duckdb.org/docs/guides/python/filesystems.html). The `fsspec` library provides\nsupport for reading and writing files from a [variety of cloud data storage systems](https://filesystem-spec.readthedocs.io/en/latest/api.html#other-known-implementations)\nincluding S3, GCS, and Azure Blob Storage. You can configure a list of fsspec-compatible implementations for use with your dbt-duckdb project by installing the relevant Python modules\nand configuring your profile like so:\n\n```\ndefault:\n  outputs:\n    dev:\n      type: duckdb\n      path: /tmp/dbt.duckdb\n      filesystems:\n        - fs: s3\n          anon: false\n          key: \"{{ env_var('S3_ACCESS_KEY_ID') }}\"\n          secret: \"{{ env_var('S3_SECRET_ACCESS_KEY') }}\"\n          client_kwargs:\n            endpoint_url: \"http://localhost:4566\"\n  target: dev\n```\n\nHere, the `filesystems` property takes a list of configurations, where each entry must have a property named `fs` that indicates which `fsspec` protocol\nto load (so `s3`, `gcs`, `abfs`, etc.) and then an arbitrary set of other key-value pairs that are used to configure the `fsspec` implementation. You can see a simple example project that\nillustrates the usage of this feature to connect to a Localstack instance running S3 from dbt-duckdb [here](https://github.com/jwills/s3-demo).\n\n#### Fetching credentials from context\n\nInstead of specifying the credentials through the settings block, you can also use the `CREDENTIAL_CHAIN` secret provider. This means that you can use any supported mechanism from AWS to obtain credentials (e.g., web identity tokens). You can read more about the secret providers [here](https://duckdb.org/docs/configuration/secrets_manager.html#secret-providers). To use the `CREDENTIAL_CHAIN` provider and automatically fetch credentials from AWS, specify the `provider` in the `secrets` key:\n\n```\ndefault:\n  outputs:\n    dev:\n      type: duckdb\n      path: /tmp/dbt.duckdb\n      extensions:\n        - httpfs\n        - parquet\n      secrets:\n        - type: s3\n          provider: credential_chain\n  target: dev\n```\n\n#### Scoped credentials by storage prefix\n\nSecrets can be scoped, such that different storage path can use different credentials.\n\n```\ndefault:\n  outputs:\n    dev:\n      type: duckdb\n      path: /tmp/dbt.duckdb\n      extensions:\n        - httpfs\n        - parquet\n      secrets:\n        - type: s3\n          provider: credential_chain\n          scope: [ \"s3://bucket-in-eu-region\", \"s3://bucket-2-in-eu-region\" ]\n          region: \"eu-central-1\"\n        - type: s3\n          region: us-west-2\n          scope: \"s3://bucket-in-us-region\"\n```\n\nWhen fetching a secret for a path, the secret scopes are compared to the path, returning the matching secret for the path. In the case of multiple matching secrets, the longest prefix is chosen.\n\n#### Attaching Additional Databases\n\nDuckDB supports [attaching additional databases](https://duckdb.org/docs/sql/statements/attach.html) to your dbt-duckdb run so that you can read\nand write from multiple databases. Additional databases may be configured via the `attach` argument\nin your profile that was added in dbt-duckdb `1.4.0`:\n\n```\ndefault:\n  outputs:\n    dev:\n      type: duckdb\n      path: /tmp/dbt.duckdb\n      attach:\n        - path: /tmp/other.duckdb\n        - path: ./yet/another.duckdb\n          alias: yet_another\n        - path: s3://yep/even/this/works.duckdb\n          read_only: true\n        - path: sqlite.db\n          type: sqlite\n        - path: postgresql://username@hostname/dbname\n          type: postgres\n        # Using the options dict for arbitrary ATTACH options\n        - path: /tmp/special.duckdb\n          options:\n            cache_size: 1GB\n            threads: 4\n            enable_fsst: true\n```\n\nFor DuckLake, use `ducklake:` for local; for MotherDuck-managed DuckLake use `md:` with `is_ducklake: true`.\n\n```yaml\nattach:\n  - path: \"ducklake:my_ducklake.ddb\"\n  - path: \"md:my_other_ducklake\"\n    is_ducklake: true\n```\n\n\nThe attached databases may be referred to in your dbt sources and models by either the basename of the database file minus its suffix (e.g., `/tmp/other.duckdb` is the `other` database\nand `s3://yep/even/this/works.duckdb` is the `works` database) or by an alias that you specify (so the `./yet/another.duckdb` database in the above configuration is referred to\nas `yet_another` instead of `another`.) Note that these additional databases do not necessarily have to be DuckDB files: DuckDB's storage and catalog engines are pluggable, and\nDuckDB ships with support for reading and writing from attached databases. You can indicate the type of the database you are connecting to via the `type` argument,\nwhich currently supports `duckdb`, `sqlite` and `postgres`.\n\n##### Arbitrary ATTACH Options\n\nAs DuckDB continues to add new attachment options, you can use the `options` dictionary to specify any additional key-value pairs that will be passed to the `ATTACH` statement. This allows you to take advantage of new DuckDB features without waiting for explicit support in dbt-duckdb:\n\n```\nattach:\n  # Standard way using direct fields\n  - path: /tmp/db1.duckdb\n    type: sqlite\n    read_only: true\n\n  # New way using options dict (equivalent to above)\n  - path: /tmp/db2.duckdb\n    options:\n      type: sqlite\n      read_only: true\n\n  # Mix of both (no conflicts allowed)\n  - path: /tmp/db3.duckdb\n    type: sqlite\n    options:\n      block_size: 16384\n\n  # Using options dict for future DuckDB attachment options\n  - path: /tmp/db4.duckdb\n    options:\n      type: duckdb\n      # Example: hypothetical future options DuckDB might add\n      compression: lz4\n      memory_limit: 2GB\n```\n\nNote: If you specify the same option in both a direct field (`type`, `secret`, `read_only`) and in the `options` dict, dbt-duckdb will raise an error to prevent conflicts.\n\n#### Configuring dbt-duckdb Plugins\n\ndbt-duckdb has its own [plugin](dbt/adapters/duckdb/plugins/__init__.py) system to enable advanced users to extend\ndbt-duckdb with additional functionality, including:\n\n* Defining [custom Python UDFs](https://duckdb.org/docs/api/python/function.html) on the DuckDB database connection\nso that they can be used in your SQL models\n* Loading source data from [Excel](dbt/adapters/duckdb/plugins/excel.py), [Google Sheets](dbt/adapters/duckdb/plugins/gsheet.py), or [SQLAlchemy](dbt/adapters/duckdb/plugins/sqlalchemy.py) tables\n\nYou can find more details on [how to write your own plugins here](#writing-your-own-plugins). To configure a plugin for use\nin your dbt project, use the `plugins` property on the profile:\n\n```\ndefault:\n  outputs:\n    dev:\n      type: duckdb\n      path: /tmp/dbt.duckdb\n      plugins:\n        - module: gsheet\n          config:\n            method: oauth\n        - module: sqlalchemy\n          alias: sql\n          config:\n            connection_url: \"{{ env_var('DBT_ENV_SECRET_SQLALCHEMY_URI') }}\"\n        - module: path.to.custom_udf_module\n```\n\nEvery plugin must have a `module` property that indicates where the `Plugin` class to load is defined. There is\na set of built-in plugins that are defined in [dbt.adapters.duckdb.plugins](dbt/adapters/duckdb/plugins/) that\nmay be referenced by their base filename (e.g., `excel` or `gsheet`), while user-defined plugins (which are\ndescribed later in this document) should be referred to via their full module path name (e.g. a `lib.my.custom` module that defines a class named `Plugin`.)\n\nEach plugin instance has a name for logging and reference purposes that defaults to the name of the module\nbut that may be overridden by the user by setting the `alias` property in the configuration. Finally,\nmodules may be initialized using an arbitrary set of key-value pairs that are defined in the\n`config` dictionary. In this example, we initialize the `gsheet` plugin with the setting `method: oauth` and we\ninitialize the `sqlalchemy` plugin (aliased as \"sql\") with a `connection_url` that is set via an environment variable.\n\nPlease remember that using plugins may require you to add additional dependencies to the Python environment that your dbt-duckdb pipeline runs in:\n\n* `excel` depends on `pandas`, and `openpyxl` or `xlsxwriter` to perform writes\n* `gsheet` depends on `gspread` and `pandas`\n*  `iceberg` depends on `pyiceberg` and Python >= 3.8\n* `sqlalchemy` depends on `pandas`, `sqlalchemy`, and the driver(s) you need\n\n**Experimental:**\n\n* `delta` depends on `deltalake`, [an example project](https://github.com/milicevica23/dbt-duckdb-delta-plugin-demo)\n\n**Note:** Be aware that experimental features can change over time, and we would like your feedback on config and possible different use cases.\n\n#### Using Local Python Modules\n\nIn dbt-duckdb 1.6.0, we added a new profile setting named `module_paths` that allows users to specify a list\nof paths on the filesystem that contain additional Python modules that should be added to the Python processes'\n`sys.path` property. This allows users to include additional helper Python modules in their dbt projects that\ncan be accessed by the running dbt process and used to define custom dbt-duckdb Plugins or library code that is\nhelpful for creating dbt Python models.\n\n### Reading and Writing External Files\n\nOne of DuckDB's most powerful features is its ability to read and write CSV, JSON, and Parquet files directly, without needing to import/export\nthem from the database first.\n\n#### Reading from external files\n\nYou may reference external files in your dbt models either directly or as dbt `source`s by configuring the `external_location`\nin either the `meta` or the `config` option on the source definition. The difference is that settings under the `meta` option\nwill be propagated to the documentation for the source generated via `dbt docs generate`, but the settings under the `config`\noption will not be. Any source settings that should be excluded from the docs should be specified via `config`, while any\noptions that you would like to be included in the generated documentation should live under `meta`.\n\n```\nsources:\n  - name: external_source\n    meta:\n      external_location: \"s3://my-bucket/my-sources/{name}.parquet\"\n    tables:\n      - name: source1\n      - name: source2\n```\n\nHere, the `meta` options on `external_source` defines `external_location` as an [f-string](https://peps.python.org/pep-0498/) that\nallows us to express a pattern that indicates the location of any of the tables defined for that source. So a dbt model like:\n\n```\nSELECT *\nFROM {{ source('external_source', 'source1') }}\n```\n\nwill be compiled as:\n\n```\nSELECT *\nFROM 's3://my-bucket/my-sources/source1.parquet'\n```\n\nIf one of the source tables deviates from the pattern or needs some other special handling, then the `external_location` can also be set on the `meta`\noptions for the table itself, for example:\n\n```\nsources:\n  - name: external_source\n    meta:\n      external_location: \"s3://my-bucket/my-sources/{name}.parquet\"\n    tables:\n      - name: source1\n      - name: source2\n        config:\n          external_location: \"read_parquet(['s3://my-bucket/my-sources/source2a.parquet', 's3://my-bucket/my-sources/source2b.parquet'])\"\n```\n\nIn this situation, the `external_location` setting on the `source2` table will take precedence, so a dbt model like:\n\n```\nSELECT *\nFROM {{ source('external_source', 'source2') }}\n```\n\nwill be compiled to the SQL query:\n\n```\nSELECT *\nFROM read_parquet(['s3://my-bucket/my-sources/source2a.parquet', 's3://my-bucket/my-sources/source2b.parquet'])\n```\n\nNote that the value of the `external_location` property does not need to be a path-like string; it can also be a function\ncall, which is helpful in the case that you have an external source that is a CSV file which requires special handling for DuckDB to load it correctly:\n\n```\nsources:\n  - name: flights_source\n    tables:\n      - name: flights\n        config:\n          external_location: \"read_csv('flights.csv', types={'FlightDate': 'DATE'}, names=['FlightDate', 'UniqueCarrier'])\"\n          formatter: oldstyle\n```\n\nNote that we need to override the default `str.format` string formatting strategy for this example\nbecause the `types={'FlightDate': 'DATE'}` argument to the `read_csv` function will be interpreted by\n`str.format` as a template to be matched on, which will cause a `KeyError: \"'FlightDate'\"` when we attempt\nto parse the source in a dbt model. The `formatter` configuration option for the source indicates whether\nwe should use `newstyle` string formatting (the default), `oldstyle` string formatting, or `template` string\nformatting. You can read up on the strategies the various string formatting techniques use at this\n[Stack Overflow answer](https://stackoverflow.com/questions/13451989/pythons-many-ways-of-string-formatting-are-the-older-ones-going-to-be-depre) and see examples of their use\nin this [dbt-duckdb integration test](https://github.com/jwills/dbt-duckdb/blob/master/tests/functional/adapter/test_sources.py).\n\n#### Writing to external files\n\nWe support creating dbt models that are backed by external files via the `external` materialization strategy:\n\n```\n{{ config(materialized='external', location='local/directory/file.parquet') }}\nSELECT m.*, s.id IS NOT NULL as has_source_id\nFROM {{ ref('upstream_model') }} m\nLEFT JOIN {{ source('upstream', 'source') }} s USING (id)\n```\n\n| Option | Default | Description\n| :---:    |  :---:    | ---\n| location | [external_location](dbt/include/duckdb/macros/utils/external_location.sql) macro | The path to write the external materialization to. See below for more details.\n| format | parquet | The format of the external file (parquet, csv, or json)\n| delimiter | ,    | For CSV files, the delimiter to use for fields.\n| options | None | Any other options to pass to DuckDB's `COPY` operation (e.g., `partition_by`, `codec`, etc.)\n| glue_register | false | If true, try to register the file created by this model with the AWS Glue Catalog.\n| glue_database | default | The name of the AWS Glue database to register the model with.\n\nIf the `location` argument is specified, it must be a filename (or S3 bucket/path), and dbt-duckdb will attempt to infer\nthe `format` argument from the file extension of the `location` if the `format` argument is unspecified (this functionality was\nadded in version 1.4.1.)\n\nIf the `location` argument is _not_ specified, then the external file will be named after the model.sql (or model.py) file that defined it\nwith an extension that matches the `format` argument (`parquet`, `csv`, or `json`). By default, the external files are created\nrelative to the current working directory, but you can change the default directory (or S3 bucket/prefix) by specifying the\n`external_root` setting in your DuckDB profile.\n\nUnfortunately incremental materialization strategies are not yet supported for `external` models.\n\n\n#### Incremental Strategy Configuration\n\ndbt-duckdb supports the `delete+insert`, `append`, and `merge` strategies for incremental `table` models. The `merge` strategy requires DuckDB >= 1.4.0 and provides access to DuckDB's native MERGE statement.\n\n**Append Strategy:**\n\n| Configuration | Type | Default | Description |\n|---------------|------|---------|-------------|\n| `incremental_predicates` | list | null | SQL conditions to filter which records get appended |\n\nExample:\n```yaml\nmodels:\n  - name: my_incremental_model\n    config:\n      materialized: incremental\n      incremental_strategy: append\n      incremental_predicates: [\"created_at > (select max(created_at) from {{ this }})\"]\n```\n\n**Delete+Insert Strategy:**\n\n| Configuration | Type | Default | Description |\n|---------------|------|---------|-------------|\n| `unique_key` | string/list | required | Column(s) used to identify records for deletion |\n| `incremental_predicates` | list | null | SQL conditions to filter the delete and insert operations |\n\nExample:\n```yaml\nmodels:\n  - name: my_incremental_model\n    config:\n      materialized: incremental\n      incremental_strategy: delete+insert\n      unique_key: id  # or ['id', 'date'] for composite keys\n      incremental_predicates: [\"updated_at >= '2023-01-01'\"]\n```\n\n**Merge Strategy (DuckDB >= 1.4.0):**\n\nThe merge strategy leverages DuckDB's native MERGE statement to efficiently synchronize data between your incremental model and the target table. This strategy offers three configuration approaches: basic configuration (using simple options), enhanced configuration with explicit column control, and fully custom merge clauses.\n\n**Basic Configuration (Default Behavior):**\n\nWhen you specify only `unique_key`, dbt-duckdb uses DuckDB's `UPDATE BY NAME` and `INSERT BY NAME` operations, which automatically match columns by name between source and target tables.\n\n```yaml\nmodels:\n  - name: my_incremental_model\n    config:\n      materialized: incremental\n      incremental_strategy: merge\n      unique_key: id  # or ['id', 'date'] for composite keys\n```\n\nThis generates SQL equivalent to:\n```sql\nMERGE INTO target AS DBT_INTERNAL_DEST\nUSING source AS DBT_INTERNAL_SOURCE\nON (DBT_INTERNAL_SOURCE.id = DBT_INTERNAL_DEST.id)\nWHEN MATCHED THEN UPDATE BY NAME\nWHEN NOT MATCHED THEN INSERT BY NAME\n```\n\n**Enhanced Configuration:**\n\nThese options extend the basic merge behavior with additional control over which records get updated or inserted, which columns are affected, and how values are set.\n\n| Configuration | Type | Default | Description |\n|---------------|------|---------|-------------|\n| `unique_key` | string/list | required | Column(s) used for the MERGE join condition |\n| `incremental_predicates` | list | null | Additional SQL conditions to filter the MERGE operation |\n| `merge_on_using_columns` | list | null | Columns for USING clause syntax instead of ON for the join condition |\n| `merge_update_condition` | string | null | SQL condition to control when matched records are updated |\n| `merge_insert_condition` | string | null | SQL condition to control when unmatched records are inserted |\n| `merge_update_columns` | list | null | Specific columns to update |\n| `merge_exclude_columns` | list | null | Columns to exclude from updates |\n| `merge_update_set_expressions` | dict | null | Custom expressions for column updates |\n| `merge_returning_columns` | list | null | Columns to return from the MERGE operation |\n\n**Example with Enhanced Options:**\n```yaml\nmodels:\n  - name: my_incremental_model\n    config:\n      materialized: incremental\n      incremental_strategy: merge\n      unique_key: id\n      merge_update_condition: \"DBT_INTERNAL_DEST.age < DBT_INTERNAL_SOURCE.age\"\n      merge_insert_condition: \"DBT_INTERNAL_SOURCE.status != 'inactive'\"\n      merge_update_columns: ['name', 'age', 'status']\n      merge_exclude_columns: ['created_at']\n      merge_update_set_expressions:\n        updated_at: \"CURRENT_TIMESTAMP\"\n        version: \"COALESCE(DBT_INTERNAL_DEST.version, 0) + 1\"\n```\n\n**Custom Merge Clauses:**\n\nFor maximum flexibility, use `merge_clauses` to define custom `when_matched` and `when_not_matched` behaviors.  This is especially helpful in more complex scenarios where you have more than one action, multiple conditions, or error handling within a `when_matched` or `when_not_matched` clause.\n\n*Supported When Matched Actions and Modes:*\n- `update`: Update the matched record\n  - `mode: by_name`: Use `UPDATE BY NAME` (default)\n  - `mode: by_position`: Use `UPDATE BY POSITION`\n  - `mode: star`: Use `UPDATE SET *`\n  - `mode: explicit`: Use explicit column list with custom expressions\n    - `update.include`: List of columns to include in the update\n    - `update.exclude`: List of columns to exclude from the update\n    - `update.set_expressions`: Dictionary of column-to-expression mappings for custom update values\n- `delete`: Delete the matched record\n- `do_nothing`: Skip the matched record\n- `error`: Raise an error for matched records\n  - `error_message`: Optional custom error message\n\n*Supported When Not Matched Actions and Modes:*\n- `insert`: Insert the unmatched record\n  - `mode: by_name`: Use `INSERT BY NAME` (default)\n  - `mode: by_position`: Use `INSERT BY POSITION`\n  - `mode: star`: Use `INSERT *`\n  - `mode: explicit`: Use explicit column and value lists\n    - `insert.columns`: List of column names for the INSERT statement\n    - `insert.values`: List of values/expressions corresponding to the columns\n- `update`: Update unmatched records (for WHEN NOT MATCHED BY SOURCE scenarios)\n  - `set_expressions`: Dictionary of column-to-expression mappings\n- `delete`: Delete unmatched records\n- `do_nothing`: Skip the unmatched record\n- `error`: Raise an error for unmatched records\n  - `error_message`: Optional custom error message\n\n**Example with Custom Merge Clauses:**\n\n```yaml\nmodels:\n  - name: my_incremental_model\n    config:\n      materialized: incremental\n      incremental_strategy: merge\n      unique_key: id\n      merge_clauses:\n        when_matched:\n          - action: update\n            mode: explicit\n            condition: \"DBT_INTERNAL_SOURCE.status = 'active'\"\n            update:\n              include: ['name', 'email', 'status']\n              exclude: ['created_at']\n              set_expressions:\n                updated_at: \"CURRENT_TIMESTAMP\"\n                version: \"COALESCE(DBT_INTERNAL_DEST.version, 0) + 1\"\n          - action: delete\n            condition: \"DBT_INTERNAL_SOURCE.status = 'deleted'\"\n        when_not_matched:\n          - action: insert\n            mode: explicit\n            insert:\n              columns: ['id', 'name', 'email', 'created_at']\n              values: ['DBT_INTERNAL_SOURCE.id', 'DBT_INTERNAL_SOURCE.name', 'DBT_INTERNAL_SOURCE.email', 'CURRENT_TIMESTAMP']\n```\n\n**DuckLake Restrictions:**\n\nWhen using DuckLake (attached DuckLake databases), MERGE statements are limited to a single UPDATE or DELETE action in `when_matched` clauses due to DuckLake's current MERGE implementation constraints.\n\n**Table Aliases:**\n\nIn conditions and expressions, use these table aliases:\n- `DBT_INTERNAL_SOURCE`: References the incoming data (your model's SELECT)\n- `DBT_INTERNAL_DEST`: References the existing target table\n\n#### Re-running external models with an in-memory version of dbt-duckdb\nWhen using `:memory:` as the DuckDB database, subsequent dbt runs can fail when selecting a subset of models that depend on external tables. This is because external files are only registered as  DuckDB views when they are created, not when they are referenced. To overcome this issue we have provided the `register_upstream_external_models` macro that can be triggered at the beginning of a run. To enable this automatic registration, place the following in your `dbt_project.yml` file:\n\n```yaml\non-run-start:\n  - \"{{ register_upstream_external_models() }}\"\n```\n\n### `table_function` Materialization\n\ndbt-duckdb also provides a custom table_function materialization to use DuckDB's Table Function / Table Macro feature to provide parameterized views.\n\nWhy use this materialization?\n* Late binding of functions means that the underlying table can change (have new columns added) and the function does not need to be recreated.\n  * (With a view, the create view statement would need to be re-run).\n  * This allows for skipping parts of the dbt DAG, even if the underlying table changed.\n* Parameters can force filter pushdown\n* Functions can provide advanced features like dynamic SQL (the query and query_table functions)\n\n\nExample table_function creation with 0 parameters:\n```sql\n{{\n    config(\n        materialized='table_function'\n    )\n}}\nselect * from {{ ref(\"example_table\") }}\n```\n\nExample table_function invocation (note the parentheses are needed even with 0 parameters!):\n```sql\nselect * from {{ ref(\"my_table_function\") }}()\n```\n\nExample table_function creation with 2 parameters:\n```sql\n{{\n    config(\n        materialized='table_function',\n        parameters=['where_a', 'where_b']\n    )\n}}\nselect *\nfrom {{ ref(\"example_table\") }}\nwhere 1=1\n    and a = where_a\n    and b = where_b\n```\n\nExample table_function with 2 parameters invocation:\n```sql\nselect * from {{ ref(\"my_table_function_with_parameters\") }}(1, 2)\n```\n\n### Python Support\n\ndbt added support for [Python models in version 1.3.0](https://docs.getdbt.com/docs/build/python-models). For most data platforms,\ndbt will package up the Python code defined in a `.py` file and ship it off to be executed in whatever Python environment that\ndata platform supports (e.g., Snowpark for Snowflake or Dataproc for BigQuery.) In dbt-duckdb, we execute Python models in the same\nprocess that owns the connection to the DuckDB database, which by default, is the Python process that is created when you run dbt.\nTo execute the Python model, we treat the `.py` file that your model is defined in as a Python module and load it into the\nrunning process using [importlib](https://docs.python.org/3/library/importlib.html). We then construct the arguments to the `model`\nfunction that you defined (a `dbt` object that contains the names of any `ref` and `source` information your model needs and a\n`DuckDBPyConnection` object for you to interact with the underlying DuckDB database), call the `model` function, and then materialize\nthe returned object as a table in DuckDB.\n\nThe value of the `dbt.ref` and `dbt.source` functions inside of a Python model will be a [DuckDB Relation](https://duckdb.org/docs/api/python/reference/)\nobject that can be easily converted into a Pandas/Polars DataFrame or an Arrow table. The return value of the `model` function can be\nany Python object that DuckDB knows how to turn into a table, including a Pandas/Polars `DataFrame`, a DuckDB `Relation`, or an Arrow `Table`,\n`Dataset`, `RecordBatchReader`, or `Scanner`.\n\n#### Batch processing with Python models\n\nAs of version 1.6.1, it is possible to both read and write data in chunks, which allows for larger-than-memory\ndatasets to be manipulated in Python models. Here is a basic example:\n```\nimport pyarrow as pa\n\ndef batcher(batch_reader: pa.RecordBatchReader):\n    for batch in batch_reader:\n        df = batch.to_pandas()\n        # Do some operations on the DF...\n        # ...then yield back a new batch\n        yield pa.RecordBatch.from_pandas(df)\n\ndef model(dbt, session):\n    big_model = dbt.ref(\"big_model\")\n    batch_reader = big_model.record_batch(100_000)\n    batch_iter = batcher(batch_reader)\n    return pa.RecordBatchReader.from_batches(batch_reader.schema, batch_iter)\n```\n\n### Writing Your Own Plugins\n\nDefining your own dbt-duckdb plugin is as simple as creating a python module that defines a class named `Plugin` that\ninherits from [dbt.adapters.duckdb.plugins.BasePlugin](dbt/adapters/duckdb/plugins/__init__.py). There are currently\nfour methods that may be implemented in your Plugin class:\n\n1. `initialize`: Takes in the `config` dictionary for the plugin that is defined in the profile to enable any\nadditional configuration for the module based on the project; this method is called once when an instance of the\n`Plugin` class is created.\n1. `configure_connection`: Takes an instance of the `DuckDBPyConnection` object used to connect to the DuckDB\ndatabase and may perform any additional configuration of that object that is needed by the plugin, like defining\ncustom user-defined functions.\n1. `load`: Takes a [SourceConfig](dbt/adapters/duckdb/utils.py) instance, which encapsulates the configuration for a\na dbt source and can optionally return a DataFrame-like object that DuckDB knows how to turn into a table (this is\nsimilar to a dbt-duckdb Python model, but without the ability to `ref` any models or access any information beyond\nthe source config.)\n1. `store`: Takes a [TargetConfig](dbt/adapters/duckdb/utils.py) instance, which encapsulates the configuration for\nan `external` materialization and can perform additional operations once the CSV/Parquet/JSON file is written. The\n[glue](dbt/adapters/duckdb/plugins/glue.py) and [sqlalchemy](dbt/adapters/duckdb/plugins/sqlalchemy.py) are examples\nthat demonstrate how to use the `store` operation to register an AWS Glue database table or upload a DataFrame to\nan external database, respectively.\n\ndbt-duckdb ships with a number of [built-in plugins](dbt/adapters/duckdb/plugins/) that can be used as examples\nfor implementing your own.\n\n### Interactive Shell\n\nAs of version 1.9.3, dbt-duckdb includes an interactive shell that allows you to run dbt commands and query the DuckDB database in an integrated CLI environment. The shell automatically launches the [DuckDB UI](https://duckdb.org/2025/03/12/duckdb-ui.html), providing a visual interface to explore your data while working with your dbt models.\n\nTo start the interactive shell, use:\n\n```\npython -m dbt.adapters.duckdb.cli\n```\n\nYou can specify a profile to use with the `--profile` flag:\n\n```\npython -m dbt.adapters.duckdb.cli --profile my_profile\n```\n\nThe shell provides access to all standard dbt commands:\n- `run` - Run dbt models\n- `test` - Run tests on dbt models\n- `build` - Build and test dbt models\n- `seed` - Load seed files\n- `snapshot` - Run snapshots\n- `compile` - Compile models without running them\n- `parse` - Parse the project\n- `debug` - Debug connection\n- `deps` - Install dependencies\n- `list` - List resources\n\nWhen you launch the shell, it automatically:\n1. Runs `dbt debug` to test your connection\n2. Parses your dbt project\n3. Launches the DuckDB UI for visual data exploration\n\nThe shell supports model name autocompletion if you install the optional `iterfzf` package:\n\n```\npip install iterfzf\n```\n\nExample workflow:\n1. Start the interactive shell\n2. View your project's models in the launched DuckDB UI\n3. Run `build` to build your models\n4. Immediately see the results in the UI and continue iterating\n\nThis interactive environment makes it easier to develop and test dbt models while simultaneously exploring the data in a visual interface.\n\n### Roadmap\n\nThings that we would like to add in the near future:\n\n* Support for Delta and Iceberg external table formats (both as sources and destinations)\n* Make dbt's incremental models and snapshots work with external materializations\n\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "setup",
          "distutils"
        ],
        "home_page": "https://github.com/jwills/dbt-duckdb",
        "author": "Josh Wills",
        "author_email": "joshwills+dbt@gmail.com",
        "license": "Apache-2",
        "license_file": [
          "LICENSE",
          "AUTHORS"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "License :: OSI Approved :: Apache Software License",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: POSIX :: Linux",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "dbt-common<2,>=1",
          "dbt-adapters<2,>=1",
          "duckdb>=1.0.0",
          "dbt-core>=1.8.0",
          "boto3; extra == \"glue\"",
          "mypy-boto3-glue; extra == \"glue\"",
          "duckdb==1.4.1; extra == \"md\""
        ],
        "requires_python": ">=3.9",
        "provides_extra": [
          "glue",
          "md"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/dbt_duckdb-1.10.0.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "click",
        "version": "8.3.1",
        "summary": "Composable command line interface toolkit",
        "description": "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/pallets/click/refs/heads/stable/docs/_static/click-name.svg\" alt=\"\" height=\"150\"></div>\n\n# Click\n\nClick is a Python package for creating beautiful command line interfaces\nin a composable way with as little code as necessary. It's the \"Command\nLine Interface Creation Kit\". It's highly configurable but comes with\nsensible defaults out of the box.\n\nIt aims to make the process of writing command line tools quick and fun\nwhile also preventing any frustration caused by the inability to\nimplement an intended CLI API.\n\nClick in three points:\n\n-   Arbitrary nesting of commands\n-   Automatic help page generation\n-   Supports lazy loading of subcommands at runtime\n\n\n## A Simple Example\n\n```python\nimport click\n\n@click.command()\n@click.option(\"--count\", default=1, help=\"Number of greetings.\")\n@click.option(\"--name\", prompt=\"Your name\", help=\"The person to greet.\")\ndef hello(count, name):\n    \"\"\"Simple program that greets NAME for a total of COUNT times.\"\"\"\n    for _ in range(count):\n        click.echo(f\"Hello, {name}!\")\n\nif __name__ == '__main__':\n    hello()\n```\n\n```\n$ python hello.py --count=3\nYour name: Click\nHello, Click!\nHello, Click!\nHello, Click!\n```\n\n\n## Donate\n\nThe Pallets organization develops and supports Click and other popular\npackages. In order to grow the community of contributors and users, and\nallow the maintainers to devote more time to the projects, [please\ndonate today][].\n\n[please donate today]: https://palletsprojects.com/donate\n\n## Contributing\n\nSee our [detailed contributing documentation][contrib] for many ways to\ncontribute, including reporting issues, requesting features, asking or answering\nquestions, and making PRs.\n\n[contrib]: https://palletsprojects.com/contributing/\n\n",
        "description_content_type": "text/markdown",
        "maintainer_email": "Pallets <contact@palletsprojects.com>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "colorama; platform_system == 'Windows'"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Changes, https://click.palletsprojects.com/page/changes/",
          "Chat, https://discord.gg/pallets",
          "Documentation, https://click.palletsprojects.com/",
          "Donate, https://palletsprojects.com/donate",
          "Source, https://github.com/pallets/click/"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/click-8.3.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "dbt-postgres",
        "version": "1.10.0",
        "summary": "The set of adapter protocols and base functionality that supports integration with dbt-core",
        "description": "<p align=\"center\">\n    <img\n        src=\"https://raw.githubusercontent.com/dbt-labs/dbt/ec7dee39f793aa4f7dd3dae37282cc87664813e4/etc/dbt-logo-full.svg\"\n        alt=\"dbt logo\"\n        width=\"500\"\n    />\n</p>\n\n<p align=\"center\">\n    <a href=\"https://pypi.org/project/dbt-postgres/\">\n        <img src=\"https://badge.fury.io/py/dbt-postgres.svg\" />\n    </a>\n    <a target=\"_blank\" href=\"https://pypi.org/project/dbt-postgres/\" style=\"background:none\">\n        <img src=\"https://img.shields.io/pypi/pyversions/dbt-postgres\">\n    </a>\n    <a href=\"https://github.com/psf/black\">\n        <img src=\"https://img.shields.io/badge/code%20style-black-000000.svg\" />\n    </a>\n    <a href=\"https://github.com/python/mypy\">\n        <img src=\"https://www.mypy-lang.org/static/mypy_badge.svg\" />\n    </a>\n    <a href=\"https://pepy.tech/project/dbt-postgres\">\n        <img src=\"https://static.pepy.tech/badge/dbt-postgres/month\" />\n    </a>\n</p>\n\n# dbt\n\n**[dbt](https://www.getdbt.com/)** enables data analysts and engineers to transform their data using the same practices that software engineers use to build applications.\n\ndbt is the T in ELT. Organize, cleanse, denormalize, filter, rename, and pre-aggregate the raw data in your warehouse so that it's ready for analysis.\n\n## dbt-postgres\n\n`dbt-postgres` enables dbt to work with Postgres.\nFor more information on using dbt with Postgres, consult [the docs](https://docs.getdbt.com/docs/profile-postgres).\n\n# Getting started\n\nReview the repository [README.md](../README.md) as most of that information pertains to `dbt-postgres`.\n\n### psycopg2-binary vs. psycopg2\n\nBy default, `dbt-postgres` installs `psycopg2-binary`.\nThis is great for development, and even testing, as it does not require any OS dependencies; it's a pre-built wheel.\nHowever, building `psycopg2` from source will grant performance improvements that are desired in a production environment.\nIn order to install `psycopg2`, use the following steps:\n\n```bash\nif [[ $(pip show psycopg2-binary) ]]; then\n    PSYCOPG2_VERSION=$(pip show psycopg2-binary | grep Version | cut -d \" \" -f 2)\n    pip uninstall -y psycopg2-binary\n    pip install psycopg2==$PSYCOPG2_VERSION\nfi\n```\n\nThis ensures the version of `psycopg2` will match that of `psycopg2-binary`.\n\n## Contribute\n\n- Want to help us build `dbt-postgres`? Check out the [Contributing Guide](CONTRIBUTING.md).\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "adapter",
          "adapters",
          "database",
          "dbt",
          "dbt Cloud",
          "dbt Core",
          "dbt Labs",
          "dbt-core",
          "elt",
          "postgres"
        ],
        "author_email": "dbt Labs <info@dbtlabs.com>",
        "maintainer_email": "dbt Labs <info@dbtlabs.com>",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "License :: OSI Approved :: Apache Software License",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX :: Linux",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "agate<2.0,>=1.0",
          "dbt-adapters<2.0,>=1.19.0",
          "dbt-common<2.0,>=1.0.4",
          "dbt-core>=1.8.0rc1",
          "psycopg2-binary<3.0,>=2.9"
        ],
        "requires_python": ">=3.10.0",
        "project_url": [
          "Homepage, https://github.com/dbt-labs/dbt-adapters/tree/main/dbt-postgres",
          "Documentation, https://docs.getdbt.com",
          "Repository, https://github.com/dbt-labs/dbt-adapters.git#subdirectory=dbt-postgres",
          "Issues, https://github.com/dbt-labs/dbt-adapters/issues",
          "Changelog, https://github.com/dbt-labs/dbt-adapters/blob/main/dbt-postgres/CHANGELOG.md"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/dbt_postgres-1.10.0.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "pydantic",
        "version": "2.12.5",
        "summary": "Data validation using Python type hints",
        "description": "# Pydantic Validation\n\n[![CI](https://img.shields.io/github/actions/workflow/status/pydantic/pydantic/ci.yml?branch=main&logo=github&label=CI)](https://github.com/pydantic/pydantic/actions?query=event%3Apush+branch%3Amain+workflow%3ACI)\n[![Coverage](https://coverage-badge.samuelcolvin.workers.dev/pydantic/pydantic.svg)](https://coverage-badge.samuelcolvin.workers.dev/redirect/pydantic/pydantic)\n[![pypi](https://img.shields.io/pypi/v/pydantic.svg)](https://pypi.python.org/pypi/pydantic)\n[![CondaForge](https://img.shields.io/conda/v/conda-forge/pydantic.svg)](https://anaconda.org/conda-forge/pydantic)\n[![downloads](https://static.pepy.tech/badge/pydantic/month)](https://pepy.tech/project/pydantic)\n[![versions](https://img.shields.io/pypi/pyversions/pydantic.svg)](https://github.com/pydantic/pydantic)\n[![license](https://img.shields.io/github/license/pydantic/pydantic.svg)](https://github.com/pydantic/pydantic/blob/main/LICENSE)\n[![Pydantic v2](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json)](https://docs.pydantic.dev/latest/contributing/#badges)\n[![llms.txt](https://img.shields.io/badge/llms.txt-green)](https://docs.pydantic.dev/latest/llms.txt)\n\nData validation using Python type hints.\n\nFast and extensible, Pydantic plays nicely with your linters/IDE/brain.\nDefine how data should be in pure, canonical Python 3.9+; validate it with Pydantic.\n\n## Pydantic Logfire :fire:\n\nWe've recently launched Pydantic Logfire to help you monitor your applications.\n[Learn more](https://pydantic.dev/articles/logfire-announcement)\n\n## Pydantic V1.10 vs. V2\n\nPydantic V2 is a ground-up rewrite that offers many new features, performance improvements, and some breaking changes compared to Pydantic V1.\n\nIf you're using Pydantic V1 you may want to look at the\n[pydantic V1.10 Documentation](https://docs.pydantic.dev/) or,\n[`1.10.X-fixes` git branch](https://github.com/pydantic/pydantic/tree/1.10.X-fixes). Pydantic V2 also ships with the latest version of Pydantic V1 built in so that you can incrementally upgrade your code base and projects: `from pydantic import v1 as pydantic_v1`.\n\n## Help\n\nSee [documentation](https://docs.pydantic.dev/) for more details.\n\n## Installation\n\nInstall using `pip install -U pydantic` or `conda install pydantic -c conda-forge`.\nFor more installation options to make Pydantic even faster,\nsee the [Install](https://docs.pydantic.dev/install/) section in the documentation.\n\n## A Simple Example\n\n```python\nfrom datetime import datetime\nfrom typing import Optional\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    id: int\n    name: str = 'John Doe'\n    signup_ts: Optional[datetime] = None\n    friends: list[int] = []\n\nexternal_data = {'id': '123', 'signup_ts': '2017-06-01 12:22', 'friends': [1, '2', b'3']}\nuser = User(**external_data)\nprint(user)\n#> User id=123 name='John Doe' signup_ts=datetime.datetime(2017, 6, 1, 12, 22) friends=[1, 2, 3]\nprint(user.id)\n#> 123\n```\n\n## Contributing\n\nFor guidance on setting up a development environment and how to make a\ncontribution to Pydantic, see\n[Contributing to Pydantic](https://docs.pydantic.dev/contributing/).\n\n## Reporting a Security Vulnerability\n\nSee our [security policy](https://github.com/pydantic/pydantic/security/policy).\n\n## Changelog\n\n<!-- markdownlint-disable no-bare-urls -->\n<!-- markdownlint-disable descriptive-link-text -->\n<!-- markdownlint-disable-next-line first-line-heading -->\n\n## v2.12.5 (2025-11-26)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.5)\n\nThis is the fifth 2.12 patch release, addressing an issue with the `MISSING` sentinel and providing several documentation improvements.\n\nThe next 2.13 minor release will be published in a couple weeks, and will include a new *polymorphic serialization* feature addressing\nthe remaining unexpected changes to the *serialize as any* behavior.\n\n* Fix pickle error when using `model_construct()` on a model with `MISSING` as a default value by [@ornariece](https://github.com/ornariece) in [#12522](https://github.com/pydantic/pydantic/pull/12522).\n* Several updates to the documentation by [@Viicos](https://github.com/Viicos).\n\n## v2.12.4 (2025-11-05)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.4)\n\nThis is the fourth 2.12 patch release, fixing more regressions, and reverting a change in the `build()` method\nof the [`AnyUrl` and Dsn types](https://docs.pydantic.dev/latest/api/networks/).\n\nThis patch release also fixes an issue with the serialization of IP address types, when `serialize_as_any` is used. The next patch release\nwill try to address the remaining issues with *serialize as any* behavior by introducing a new *polymorphic serialization* feature, that\nshould be used in most cases in place of *serialize as any*.\n\n* Fix issue with forward references in parent `TypedDict` classes by [@Viicos](https://github.com/Viicos) in [#12427](https://github.com/pydantic/pydantic/pull/12427).\n\n    This issue is only relevant on Python 3.14 and greater.\n* Exclude fields with `exclude_if` from JSON Schema required fields by [@Viicos](https://github.com/Viicos) in [#12430](https://github.com/pydantic/pydantic/pull/12430)\n* Revert URL percent-encoding of credentials in the `build()` method\n  of the [`AnyUrl` and Dsn types](https://docs.pydantic.dev/latest/api/networks/) by [@davidhewitt](https://github.com/davidhewitt) in\n  [pydantic-core#1833](https://github.com/pydantic/pydantic-core/pull/1833).\n\n    This was initially considered as a bugfix, but caused regressions and as such was fully reverted. The next release will include\n    an opt-in option to percent-encode components of the URL.\n* Add type inference for IP address types by [@davidhewitt](https://github.com/davidhewitt) in [pydantic-core#1868](https://github.com/pydantic/pydantic-core/pull/1868).\n\n    The 2.12 changes to the `serialize_as_any` behavior made it so that IP address types could not properly serialize to JSON.\n* Avoid getting default values from defaultdict by [@davidhewitt](https://github.com/davidhewitt) in [pydantic-core#1853](https://github.com/pydantic/pydantic-core/pull/1853).\n\n    This fixes a subtle regression in the validation behavior of the [`collections.defaultdict`](https://docs.python.org/3/library/collections.html#collections.defaultdict)\n    type.\n* Fix issue with field serializers on nested typed dictionaries by [@davidhewitt](https://github.com/davidhewitt) in [pydantic-core#1879](https://github.com/pydantic/pydantic-core/pull/1879).\n* Add more `pydantic-core` builds for the three-threaded version of Python 3.14 by [@davidhewitt](https://github.com/davidhewitt) in [pydantic-core#1864](https://github.com/pydantic/pydantic-core/pull/1864).\n\n## v2.12.3 (2025-10-17)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.3)\n\n### What's Changed\n\nThis is the third 2.12 patch release, fixing issues related to the `FieldInfo` class, and reverting a change to the supported\n[*after* model validator](https://docs.pydantic.dev/latest/concepts/validators/#model-validators) function signatures.\n\n* Raise a warning when an invalid after model validator function signature is raised by [@Viicos](https://github.com/Viicos) in [#12414](https://github.com/pydantic/pydantic/pull/12414).\n  Starting in 2.12.0, using class methods for *after* model validators raised an error, but the error wasn't raised concistently. We decided\n  to emit a deprecation warning instead.\n* Add [`FieldInfo.asdict()`](https://docs.pydantic.dev/latest/api/fields/#pydantic.fields.FieldInfo.asdict) method, improve documentation around `FieldInfo` by [@Viicos](https://github.com/Viicos) in [#12411](https://github.com/pydantic/pydantic/pull/12411).\n  This also add back support for mutations on `FieldInfo` classes, that are reused as `Annotated` metadata. **However**, note that this is still\n  *not* a supported pattern. Instead, please refer to the [added example](https://docs.pydantic.dev/latest/examples/dynamic_models/) in the documentation.\n\nThe [blog post](https://pydantic.dev/articles/pydantic-v2-12-release#changes) section on changes was also updated to document the changes related to `serialize_as_any`.\n\n## v2.12.2 (2025-10-14)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.2)\n\n### What's Changed\n\n#### Fixes\n\n* Release a new `pydantic-core` version, as a corrupted CPython 3.10 `manylinux2014_aarch64` wheel got uploaded ([pydantic-core#1843](https://github.com/pydantic/pydantic-core/pull/1843)).\n* Fix issue with recursive generic models with a parent model class by [@Viicos](https://github.com/Viicos) in [#12398](https://github.com/pydantic/pydantic/pull/12398)\n\n## v2.12.1 (2025-10-13)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.1)\n\n### What's Changed\n\nThis is the first 2.12 patch release, addressing most (but not all yet) regressions from the initial 2.12.0 release.\n\n#### Fixes\n\n* Do not evaluate annotations when inspecting validators and serializers by [@Viicos](https://github.com/Viicos) in [#12355](https://github.com/pydantic/pydantic/pull/12355)\n* Make sure `None` is converted as `NoneType` in Python 3.14 by [@Viicos](https://github.com/Viicos) in [#12370](https://github.com/pydantic/pydantic/pull/12370)\n* Backport V1 runtime warning when using Python 3.14 by [@Viicos](https://github.com/Viicos) in [#12367](https://github.com/pydantic/pydantic/pull/12367)\n* Fix error message for invalid validator signatures by [@Viicos](https://github.com/Viicos) in [#12366](https://github.com/pydantic/pydantic/pull/12366)\n* Populate field name in `ValidationInfo` for validation of default value by [@Viicos](https://github.com/Viicos) in [pydantic-core#1826](https://github.com/pydantic/pydantic-core/pull/1826)\n* Encode credentials in `MultiHostUrl` builder by [@willswire](https://github.com/willswire) in [pydantic-core#1829](https://github.com/pydantic/pydantic-core/pull/1829)\n* Respect field serializers when using `serialize_as_any` serialization flag by [@davidhewitt](https://github.com/davidhewitt) in [pydantic-core#1829](https://github.com/pydantic/pydantic-core/pull/1829)\n* Fix various `RootModel` serialization issues by [@davidhewitt](https://github.com/davidhewitt) in [pydantic-core#1836](https://github.com/pydantic/pydantic-core/pull/1836)\n\n### New Contributors\n\n* [@willswire](https://github.com/willswire) made their first contribution in [pydantic-core#1829](https://github.com/pydantic/pydantic-core/pull/1829)\n\n## v2.12.0 (2025-10-07)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.0)\n\n### What's Changed\n\nThis is the final 2.12 release. It features the work of 20 external contributors and provides useful new features, along with initial Python 3.14 support.\nSeveral minor changes (considered non-breaking changes according to our [versioning policy](https://docs.pydantic.dev/2.12/version-policy/#pydantic-v2))\nare also included in this release. Make sure to look into them before upgrading.\n\n**Note that Pydantic V1 is not compatible with Python 3.14 and greater**.\n\nChanges (see the alpha and beta releases for additional changes since 2.11):\n\n#### Packaging\n\n* Update V1 copy to v1.10.24 by [@Viicos](https://github.com/Viicos) in [#12338](https://github.com/pydantic/pydantic/pull/12338)\n\n#### New Features\n\n* Add `extra` parameter to the validate functions by [@anvilpete](https://github.com/anvilpete) in [#12233](https://github.com/pydantic/pydantic/pull/12233)\n* Add `exclude_computed_fields` serialization option by [@Viicos](https://github.com/Viicos) in [#12334](https://github.com/pydantic/pydantic/pull/12334)\n* Add `preverse_empty_path` URL options by [@Viicos](https://github.com/Viicos) in [#12336](https://github.com/pydantic/pydantic/pull/12336)\n* Add `union_format` parameter to JSON Schema generation by [@Viicos](https://github.com/Viicos) in [#12147](https://github.com/pydantic/pydantic/pull/12147)\n* Add `__qualname__` parameter for `create_model` by [@Atry](https://github.com/Atry) in [#12001](https://github.com/pydantic/pydantic/pull/12001)\n\n#### Fixes\n\n* Do not try to infer name from lambda definitions in pipelines API by [@Viicos](https://github.com/Viicos) in [#12289](https://github.com/pydantic/pydantic/pull/12289)\n* Use proper namespace for functions in `TypeAdapter` by [@Viicos](https://github.com/Viicos) in [#12324](https://github.com/pydantic/pydantic/pull/12324)\n* Use `Any` for context type annotation in `TypeAdapter` by [@inducer](https://github.com/inducer) in [#12279](https://github.com/pydantic/pydantic/pull/12279)\n* Expose `FieldInfo` in `pydantic.fields.__all__` by [@Viicos](https://github.com/Viicos) in [#12339](https://github.com/pydantic/pydantic/pull/12339)\n* Respect `validation_alias` in `@validate_call` by [@Viicos](https://github.com/Viicos) in [#12340](https://github.com/pydantic/pydantic/pull/12340)\n* Use `Any` as context annotation in plugin API by [@Viicos](https://github.com/Viicos) in [#12341](https://github.com/pydantic/pydantic/pull/12341)\n* Use proper `stacklevel` in warnings when possible by [@Viicos](https://github.com/Viicos) in [#12342](https://github.com/pydantic/pydantic/pull/12342)\n\n### New Contributors\n\n* [@anvilpete](https://github.com/anvilpete) made their first contribution in [#12233](https://github.com/pydantic/pydantic/pull/12233)\n* [@JonathanWindell](https://github.com/JonathanWindell) made their first contribution in [#12327](https://github.com/pydantic/pydantic/pull/12327)\n* [@inducer](https://github.com/inducer) made their first contribution in [#12279](https://github.com/pydantic/pydantic/pull/12279)\n* [@Atry](https://github.com/Atry) made their first contribution in [#12001](https://github.com/pydantic/pydantic/pull/12001)\n\n## v2.12.0b1 (2025-10-03)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.0b1)\n\nThis is the first beta release of the upcoming 2.12 release.\n\n### What's Changed\n\n#### Packaging\n\n* Bump `pydantic-core` to v2.40.1 by [@Viicos](https://github.com/Viicos) in [#12314](https://github.com/pydantic/pydantic/pull/12314)\n\n#### New Features\n\n* Add support for `exclude_if` at the field level by [@andresliszt](https://github.com/andresliszt) in [#12141](https://github.com/pydantic/pydantic/pull/12141)\n* Add `ValidateAs` annotation helper by [@Viicos](https://github.com/Viicos) in [#11942](https://github.com/pydantic/pydantic/pull/11942)\n* Add configuration options for validation and JSON serialization of temporal types by [@ollz272](https://github.com/ollz272) in [#12068](https://github.com/pydantic/pydantic/pull/12068)\n* Add support for PEP 728 by [@Viicos](https://github.com/Viicos) in [#12179](https://github.com/pydantic/pydantic/pull/12179)\n* Add field name in serialization error by [@NicolasPllr1](https://github.com/NicolasPllr1) in [pydantic-core#1799](https://github.com/pydantic/pydantic-core/pull/1799)\n* Add option to preserve empty URL paths by [@davidhewitt](https://github.com/davidhewitt) in [pydantic-core#1789](https://github.com/pydantic/pydantic-core/pull/1789)\n\n#### Changes\n\n* Raise error if an incompatible `pydantic-core` version is installed by [@Viicos](https://github.com/Viicos) in [#12196](https://github.com/pydantic/pydantic/pull/12196)\n* Remove runtime warning for experimental features by [@Viicos](https://github.com/Viicos) in [#12265](https://github.com/pydantic/pydantic/pull/12265)\n* Warn if registering virtual subclasses on Pydantic models by [@Viicos](https://github.com/Viicos) in [#11669](https://github.com/pydantic/pydantic/pull/11669)\n\n#### Fixes\n\n* Fix `__getattr__()` behavior on Pydantic models when a property raised an `AttributeError` and extra values are present by [@raspuchin](https://github.com/raspuchin) in [#12106](https://github.com/pydantic/pydantic/pull/12106)\n* Add test to prevent regression with Pydantic models used as annotated metadata by [@Viicos](https://github.com/Viicos) in [#12133](https://github.com/pydantic/pydantic/pull/12133)\n* Allow to use property setters on Pydantic dataclasses with `validate_assignment` set by [@Viicos](https://github.com/Viicos) in [#12173](https://github.com/pydantic/pydantic/pull/12173)\n* Fix mypy v2 plugin for upcoming mypy release by [@cdce8p](https://github.com/cdce8p) in [#12209](https://github.com/pydantic/pydantic/pull/12209)\n* Respect custom title in functions JSON Schema by [@Viicos](https://github.com/Viicos) in [#11892](https://github.com/pydantic/pydantic/pull/11892)\n* Fix `ImportString` JSON serialization for objects with a `name` attribute by [@chr1sj0nes](https://github.com/chr1sj0nes) in [#12219](https://github.com/pydantic/pydantic/pull/12219)\n* Do not error on fields overridden by methods in the mypy plugin by [@Viicos](https://github.com/Viicos) in [#12290](https://github.com/pydantic/pydantic/pull/12290)\n\n### New Contributors\n\n* [@raspuchin](https://github.com/raspuchin) made their first contribution in [#12106](https://github.com/pydantic/pydantic/pull/12106)\n* [@chr1sj0nes](https://github.com/chr1sj0nes) made their first contribution in [#12219](https://github.com/pydantic/pydantic/pull/12219)\n\n## v2.12.0a1 (2025-07-26)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.0a1)\n\nThis is the first alpha release of the upcoming 2.12 release, which adds initial support for Python 3.14.\n\n### What's Changed\n\n#### New Features\n\n* Add `__pydantic_on_complete__()` hook that is called once model is fully ready to be used by [@DouweM](https://github.com/DouweM) in [#11762](https://github.com/pydantic/pydantic/pull/11762)\n* Add initial support for Python 3.14 by [@Viicos](https://github.com/Viicos) in [#11991](https://github.com/pydantic/pydantic/pull/11991)\n* Add regex patterns to JSON schema for `Decimal` type by [@Dima-Bulavenko](https://github.com/Dima-Bulavenko) in [#11987](https://github.com/pydantic/pydantic/pull/11987)\n* Add support for `doc` attribute on dataclass fields by [@Viicos](https://github.com/Viicos) in [#12077](https://github.com/pydantic/pydantic/pull/12077)\n* Add experimental `MISSING` sentinel by [@Viicos](https://github.com/Viicos) in [#11883](https://github.com/pydantic/pydantic/pull/11883)\n\n#### Changes\n\n* Allow config and bases to be specified together in `create_model()` by [@Viicos](https://github.com/Viicos) in [#11714](https://github.com/pydantic/pydantic/pull/11714)\n* Move some field logic out of the `GenerateSchema` class by [@Viicos](https://github.com/Viicos) in [#11733](https://github.com/pydantic/pydantic/pull/11733)\n* Always make use of `inspect.getsourcelines()` for docstring extraction on Python 3.13 and greater by [@Viicos](https://github.com/Viicos) in [#11829](https://github.com/pydantic/pydantic/pull/11829)\n* Only support the latest Mypy version by [@Viicos](https://github.com/Viicos) in [#11832](https://github.com/pydantic/pydantic/pull/11832)\n* Do not implicitly convert after model validators to class methods by [@Viicos](https://github.com/Viicos) in [#11957](https://github.com/pydantic/pydantic/pull/11957)\n* Refactor `FieldInfo` creation implementation by [@Viicos](https://github.com/Viicos) in [#11898](https://github.com/pydantic/pydantic/pull/11898)\n* Make `Secret` covariant by [@bluenote10](https://github.com/bluenote10) in [#12008](https://github.com/pydantic/pydantic/pull/12008)\n* Emit warning when field-specific metadata is used in invalid contexts by [@Viicos](https://github.com/Viicos) in [#12028](https://github.com/pydantic/pydantic/pull/12028)\n\n#### Fixes\n\n* Properly fetch plain serializer function when serializing default value in JSON Schema by [@Viicos](https://github.com/Viicos) in [#11721](https://github.com/pydantic/pydantic/pull/11721)\n* Remove generics cache workaround by [@Viicos](https://github.com/Viicos) in [#11755](https://github.com/pydantic/pydantic/pull/11755)\n* Remove coercion of decimal constraints by [@Viicos](https://github.com/Viicos) in [#11772](https://github.com/pydantic/pydantic/pull/11772)\n* Fix crash when expanding root type in the mypy plugin by [@Viicos](https://github.com/Viicos) in [#11735](https://github.com/pydantic/pydantic/pull/11735)\n* Only mark model as complete once all fields are complete by [@DouweM](https://github.com/DouweM) in [#11759](https://github.com/pydantic/pydantic/pull/11759)\n* Do not provide `field_name` in validator core schemas by [@DouweM](https://github.com/DouweM) in [#11761](https://github.com/pydantic/pydantic/pull/11761)\n* Fix issue with recursive generic models by [@Viicos](https://github.com/Viicos) in [#11775](https://github.com/pydantic/pydantic/pull/11775)\n* Fix qualified name comparison of private attributes during namespace inspection by [@karta9821](https://github.com/karta9821) in [#11803](https://github.com/pydantic/pydantic/pull/11803)\n* Make sure Pydantic dataclasses with slots and `validate_assignment` can be unpickled by [@Viicos](https://github.com/Viicos) in [#11769](https://github.com/pydantic/pydantic/pull/11769)\n* Traverse `function-before` schemas during schema gathering by [@Viicos](https://github.com/Viicos) in [#11801](https://github.com/pydantic/pydantic/pull/11801)\n* Fix check for stdlib dataclasses by [@Viicos](https://github.com/Viicos) in [#11822](https://github.com/pydantic/pydantic/pull/11822)\n* Check if `FieldInfo` is complete after applying type variable map by [@Viicos](https://github.com/Viicos) in [#11855](https://github.com/pydantic/pydantic/pull/11855)\n* Do not delete mock validator/serializer in `model_rebuild()` by [@Viicos](https://github.com/Viicos) in [#11890](https://github.com/pydantic/pydantic/pull/11890)\n* Rebuild dataclass fields before schema generation by [@Viicos](https://github.com/Viicos) in [#11949](https://github.com/pydantic/pydantic/pull/11949)\n* Always store the original field assignment on `FieldInfo` by [@Viicos](https://github.com/Viicos) in [#11946](https://github.com/pydantic/pydantic/pull/11946)\n* Do not use deprecated methods as default field values by [@Viicos](https://github.com/Viicos) in [#11914](https://github.com/pydantic/pydantic/pull/11914)\n* Allow callable discriminator to be applied on PEP 695 type aliases by [@Viicos](https://github.com/Viicos) in [#11941](https://github.com/pydantic/pydantic/pull/11941)\n* Suppress core schema generation warning when using `SkipValidation` by [@ygsh0816](https://github.com/ygsh0816) in [#12002](https://github.com/pydantic/pydantic/pull/12002)\n* Do not emit typechecking error for invalid `Field()` default with `validate_default` set to `True` by [@Viicos](https://github.com/Viicos) in [#11988](https://github.com/pydantic/pydantic/pull/11988)\n* Refactor logic to support Pydantic's `Field()` function in dataclasses by [@Viicos](https://github.com/Viicos) in [#12051](https://github.com/pydantic/pydantic/pull/12051)\n\n#### Packaging\n\n* Update project metadata to use PEP 639 by [@Viicos](https://github.com/Viicos) in [#11694](https://github.com/pydantic/pydantic/pull/11694)\n* Bump `mkdocs-llmstxt` to v0.2.0 by [@Viicos](https://github.com/Viicos) in [#11725](https://github.com/pydantic/pydantic/pull/11725)\n* Bump `pydantic-core` to v2.35.1 by [@Viicos](https://github.com/Viicos) in [#11963](https://github.com/pydantic/pydantic/pull/11963)\n* Bump dawidd6/action-download-artifact from 10 to 11 by [@dependabot](https://github.com/dependabot)[bot] in [#12033](https://github.com/pydantic/pydantic/pull/12033)\n* Bump astral-sh/setup-uv from 5 to 6 by [@dependabot](https://github.com/dependabot)[bot] in [#11826](https://github.com/pydantic/pydantic/pull/11826)\n* Update mypy to 1.17.0 by [@Viicos](https://github.com/Viicos) in [#12076](https://github.com/pydantic/pydantic/pull/12076)\n\n### New Contributors\n\n* [@parth-paradkar](https://github.com/parth-paradkar) made their first contribution in [#11695](https://github.com/pydantic/pydantic/pull/11695)\n* [@dqkqd](https://github.com/dqkqd) made their first contribution in [#11739](https://github.com/pydantic/pydantic/pull/11739)\n* [@fhightower](https://github.com/fhightower) made their first contribution in [#11722](https://github.com/pydantic/pydantic/pull/11722)\n* [@gbaian10](https://github.com/gbaian10) made their first contribution in [#11766](https://github.com/pydantic/pydantic/pull/11766)\n* [@DouweM](https://github.com/DouweM) made their first contribution in [#11759](https://github.com/pydantic/pydantic/pull/11759)\n* [@bowenliang123](https://github.com/bowenliang123) made their first contribution in [#11719](https://github.com/pydantic/pydantic/pull/11719)\n* [@rawwar](https://github.com/rawwar) made their first contribution in [#11799](https://github.com/pydantic/pydantic/pull/11799)\n* [@karta9821](https://github.com/karta9821) made their first contribution in [#11803](https://github.com/pydantic/pydantic/pull/11803)\n* [@jinnovation](https://github.com/jinnovation) made their first contribution in [#11834](https://github.com/pydantic/pydantic/pull/11834)\n* [@zmievsa](https://github.com/zmievsa) made their first contribution in [#11861](https://github.com/pydantic/pydantic/pull/11861)\n* [@Otto-AA](https://github.com/Otto-AA) made their first contribution in [#11860](https://github.com/pydantic/pydantic/pull/11860)\n* [@ygsh0816](https://github.com/ygsh0816) made their first contribution in [#12002](https://github.com/pydantic/pydantic/pull/12002)\n* [@lukland](https://github.com/lukland) made their first contribution in [#12015](https://github.com/pydantic/pydantic/pull/12015)\n* [@Dima-Bulavenko](https://github.com/Dima-Bulavenko) made their first contribution in [#11987](https://github.com/pydantic/pydantic/pull/11987)\n* [@GSemikozov](https://github.com/GSemikozov) made their first contribution in [#12050](https://github.com/pydantic/pydantic/pull/12050)\n* [@hannah-heywa](https://github.com/hannah-heywa) made their first contribution in [#12082](https://github.com/pydantic/pydantic/pull/12082)\n\n## v2.11.7 (2025-06-14)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.7)\n\n### What's Changed\n\n#### Fixes\n\n* Copy `FieldInfo` instance if necessary during `FieldInfo` build by [@Viicos](https://github.com/Viicos) in [#11898](https://github.com/pydantic/pydantic/pull/11898)\n\n## v2.11.6 (2025-06-13)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.6)\n\n### What's Changed\n\n#### Fixes\n\n* Rebuild dataclass fields before schema generation by [@Viicos](https://github.com/Viicos) in [#11949](https://github.com/pydantic/pydantic/pull/11949)\n* Always store the original field assignment on `FieldInfo` by [@Viicos](https://github.com/Viicos) in [#11946](https://github.com/pydantic/pydantic/pull/11946)\n\n## v2.11.5 (2025-05-22)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.5)\n\n### What's Changed\n\n#### Fixes\n\n* Check if `FieldInfo` is complete after applying type variable map by [@Viicos](https://github.com/Viicos) in [#11855](https://github.com/pydantic/pydantic/pull/11855)\n* Do not delete mock validator/serializer in `model_rebuild()` by [@Viicos](https://github.com/Viicos) in [#11890](https://github.com/pydantic/pydantic/pull/11890)\n* Do not duplicate metadata on model rebuild by [@Viicos](https://github.com/Viicos) in [#11902](https://github.com/pydantic/pydantic/pull/11902)\n\n## v2.11.4 (2025-04-29)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.4)\n\n### What's Changed\n\n#### Packaging\n\n* Bump `mkdocs-llmstxt` to v0.2.0 by [@Viicos](https://github.com/Viicos) in [#11725](https://github.com/pydantic/pydantic/pull/11725)\n\n#### Changes\n\n* Allow config and bases to be specified together in `create_model()` by [@Viicos](https://github.com/Viicos) in [#11714](https://github.com/pydantic/pydantic/pull/11714).\n  This change was backported as it was previously possible (although not meant to be supported)\n  to provide `model_config` as a field, which would make it possible to provide both configuration\n  and bases.\n\n#### Fixes\n\n* Remove generics cache workaround by [@Viicos](https://github.com/Viicos) in [#11755](https://github.com/pydantic/pydantic/pull/11755)\n* Remove coercion of decimal constraints by [@Viicos](https://github.com/Viicos) in [#11772](https://github.com/pydantic/pydantic/pull/11772)\n* Fix crash when expanding root type in the mypy plugin by [@Viicos](https://github.com/Viicos) in [#11735](https://github.com/pydantic/pydantic/pull/11735)\n* Fix issue with recursive generic models by [@Viicos](https://github.com/Viicos) in [#11775](https://github.com/pydantic/pydantic/pull/11775)\n* Traverse `function-before` schemas during schema gathering by [@Viicos](https://github.com/Viicos) in [#11801](https://github.com/pydantic/pydantic/pull/11801)\n\n## v2.11.3 (2025-04-08)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.3)\n\n### What's Changed\n\n#### Packaging\n\n* Update V1 copy to v1.10.21 by [@Viicos](https://github.com/Viicos) in [#11706](https://github.com/pydantic/pydantic/pull/11706)\n\n#### Fixes\n\n* Preserve field description when rebuilding model fields by [@Viicos](https://github.com/Viicos) in [#11698](https://github.com/pydantic/pydantic/pull/11698)\n\n## v2.11.2 (2025-04-03)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.2)\n\n### What's Changed\n\n#### Fixes\n\n* Bump `pydantic-core` to v2.33.1 by [@Viicos](https://github.com/Viicos) in [#11678](https://github.com/pydantic/pydantic/pull/11678)\n* Make sure `__pydantic_private__` exists before setting private attributes by [@Viicos](https://github.com/Viicos) in [#11666](https://github.com/pydantic/pydantic/pull/11666)\n* Do not override `FieldInfo._complete` when using field from parent class by [@Viicos](https://github.com/Viicos) in [#11668](https://github.com/pydantic/pydantic/pull/11668)\n* Provide the available definitions when applying discriminated unions by [@Viicos](https://github.com/Viicos) in [#11670](https://github.com/pydantic/pydantic/pull/11670)\n* Do not expand root type in the mypy plugin for variables by [@Viicos](https://github.com/Viicos) in [#11676](https://github.com/pydantic/pydantic/pull/11676)\n* Mention the attribute name in model fields deprecation message by [@Viicos](https://github.com/Viicos) in [#11674](https://github.com/pydantic/pydantic/pull/11674)\n* Properly validate parameterized mappings by [@Viicos](https://github.com/Viicos) in [#11658](https://github.com/pydantic/pydantic/pull/11658)\n\n## v2.11.1 (2025-03-28)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.1)\n\n### What's Changed\n\n#### Fixes\n\n* Do not override `'definitions-ref'` schemas containing serialization schemas or metadata by [@Viicos](https://github.com/Viicos) in [#11644](https://github.com/pydantic/pydantic/pull/11644)\n\n## v2.11.0 (2025-03-27)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.0)\n\n### What's Changed\n\nPydantic v2.11 is a version strongly focused on build time performance of Pydantic models (and core schema generation in general).\nSee the [blog post](https://pydantic.dev/articles/pydantic-v2-11-release) for more details.\n\n#### Packaging\n\n* Bump `pydantic-core` to v2.33.0 by [@Viicos](https://github.com/Viicos) in [#11631](https://github.com/pydantic/pydantic/pull/11631)\n\n#### New Features\n\n* Add `encoded_string()` method to the URL types by [@YassinNouh21](https://github.com/YassinNouh21) in [#11580](https://github.com/pydantic/pydantic/pull/11580)\n* Add support for `defer_build` with `@validate_call` decorator by [@Viicos](https://github.com/Viicos) in [#11584](https://github.com/pydantic/pydantic/pull/11584)\n* Allow `@with_config` decorator to be used with keyword arguments by [@Viicos](https://github.com/Viicos) in [#11608](https://github.com/pydantic/pydantic/pull/11608)\n* Simplify customization of default value inclusion in JSON Schema generation by [@Viicos](https://github.com/Viicos) in [#11634](https://github.com/pydantic/pydantic/pull/11634)\n* Add `generate_arguments_schema()` function by [@Viicos](https://github.com/Viicos) in [#11572](https://github.com/pydantic/pydantic/pull/11572)\n\n#### Fixes\n\n* Allow generic typed dictionaries to be used for unpacked variadic keyword parameters by [@Viicos](https://github.com/Viicos) in [#11571](https://github.com/pydantic/pydantic/pull/11571)\n* Fix runtime error when computing model string representation involving cached properties and self-referenced models by [@Viicos](https://github.com/Viicos) in [#11579](https://github.com/pydantic/pydantic/pull/11579)\n* Preserve other steps when using the ellipsis in the pipeline API by [@Viicos](https://github.com/Viicos) in [#11626](https://github.com/pydantic/pydantic/pull/11626)\n* Fix deferred discriminator application logic by [@Viicos](https://github.com/Viicos) in [#11591](https://github.com/pydantic/pydantic/pull/11591)\n\n### New Contributors\n\n* [@cmenon12](https://github.com/cmenon12) made their first contribution in [#11562](https://github.com/pydantic/pydantic/pull/11562)\n* [@Jeukoh](https://github.com/Jeukoh) made their first contribution in [#11611](https://github.com/pydantic/pydantic/pull/11611)\n\n## v2.11.0b2 (2025-03-17)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.0b2)\n\n### What's Changed\n\n#### Packaging\n\n* Bump `pydantic-core` to v2.32.0 by [@Viicos](https://github.com/Viicos) in [#11567](https://github.com/pydantic/pydantic/pull/11567)\n\n#### New Features\n\n* Add experimental support for free threading by [@Viicos](https://github.com/Viicos) in [#11516](https://github.com/pydantic/pydantic/pull/11516)\n\n#### Fixes\n\n* Fix `NotRequired` qualifier not taken into account in stringified annotation by [@Viicos](https://github.com/Viicos) in [#11559](https://github.com/pydantic/pydantic/pull/11559)\n\n### New Contributors\n\n* [@joren485](https://github.com/joren485) made their first contribution in [#11547](https://github.com/pydantic/pydantic/pull/11547)\n\n## v2.11.0b1 (2025-03-06)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.0b1)\n\n### What's Changed\n\n#### Packaging\n\n* Add a `check_pydantic_core_version()` function by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11324\n* Remove `greenlet` development dependency by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11351\n* Use the `typing-inspection` library by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11479\n* Bump `pydantic-core` to `v2.31.1` by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11526\n\n#### New Features\n\n* Support unsubstituted type variables with both a default and a bound or constraints by [@FyZzyss](https://github.com/FyZzyss) in https://github.com/pydantic/pydantic/pull/10789\n* Add a `default_factory_takes_validated_data` property to `FieldInfo` by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11034\n* Raise a better error when a generic alias is used inside `type[]` by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11088\n* Properly support PEP 695 generics syntax by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11189\n* Properly support type variable defaults by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11332\n* Add support for validating v6, v7, v8 UUIDs by [@astei](https://github.com/astei) in https://github.com/pydantic/pydantic/pull/11436\n* Improve alias configuration APIs by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11468\n\n#### Changes\n\n* Rework `create_model` field definitions format by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11032\n* Raise a deprecation warning when a field is annotated as final with a default value by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11168\n* Deprecate accessing `model_fields` and `model_computed_fields` on instances by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11169\n* **Breaking Change:** Move core schema generation logic for path types inside the `GenerateSchema` class by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/10846\n* Remove Python 3.8 Support by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11258\n* Optimize calls to `get_type_ref` by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/10863\n* Disable `pydantic-core` core schema validation by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11271\n\n#### Performance\n\n* Only evaluate `FieldInfo` annotations if required during schema building by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/10769\n* Improve `__setattr__` performance of Pydantic models by caching setter functions by [@MarkusSintonen](https://github.com/MarkusSintonen) in https://github.com/pydantic/pydantic/pull/10868\n* Improve annotation application performance by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11186\n* Improve performance of `_typing_extra` module by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11255\n* Refactor and optimize schema cleaning logic by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11244\n* Create a single dictionary when creating a `CoreConfig` instance by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11384\n* Bump `pydantic-core` and thus use `SchemaValidator` and `SchemaSerializer` caching by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11402\n* Reuse cached core schemas for parametrized generic Pydantic models by [@MarkusSintonen](https://github.com/MarkusSintonen) in https://github.com/pydantic/pydantic/pull/11434\n\n#### Fixes\n\n* Improve `TypeAdapter` instance repr by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/10872\n* Use the correct frame when instantiating a parametrized `TypeAdapter` by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/10893\n* Infer final fields with a default value as class variables in the mypy plugin by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11121\n* Recursively unpack `Literal` values if using PEP 695 type aliases by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11114\n* Override `__subclasscheck__` on `ModelMetaclass` to avoid memory leak and performance issues by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11116\n* Remove unused `_extract_get_pydantic_json_schema()` parameter by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11155\n* Improve discriminated union error message for invalid union variants by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11161\n* Unpack PEP 695 type aliases if using the `Annotated` form by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11109\n* Add missing stacklevel in `deprecated_instance_property` warning by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11200\n* Copy `WithJsonSchema` schema to avoid sharing mutated data by [@thejcannon](https://github.com/thejcannon) in https://github.com/pydantic/pydantic/pull/11014\n* Do not cache parametrized models when in the process of parametrizing another model by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/10704\n* Add discriminated union related metadata entries to the `CoreMetadata` definition by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11216\n* Consolidate schema definitions logic in the `_Definitions` class by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11208\n* Support initializing root model fields with values of the `root` type in the mypy plugin by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11212\n* Fix various issues with dataclasses and `use_attribute_docstrings` by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11246\n* Only compute normalized decimal places if necessary in `decimal_places_validator` by [@misrasaurabh1](https://github.com/misrasaurabh1) in https://github.com/pydantic/pydantic/pull/11281\n* Add support for `validation_alias` in the mypy plugin by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11295\n* Fix JSON Schema reference collection with `\"examples\"` keys by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11305\n* Do not transform model serializer functions as class methods in the mypy plugin by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11298\n* Simplify `GenerateJsonSchema.literal_schema()` implementation by [@misrasaurabh1](https://github.com/misrasaurabh1) in https://github.com/pydantic/pydantic/pull/11321\n* Add additional allowed schemes for `ClickHouseDsn` by [@Maze21127](https://github.com/Maze21127) in https://github.com/pydantic/pydantic/pull/11319\n* Coerce decimal constraints to `Decimal` instances by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11350\n* Use the correct JSON Schema mode when handling function schemas by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11367\n* Improve exception message when encountering recursion errors during type evaluation by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11356\n* Always include `additionalProperties: True` for arbitrary dictionary schemas by [@austinyu](https://github.com/austinyu) in https://github.com/pydantic/pydantic/pull/11392\n* Expose `fallback` parameter in serialization methods by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11398\n* Fix path serialization behavior by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11416\n* Do not reuse validators and serializers during model rebuild by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11429\n* Collect model fields when rebuilding a model by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11388\n* Allow cached properties to be altered on frozen models by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11432\n* Fix tuple serialization for `Sequence` types by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11435\n* Fix: do not check for `__get_validators__` on classes where `__get_pydantic_core_schema__` is also defined by [@tlambert03](https://github.com/tlambert03) in https://github.com/pydantic/pydantic/pull/11444\n* Allow callable instances to be used as serializers by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11451\n* Improve error thrown when overriding field with a property by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11459\n* Fix JSON Schema generation with referenceable core schemas holding JSON metadata by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11475\n* Support strict specification on union member types by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11481\n* Implicitly set `validate_by_name` to `True` when `validate_by_alias` is `False` by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic/pull/11503\n* Change type of `Any` when synthesizing `BaseSettings.__init__` signature in the mypy plugin by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11497\n* Support type variable defaults referencing other type variables by [@Viicos](https://github.com/Viicos) in https://github.com/pydantic/pydantic/pull/11520\n* Fix `ValueError` on year zero by [@davidhewitt](https://github.com/davidhewitt) in https://github.com/pydantic/pydantic-core/pull/1583\n* `dataclass` `InitVar` shouldn't be required on serialization by [@sydney-runkle](https://github.com/sydney-runkle) in https://github.com/pydantic/pydantic-core/pull/1602\n\n## New Contributors\n\n* [@FyZzyss](https://github.com/FyZzyss) made their first contribution in https://github.com/pydantic/pydantic/pull/10789\n* [@tamird](https://github.com/tamird) made their first contribution in https://github.com/pydantic/pydantic/pull/10948\n* [@felixxm](https://github.com/felixxm) made their first contribution in https://github.com/pydantic/pydantic/pull/11077\n* [@alexprabhat99](https://github.com/alexprabhat99) made their first contribution in https://github.com/pydantic/pydantic/pull/11082\n* [@Kharianne](https://github.com/Kharianne) made their first contribution in https://github.com/pydantic/pydantic/pull/11111\n* [@mdaffad](https://github.com/mdaffad) made their first contribution in https://github.com/pydantic/pydantic/pull/11177\n* [@thejcannon](https://github.com/thejcannon) made their first contribution in https://github.com/pydantic/pydantic/pull/11014\n* [@thomasfrimannkoren](https://github.com/thomasfrimannkoren) made their first contribution in https://github.com/pydantic/pydantic/pull/11251\n* [@usernameMAI](https://github.com/usernameMAI) made their first contribution in https://github.com/pydantic/pydantic/pull/11275\n* [@ananiavito](https://github.com/ananiavito) made their first contribution in https://github.com/pydantic/pydantic/pull/11302\n* [@pawamoy](https://github.com/pawamoy) made their first contribution in https://github.com/pydantic/pydantic/pull/11311\n* [@Maze21127](https://github.com/Maze21127) made their first contribution in https://github.com/pydantic/pydantic/pull/11319\n* [@kauabh](https://github.com/kauabh) made their first contribution in https://github.com/pydantic/pydantic/pull/11369\n* [@jaceklaskowski](https://github.com/jaceklaskowski) made their first contribution in https://github.com/pydantic/pydantic/pull/11353\n* [@tmpbeing](https://github.com/tmpbeing) made their first contribution in https://github.com/pydantic/pydantic/pull/11375\n* [@petyosi](https://github.com/petyosi) made their first contribution in https://github.com/pydantic/pydantic/pull/11405\n* [@austinyu](https://github.com/austinyu) made their first contribution in https://github.com/pydantic/pydantic/pull/11392\n* [@mikeedjones](https://github.com/mikeedjones) made their first contribution in https://github.com/pydantic/pydantic/pull/11402\n* [@astei](https://github.com/astei) made their first contribution in https://github.com/pydantic/pydantic/pull/11436\n* [@dsayling](https://github.com/dsayling) made their first contribution in https://github.com/pydantic/pydantic/pull/11522\n* [@sobolevn](https://github.com/sobolevn) made their first contribution in https://github.com/pydantic/pydantic-core/pull/1645\n\n## v2.11.0a2 (2025-02-10)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.0a2)\n\n### What's Changed\n\nPydantic v2.11 is a version strongly focused on build time performance of Pydantic models (and core schema generation in general).\nThis is another early alpha release, meant to collect early feedback from users having issues with core schema builds.\n\n#### Packaging\n\n* Bump `ruff` from 0.9.2 to 0.9.5 by [@Viicos](https://github.com/Viicos) in [#11407](https://github.com/pydantic/pydantic/pull/11407)\n* Bump `pydantic-core` to v2.29.0 by [@mikeedjones](https://github.com/mikeedjones) in [#11402](https://github.com/pydantic/pydantic/pull/11402)\n* Use locally-built rust with symbols & pgo by [@davidhewitt](https://github.com/davidhewitt) in [#11403](https://github.com/pydantic/pydantic/pull/11403)\n\n#### Performance\n\n* Create a single dictionary when creating a `CoreConfig` instance by [@sydney-runkle](https://github.com/sydney-runkle) in [#11384](https://github.com/pydantic/pydantic/pull/11384)\n\n#### Fixes\n\n* Use the correct JSON Schema mode when handling function schemas by [@Viicos](https://github.com/Viicos) in [#11367](https://github.com/pydantic/pydantic/pull/11367)\n* Fix JSON Schema reference logic with `examples` keys by [@Viicos](https://github.com/Viicos) in [#11366](https://github.com/pydantic/pydantic/pull/11366)\n* Improve exception message when encountering recursion errors during type evaluation by [@Viicos](https://github.com/Viicos) in [#11356](https://github.com/pydantic/pydantic/pull/11356)\n* Always include `additionalProperties: True` for arbitrary dictionary schemas by [@austinyu](https://github.com/austinyu) in [#11392](https://github.com/pydantic/pydantic/pull/11392)\n* Expose `fallback` parameter in serialization methods by [@Viicos](https://github.com/Viicos) in [#11398](https://github.com/pydantic/pydantic/pull/11398)\n* Fix path serialization behavior by [@sydney-runkle](https://github.com/sydney-runkle) in [#11416](https://github.com/pydantic/pydantic/pull/11416)\n\n### New Contributors\n\n* [@kauabh](https://github.com/kauabh) made their first contribution in [#11369](https://github.com/pydantic/pydantic/pull/11369)\n* [@jaceklaskowski](https://github.com/jaceklaskowski) made their first contribution in [#11353](https://github.com/pydantic/pydantic/pull/11353)\n* [@tmpbeing](https://github.com/tmpbeing) made their first contribution in [#11375](https://github.com/pydantic/pydantic/pull/11375)\n* [@petyosi](https://github.com/petyosi) made their first contribution in [#11405](https://github.com/pydantic/pydantic/pull/11405)\n* [@austinyu](https://github.com/austinyu) made their first contribution in [#11392](https://github.com/pydantic/pydantic/pull/11392)\n* [@mikeedjones](https://github.com/mikeedjones) made their first contribution in [#11402](https://github.com/pydantic/pydantic/pull/11402)\n\n## v2.11.0a1 (2025-01-30)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.0a1)\n\n### What's Changed\n\nPydantic v2.11 is a version strongly focused on build time performance of Pydantic models (and core schema generation in general).\nThis is an early alpha release, meant to collect early feedback from users having issues with core schema builds.\n\n#### Packaging\n\n* Bump dawidd6/action-download-artifact from 6 to 7 by [@dependabot](https://github.com/dependabot) in [#11018](https://github.com/pydantic/pydantic/pull/11018)\n* Re-enable memray related tests on Python 3.12+ by [@Viicos](https://github.com/Viicos) in [#11191](https://github.com/pydantic/pydantic/pull/11191)\n* Bump astral-sh/setup-uv to 5 by [@dependabot](https://github.com/dependabot) in [#11205](https://github.com/pydantic/pydantic/pull/11205)\n* Bump `ruff` to v0.9.0 by [@sydney-runkle](https://github.com/sydney-runkle) in [#11254](https://github.com/pydantic/pydantic/pull/11254)\n* Regular `uv.lock` deps update by [@sydney-runkle](https://github.com/sydney-runkle) in [#11333](https://github.com/pydantic/pydantic/pull/11333)\n* Add a `check_pydantic_core_version()` function by [@Viicos](https://github.com/Viicos) in [#11324](https://github.com/pydantic/pydantic/pull/11324)\n* Remove `greenlet` development dependency by [@Viicos](https://github.com/Viicos) in [#11351](https://github.com/pydantic/pydantic/pull/11351)\n* Bump `pydantic-core` to v2.28.0 by [@Viicos](https://github.com/Viicos) in [#11364](https://github.com/pydantic/pydantic/pull/11364)\n\n#### New Features\n\n* Support unsubstituted type variables with both a default and a bound or constraints by [@FyZzyss](https://github.com/FyZzyss) in [#10789](https://github.com/pydantic/pydantic/pull/10789)\n* Add a `default_factory_takes_validated_data` property to `FieldInfo` by [@Viicos](https://github.com/Viicos) in [#11034](https://github.com/pydantic/pydantic/pull/11034)\n* Raise a better error when a generic alias is used inside `type[]` by [@Viicos](https://github.com/Viicos) in [#11088](https://github.com/pydantic/pydantic/pull/11088)\n* Properly support PEP 695 generics syntax by [@Viicos](https://github.com/Viicos) in [#11189](https://github.com/pydantic/pydantic/pull/11189)\n* Properly support type variable defaults by [@Viicos](https://github.com/Viicos) in [#11332](https://github.com/pydantic/pydantic/pull/11332)\n\n#### Changes\n\n* Rework `create_model` field definitions format by [@Viicos](https://github.com/Viicos) in [#11032](https://github.com/pydantic/pydantic/pull/11032)\n* Raise a deprecation warning when a field is annotated as final with a default value by [@Viicos](https://github.com/Viicos) in [#11168](https://github.com/pydantic/pydantic/pull/11168)\n* Deprecate accessing `model_fields` and `model_computed_fields` on instances by [@Viicos](https://github.com/Viicos) in [#11169](https://github.com/pydantic/pydantic/pull/11169)\n* Move core schema generation logic for path types inside the `GenerateSchema` class by [@sydney-runkle](https://github.com/sydney-runkle) in [#10846](https://github.com/pydantic/pydantic/pull/10846)\n* Move `deque` schema gen to `GenerateSchema` class by [@sydney-runkle](https://github.com/sydney-runkle) in [#11239](https://github.com/pydantic/pydantic/pull/11239)\n* Move `Mapping` schema gen to `GenerateSchema` to complete removal of `prepare_annotations_for_known_type` workaround by [@sydney-runkle](https://github.com/sydney-runkle) in [#11247](https://github.com/pydantic/pydantic/pull/11247)\n* Remove Python 3.8 Support by [@sydney-runkle](https://github.com/sydney-runkle) in [#11258](https://github.com/pydantic/pydantic/pull/11258)\n* Disable `pydantic-core` core schema validation by [@sydney-runkle](https://github.com/sydney-runkle) in [#11271](https://github.com/pydantic/pydantic/pull/11271)\n\n#### Performance\n\n* Only evaluate `FieldInfo` annotations if required during schema building by [@Viicos](https://github.com/Viicos) in [#10769](https://github.com/pydantic/pydantic/pull/10769)\n* Optimize calls to `get_type_ref` by [@Viicos](https://github.com/Viicos) in [#10863](https://github.com/pydantic/pydantic/pull/10863)\n* Improve `__setattr__` performance of Pydantic models by caching setter functions by [@MarkusSintonen](https://github.com/MarkusSintonen) in [#10868](https://github.com/pydantic/pydantic/pull/10868)\n* Improve annotation application performance by [@Viicos](https://github.com/Viicos) in [#11186](https://github.com/pydantic/pydantic/pull/11186)\n* Improve performance of `_typing_extra` module by [@Viicos](https://github.com/Viicos) in [#11255](https://github.com/pydantic/pydantic/pull/11255)\n* Refactor and optimize schema cleaning logic by [@Viicos](https://github.com/Viicos) and [@MarkusSintonen](https://github.com/MarkusSintonen) in [#11244](https://github.com/pydantic/pydantic/pull/11244)\n\n#### Fixes\n\n* Add validation tests for `_internal/_validators.py` by [@tkasuz](https://github.com/tkasuz) in [#10763](https://github.com/pydantic/pydantic/pull/10763)\n* Improve `TypeAdapter` instance repr by [@sydney-runkle](https://github.com/sydney-runkle) in [#10872](https://github.com/pydantic/pydantic/pull/10872)\n* Revert \"ci: use locally built pydantic-core with debug symbols by [@sydney-runkle](https://github.com/sydney-runkle) in [#10942](https://github.com/pydantic/pydantic/pull/10942)\n* Re-enable all FastAPI tests by [@tamird](https://github.com/tamird) in [#10948](https://github.com/pydantic/pydantic/pull/10948)\n* Fix typo in HISTORY.md. by [@felixxm](https://github.com/felixxm) in [#11077](https://github.com/pydantic/pydantic/pull/11077)\n* Infer final fields with a default value as class variables in the mypy plugin by [@Viicos](https://github.com/Viicos) in [#11121](https://github.com/pydantic/pydantic/pull/11121)\n* Recursively unpack `Literal` values if using PEP 695 type aliases by [@Viicos](https://github.com/Viicos) in [#11114](https://github.com/pydantic/pydantic/pull/11114)\n* Override `__subclasscheck__` on `ModelMetaclass` to avoid memory leak and performance issues by [@Viicos](https://github.com/Viicos) in [#11116](https://github.com/pydantic/pydantic/pull/11116)\n* Remove unused `_extract_get_pydantic_json_schema()` parameter by [@Viicos](https://github.com/Viicos) in [#11155](https://github.com/pydantic/pydantic/pull/11155)\n* Add FastAPI and SQLModel to third-party tests by [@sydney-runkle](https://github.com/sydney-runkle) in [#11044](https://github.com/pydantic/pydantic/pull/11044)\n* Fix conditional expressions syntax for third-party tests by [@Viicos](https://github.com/Viicos) in [#11162](https://github.com/pydantic/pydantic/pull/11162)\n* Move FastAPI tests to third-party workflow by [@Viicos](https://github.com/Viicos) in [#11164](https://github.com/pydantic/pydantic/pull/11164)\n* Improve discriminated union error message for invalid union variants by [@Viicos](https://github.com/Viicos) in [#11161](https://github.com/pydantic/pydantic/pull/11161)\n* Unpack PEP 695 type aliases if using the `Annotated` form by [@Viicos](https://github.com/Viicos) in [#11109](https://github.com/pydantic/pydantic/pull/11109)\n* Include `openapi-python-client` check in issue creation for third-party failures, use `main` branch by [@sydney-runkle](https://github.com/sydney-runkle) in [#11182](https://github.com/pydantic/pydantic/pull/11182)\n* Add pandera third-party tests by [@Viicos](https://github.com/Viicos) in [#11193](https://github.com/pydantic/pydantic/pull/11193)\n* Add ODMantic third-party tests by [@sydney-runkle](https://github.com/sydney-runkle) in [#11197](https://github.com/pydantic/pydantic/pull/11197)\n* Add missing stacklevel in `deprecated_instance_property` warning by [@Viicos](https://github.com/Viicos) in [#11200](https://github.com/pydantic/pydantic/pull/11200)\n* Copy `WithJsonSchema` schema to avoid sharing mutated data by [@thejcannon](https://github.com/thejcannon) in [#11014](https://github.com/pydantic/pydantic/pull/11014)\n* Do not cache parametrized models when in the process of parametrizing another model by [@Viicos](https://github.com/Viicos) in [#10704](https://github.com/pydantic/pydantic/pull/10704)\n* Re-enable Beanie third-party tests by [@Viicos](https://github.com/Viicos) in [#11214](https://github.com/pydantic/pydantic/pull/11214)\n* Add discriminated union related metadata entries to the `CoreMetadata` definition by [@Viicos](https://github.com/Viicos) in [#11216](https://github.com/pydantic/pydantic/pull/11216)\n* Consolidate schema definitions logic in the `_Definitions` class by [@Viicos](https://github.com/Viicos) in [#11208](https://github.com/pydantic/pydantic/pull/11208)\n* Support initializing root model fields with values of the `root` type in the mypy plugin by [@Viicos](https://github.com/Viicos) in [#11212](https://github.com/pydantic/pydantic/pull/11212)\n* Fix various issues with dataclasses and `use_attribute_docstrings` by [@Viicos](https://github.com/Viicos) in [#11246](https://github.com/pydantic/pydantic/pull/11246)\n* Only compute normalized decimal places if necessary in `decimal_places_validator` by [@misrasaurabh1](https://github.com/misrasaurabh1) in [#11281](https://github.com/pydantic/pydantic/pull/11281)\n* Fix two misplaced sentences in validation errors documentation by [@ananiavito](https://github.com/ananiavito) in [#11302](https://github.com/pydantic/pydantic/pull/11302)\n* Fix mkdocstrings inventory example in documentation by [@pawamoy](https://github.com/pawamoy) in [#11311](https://github.com/pydantic/pydantic/pull/11311)\n* Add support for `validation_alias` in the mypy plugin by [@Viicos](https://github.com/Viicos) in [#11295](https://github.com/pydantic/pydantic/pull/11295)\n* Do not transform model serializer functions as class methods in the mypy plugin by [@Viicos](https://github.com/Viicos) in [#11298](https://github.com/pydantic/pydantic/pull/11298)\n* Simplify `GenerateJsonSchema.literal_schema()` implementation by [@misrasaurabh1](https://github.com/misrasaurabh1) in [#11321](https://github.com/pydantic/pydantic/pull/11321)\n* Add additional allowed schemes for `ClickHouseDsn` by [@Maze21127](https://github.com/Maze21127) in [#11319](https://github.com/pydantic/pydantic/pull/11319)\n* Coerce decimal constraints to `Decimal` instances by [@Viicos](https://github.com/Viicos) in [#11350](https://github.com/pydantic/pydantic/pull/11350)\n* Fix `ValueError` on year zero by [@davidhewitt](https://github.com/davidhewitt) in [pydantic-core#1583](https://github.com/pydantic/pydantic-core/pull/1583)\n\n### New Contributors\n\n* [@FyZzyss](https://github.com/FyZzyss) made their first contribution in [#10789](https://github.com/pydantic/pydantic/pull/10789)\n* [@tamird](https://github.com/tamird) made their first contribution in [#10948](https://github.com/pydantic/pydantic/pull/10948)\n* [@felixxm](https://github.com/felixxm) made their first contribution in [#11077](https://github.com/pydantic/pydantic/pull/11077)\n* [@alexprabhat99](https://github.com/alexprabhat99) made their first contribution in [#11082](https://github.com/pydantic/pydantic/pull/11082)\n* [@Kharianne](https://github.com/Kharianne) made their first contribution in [#11111](https://github.com/pydantic/pydantic/pull/11111)\n* [@mdaffad](https://github.com/mdaffad) made their first contribution in [#11177](https://github.com/pydantic/pydantic/pull/11177)\n* [@thejcannon](https://github.com/thejcannon) made their first contribution in [#11014](https://github.com/pydantic/pydantic/pull/11014)\n* [@thomasfrimannkoren](https://github.com/thomasfrimannkoren) made their first contribution in [#11251](https://github.com/pydantic/pydantic/pull/11251)\n* [@usernameMAI](https://github.com/usernameMAI) made their first contribution in [#11275](https://github.com/pydantic/pydantic/pull/11275)\n* [@ananiavito](https://github.com/ananiavito) made their first contribution in [#11302](https://github.com/pydantic/pydantic/pull/11302)\n* [@pawamoy](https://github.com/pawamoy) made their first contribution in [#11311](https://github.com/pydantic/pydantic/pull/11311)\n* [@Maze21127](https://github.com/Maze21127) made their first contribution in [#11319](https://github.com/pydantic/pydantic/pull/11319)\n\n## v2.10.6 (2025-01-23)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.6)\n\n### What's Changed\n\n#### Fixes\n\n* Fix JSON Schema reference collection with `'examples'` keys by [@Viicos](https://github.com/Viicos) in [#11325](https://github.com/pydantic/pydantic/pull/11325)\n* Fix url python serialization by [@sydney-runkle](https://github.com/sydney-runkle) in [#11331](https://github.com/pydantic/pydantic/pull/11331)\n\n## v2.10.5 (2025-01-08)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.5)\n\n### What's Changed\n\n#### Fixes\n\n* Remove custom MRO implementation of Pydantic models by [@Viicos](https://github.com/Viicos) in [#11184](https://github.com/pydantic/pydantic/pull/11184)\n* Fix URL serialization for unions by [@sydney-runkle](https://github.com/sydney-runkle) in [#11233](https://github.com/pydantic/pydantic/pull/11233)\n\n## v2.10.4 (2024-12-18)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.4)\n\n### What's Changed\n\n#### Packaging\n\n* Bump `pydantic-core` to v2.27.2 by [@davidhewitt](https://github.com/davidhewitt) in [#11138](https://github.com/pydantic/pydantic/pull/11138)\n\n#### Fixes\n\n* Fix for comparison of `AnyUrl` objects by [@alexprabhat99](https://github.com/alexprabhat99) in [#11082](https://github.com/pydantic/pydantic/pull/11082)\n* Properly fetch PEP 695 type params for functions, do not fetch annotations from signature by [@Viicos](https://github.com/Viicos) in [#11093](https://github.com/pydantic/pydantic/pull/11093)\n* Include JSON Schema input core schema in function schemas by [@Viicos](https://github.com/Viicos) in [#11085](https://github.com/pydantic/pydantic/pull/11085)\n* Add `len` to `_BaseUrl` to avoid TypeError by [@Kharianne](https://github.com/Kharianne) in [#11111](https://github.com/pydantic/pydantic/pull/11111)\n* Make sure the type reference is removed from the seen references by [@Viicos](https://github.com/Viicos) in [#11143](https://github.com/pydantic/pydantic/pull/11143)\n\n### New Contributors\n\n* [@FyZzyss](https://github.com/FyZzyss) made their first contribution in [#10789](https://github.com/pydantic/pydantic/pull/10789)\n* [@tamird](https://github.com/tamird) made their first contribution in [#10948](https://github.com/pydantic/pydantic/pull/10948)\n* [@felixxm](https://github.com/felixxm) made their first contribution in [#11077](https://github.com/pydantic/pydantic/pull/11077)\n* [@alexprabhat99](https://github.com/alexprabhat99) made their first contribution in [#11082](https://github.com/pydantic/pydantic/pull/11082)\n* [@Kharianne](https://github.com/Kharianne) made their first contribution in [#11111](https://github.com/pydantic/pydantic/pull/11111)\n\n## v2.10.3 (2024-12-03)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.3)\n\n### What's Changed\n\n#### Fixes\n\n* Set fields when `defer_build` is set on Pydantic dataclasses by [@Viicos](https://github.com/Viicos) in [#10984](https://github.com/pydantic/pydantic/pull/10984)\n* Do not resolve the JSON Schema reference for `dict` core schema keys by [@Viicos](https://github.com/Viicos) in [#10989](https://github.com/pydantic/pydantic/pull/10989)\n* Use the globals of the function when evaluating the return type for `PlainSerializer` and `WrapSerializer` functions by [@Viicos](https://github.com/Viicos) in [#11008](https://github.com/pydantic/pydantic/pull/11008)\n* Fix host required enforcement for urls to be compatible with v2.9 behavior by [@sydney-runkle](https://github.com/sydney-runkle) in [#11027](https://github.com/pydantic/pydantic/pull/11027)\n* Add a `default_factory_takes_validated_data` property to `FieldInfo` by [@Viicos](https://github.com/Viicos) in [#11034](https://github.com/pydantic/pydantic/pull/11034)\n* Fix url json schema in `serialization` mode by [@sydney-runkle](https://github.com/sydney-runkle) in [#11035](https://github.com/pydantic/pydantic/pull/11035)\n\n## v2.10.2 (2024-11-25)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.2)\n\n### What's Changed\n\n#### Fixes\n\n* Only evaluate FieldInfo annotations if required during schema building by [@Viicos](https://github.com/Viicos) in [#10769](https://github.com/pydantic/pydantic/pull/10769)\n* Do not evaluate annotations for private fields by [@Viicos](https://github.com/Viicos) in [#10962](https://github.com/pydantic/pydantic/pull/10962)\n* Support serialization as any for `Secret` types and `Url` types by [@sydney-runkle](https://github.com/sydney-runkle) in [#10947](https://github.com/pydantic/pydantic/pull/10947)\n* Fix type hint of `Field.default` to be compatible with Python 3.8 and 3.9 by [@Viicos](https://github.com/Viicos) in [#10972](https://github.com/pydantic/pydantic/pull/10972)\n* Add hashing support for URL types by [@sydney-runkle](https://github.com/sydney-runkle) in [#10975](https://github.com/pydantic/pydantic/pull/10975)\n* Hide `BaseModel.__replace__` definition from type checkers by [@Viicos](https://github.com/Viicos) in [#10979](https://github.com/pydantic/pydantic/pull/10979)\n\n## v2.10.1 (2024-11-21)\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.1)\n\n### What's Changed\n\n#### Packaging\n\n* Bump `pydantic-core` version to `v2.27.1` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10938](https://github.com/pydantic/pydantic/pull/10938)\n\n#### Fixes\n\n* Use the correct frame when instantiating a parametrized `TypeAdapter` by [@Viicos](https://github.com/Viicos) in [#10893](https://github.com/pydantic/pydantic/pull/10893)\n* Relax check for validated data in `default_factory` utils by [@sydney-runkle](https://github.com/sydney-runkle) in [#10909](https://github.com/pydantic/pydantic/pull/10909)\n* Fix type checking issue with `model_fields` and `model_computed_fields` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10911](https://github.com/pydantic/pydantic/pull/10911)\n* Use the parent configuration during schema generation for stdlib `dataclass`es by [@sydney-runkle](https://github.com/sydney-runkle) in [#10928](https://github.com/pydantic/pydantic/pull/10928)\n* Use the `globals` of the function when evaluating the return type of serializers and `computed_field`s by [@Viicos](https://github.com/Viicos) in [#10929](https://github.com/pydantic/pydantic/pull/10929)\n* Fix URL constraint application by [@sydney-runkle](https://github.com/sydney-runkle) in [#10922](https://github.com/pydantic/pydantic/pull/10922)\n* Fix URL equality with different validation methods by [@sydney-runkle](https://github.com/sydney-runkle) in [#10934](https://github.com/pydantic/pydantic/pull/10934)\n* Fix JSON schema title when specified as `''` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10936](https://github.com/pydantic/pydantic/pull/10936)\n* Fix `python` mode serialization for `complex` inference by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic-core#1549](https://github.com/pydantic/pydantic-core/pull/1549)\n\n### New Contributors\n\n## v2.10.0 (2024-11-20)\n\nThe code released in v2.10.0 is practically identical to that of v2.10.0b2.\n\n[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.0)\n\nSee the [v2.10 release blog post](https://pydantic.dev/articles/pydantic-v2-10-release) for the highlights!\n\n### What's Changed\n\n#### Packaging\n\n* Bump `pydantic-core` to `v2.27.0` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10825](https://github.com/pydantic/pydantic/pull/10825)\n* Replaced pdm with uv by [@frfahim](https://github.com/frfahim) in [#10727](https://github.com/pydantic/pydantic/pull/10727)\n\n#### New Features\n\n* Support `fractions.Fraction` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10318](https://github.com/pydantic/pydantic/pull/10318)\n* Support `Hashable` for json validation by [@sydney-runkle](https://github.com/sydney-runkle) in [#10324](https://github.com/pydantic/pydantic/pull/10324)\n* Add a `SocketPath` type for `linux` systems by [@theunkn0wn1](https://github.com/theunkn0wn1) in [#10378](https://github.com/pydantic/pydantic/pull/10378)\n* Allow arbitrary refs in JSON schema `examples` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10417](https://github.com/pydantic/pydantic/pull/10417)\n* Support `defer_build` for Pydantic dataclasses by [@Viicos](https://github.com/Viicos) in [#10313](https://github.com/pydantic/pydantic/pull/10313)\n* Adding v1 / v2 incompatibility warning for nested v1 model by [@sydney-runkle](https://github.com/sydney-runkle) in [#10431](https://github.com/pydantic/pydantic/pull/10431)\n* Add support for unpacked `TypedDict` to type hint variadic keyword arguments with `@validate_call` by [@Viicos](https://github.com/Viicos) in [#10416](https://github.com/pydantic/pydantic/pull/10416)\n* Support compiled patterns in `protected_namespaces` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10522](https://github.com/pydantic/pydantic/pull/10522)\n* Add support for `propertyNames` in JSON schema by [@FlorianSW](https://github.com/FlorianSW) in [#10478](https://github.com/pydantic/pydantic/pull/10478)\n* Adding `__replace__` protocol for Python 3.13+ support by [@sydney-runkle](https://github.com/sydney-runkle) in [#10596](https://github.com/pydantic/pydantic/pull/10596)\n* Expose public `sort` method for JSON schema generation by [@sydney-runkle](https://github.com/sydney-runkle) in [#10595](https://github.com/pydantic/pydantic/pull/10595)\n* Add runtime validation of `@validate_call` callable argument by [@kc0506](https://github.com/kc0506) in [#10627](https://github.com/pydantic/pydantic/pull/10627)\n* Add `experimental_allow_partial` support by [@samuelcolvin](https://github.com/samuelcolvin) in [#10748](https://github.com/pydantic/pydantic/pull/10748)\n* Support default factories taking validated data as an argument by [@Viicos](https://github.com/Viicos) in [#10678](https://github.com/pydantic/pydantic/pull/10678)\n* Allow subclassing `ValidationError` and `PydanticCustomError` by [@Youssefares](https://github.com/Youssefares) in [pydantic/pydantic-core#1413](https://github.com/pydantic/pydantic-core/pull/1413)\n* Add `trailing-strings` support to `experimental_allow_partial` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10825](https://github.com/pydantic/pydantic/pull/10825)\n* Add `rebuild()` method for `TypeAdapter` and simplify `defer_build` patterns by [@sydney-runkle](https://github.com/sydney-runkle) in [#10537](https://github.com/pydantic/pydantic/pull/10537)\n* Improve `TypeAdapter` instance repr by [@sydney-runkle](https://github.com/sydney-runkle) in [#10872](https://github.com/pydantic/pydantic/pull/10872)\n\n#### Changes\n\n* Don't allow customization of `SchemaGenerator` until interface is more stable by [@sydney-runkle](https://github.com/sydney-runkle) in [#10303](https://github.com/pydantic/pydantic/pull/10303)\n* Cleanly `defer_build` on `TypeAdapters`, removing experimental flag by [@sydney-runkle](https://github.com/sydney-runkle) in [#10329](https://github.com/pydantic/pydantic/pull/10329)\n* Fix `mro` of generic subclass  by [@kc0506](https://github.com/kc0506) in [#10100](https://github.com/pydantic/pydantic/pull/10100)\n* Strip whitespaces on JSON Schema title generation by [@sydney-runkle](https://github.com/sydney-runkle) in [#10404](https://github.com/pydantic/pydantic/pull/10404)\n* Use `b64decode` and `b64encode` for `Base64Bytes` type by [@sydney-runkle](https://github.com/sydney-runkle) in [#10486](https://github.com/pydantic/pydantic/pull/10486)\n* Relax protected namespace config default by [@sydney-runkle](https://github.com/sydney-runkle) in [#10441](https://github.com/pydantic/pydantic/pull/10441)\n* Revalidate parametrized generics if instance's origin is subclass of OG class by [@sydney-runkle](https://github.com/sydney-runkle) in [#10666](https://github.com/pydantic/pydantic/pull/10666)\n* Warn if configuration is specified on the `@dataclass` decorator and with the `__pydantic_config__` attribute by [@sydney-runkle](https://github.com/sydney-runkle) in [#10406](https://github.com/pydantic/pydantic/pull/10406)\n* Recommend against using `Ellipsis` (...) with `Field` by [@Viicos](https://github.com/Viicos) in [#10661](https://github.com/pydantic/pydantic/pull/10661)\n* Migrate to subclassing instead of annotated approach for pydantic url types by [@sydney-runkle](https://github.com/sydney-runkle) in [#10662](https://github.com/pydantic/pydantic/pull/10662)\n* Change JSON schema generation of `Literal`s and `Enums` by [@Viicos](https://github.com/Viicos) in [#10692](https://github.com/pydantic/pydantic/pull/10692)\n* Simplify unions involving `Any` or `Never` when replacing type variables by [@Viicos](https://github.com/Viicos) in [#10338](https://github.com/pydantic/pydantic/pull/10338)\n* Do not require padding when decoding `base64` bytes by [@bschoenmaeckers](https://github.com/bschoenmaeckers) in [pydantic/pydantic-core#1448](https://github.com/pydantic/pydantic-core/pull/1448)\n* Support dates all the way to 1BC by [@changhc](https://github.com/changhc) in [pydantic/speedate#77](https://github.com/pydantic/speedate/pull/77)\n\n#### Performance\n\n* Schema cleaning: skip unnecessary copies during schema walking by [@Viicos](https://github.com/Viicos) in [#10286](https://github.com/pydantic/pydantic/pull/10286)\n* Refactor namespace logic for annotations evaluation by [@Viicos](https://github.com/Viicos) in [#10530](https://github.com/pydantic/pydantic/pull/10530)\n* Improve email regexp on edge cases by [@AlekseyLobanov](https://github.com/AlekseyLobanov) in [#10601](https://github.com/pydantic/pydantic/pull/10601)\n* `CoreMetadata` refactor with an emphasis on documentation, schema build time performance, and reducing complexity by [@sydney-runkle](https://github.com/sydney-runkle) in [#10675](https://github.com/pydantic/pydantic/pull/10675)\n\n#### Fixes\n\n* Remove guarding check on `computed_field` with `field_serializer` by [@nix010](https://github.com/nix010) in [#10390](https://github.com/pydantic/pydantic/pull/10390)\n* Fix `Predicate` issue in `v2.9.0` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10321](https://github.com/pydantic/pydantic/pull/10321)\n* Fixing `annotated-types` bound by [@sydney-runkle](https://github.com/sydney-runkle) in [#10327](https://github.com/pydantic/pydantic/pull/10327)\n* Turn `tzdata` install requirement into optional `timezone` dependency by [@jakob-keller](https://github.com/jakob-keller) in [#10331](https://github.com/pydantic/pydantic/pull/10331)\n* Use correct types namespace when building `namedtuple` core schemas by [@Viicos](https://github.com/Viicos) in [#10337](https://github.com/pydantic/pydantic/pull/10337)\n* Fix evaluation of stringified annotations during namespace inspection by [@Viicos](https://github.com/Viicos) in [#10347](https://github.com/pydantic/pydantic/pull/10347)\n* Fix `IncEx` type alias definition by [@Viicos](https://github.com/Viicos) in [#10339](https://github.com/pydantic/pydantic/pull/10339)\n* Do not error when trying to evaluate annotations of private attributes by [@Viicos](https://github.com/Viicos) in [#10358](https://github.com/pydantic/pydantic/pull/10358)\n* Fix nested type statement by [@kc0506](https://github.com/kc0506) in [#10369](https://github.com/pydantic/pydantic/pull/10369)\n* Improve typing of `ModelMetaclass.mro` by [@Viicos](https://github.com/Viicos) in [#10372](https://github.com/pydantic/pydantic/pull/10372)\n* Fix class access of deprecated `computed_field`s by [@Viicos](https://github.com/Viicos) in [#10391](https://github.com/pydantic/pydantic/pull/10391)\n* Make sure `inspect.iscoroutinefunction` works on coroutines decorated with `@validate_call` by [@MovisLi](https://github.com/MovisLi) in [#10374](https://github.com/pydantic/pydantic/pull/10374)\n* Fix `NameError` when using `validate_call` with PEP 695 on a class by [@kc0506](https://github.com/kc0506) in [#10380](https://github.com/pydantic/pydantic/pull/10380)\n* Fix `ZoneInfo` with various invalid types by [@sydney-runkle](https://github.com/sydney-runkle) in [#10408](https://github.com/pydantic/pydantic/pull/10408)\n* Fix `PydanticUserError` on empty `model_config` with annotations by [@cdwilson](https://github.com/cdwilson) in [#10412](https://github.com/pydantic/pydantic/pull/10412)\n* Fix variance issue in `_IncEx` type alias, only allow `True` by [@Viicos](https://github.com/Viicos) in [#10414](https://github.com/pydantic/pydantic/pull/10414)\n* Fix serialization schema generation when using `PlainValidator` by [@Viicos](https://github.com/Viicos) in [#10427](https://github.com/pydantic/pydantic/pull/10427)\n* Fix schema generation error when serialization schema holds references by [@Viicos](https://github.com/Viicos) in [#10444](https://github.com/pydantic/pydantic/pull/10444)\n* Inline references if possible when generating schema for `json_schema_input_type` by [@Viicos](https://github.com/Viicos) in [#10439](https://github.com/pydantic/pydantic/pull/10439)\n* Fix recursive arguments in `Representation` by [@Viicos](https://github.com/Viicos) in [#10480](https://github.com/pydantic/pydantic/pull/10480)\n* Fix representation for builtin function types by [@kschwab](https://github.com/kschwab) in [#10479](https://github.com/pydantic/pydantic/pull/10479)\n* Add python validators for decimal constraints (`max_digits` and `decimal_places`) by [@sydney-runkle](https://github.com/sydney-runkle) in [#10506](https://github.com/pydantic/pydantic/pull/10506)\n* Only fetch `__pydantic_core_schema__` from the current class during schema generation by [@Viicos](https://github.com/Viicos) in [#10518](https://github.com/pydantic/pydantic/pull/10518)\n* Fix `stacklevel` on deprecation warnings for `BaseModel` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10520](https://github.com/pydantic/pydantic/pull/10520)\n* Fix warning `stacklevel` in `BaseModel.__init__` by [@Viicos](https://github.com/Viicos) in [#10526](https://github.com/pydantic/pydantic/pull/10526)\n* Improve error handling for in-evaluable refs for discriminator application by [@sydney-runkle](https://github.com/sydney-runkle) in [#10440](https://github.com/pydantic/pydantic/pull/10440)\n* Change the signature of `ConfigWrapper.core_config` to take the title directly by [@Viicos](https://github.com/Viicos) in [#10562](https://github.com/pydantic/pydantic/pull/10562)\n* Do not use the previous config from the stack for dataclasses without config by [@Viicos](https://github.com/Viicos) in [#10576](https://github.com/pydantic/pydantic/pull/10576)\n* Fix serialization for IP types with `mode='python'` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10594](https://github.com/pydantic/pydantic/pull/10594)\n* Support constraint application for `Base64Etc` types by [@sydney-runkle](https://github.com/sydney-runkle) in [#10584](https://github.com/pydantic/pydantic/pull/10584)\n* Fix `validate_call` ignoring `Field` in `Annotated` by [@kc0506](https://github.com/kc0506) in [#10610](https://github.com/pydantic/pydantic/pull/10610)\n* Raise an error when `Self` is invalid by [@kc0506](https://github.com/kc0506) in [#10609](https://github.com/pydantic/pydantic/pull/10609)\n* Using `core_schema.InvalidSchema` instead of metadata injection + checks by [@sydney-runkle](https://github.com/sydney-runkle) in [#10523](https://github.com/pydantic/pydantic/pull/10523)\n* Tweak type alias logic by [@kc0506](https://github.com/kc0506) in [#10643](https://github.com/pydantic/pydantic/pull/10643)\n* Support usage of `type` with `typing.Self` and type aliases by [@kc0506](https://github.com/kc0506) in [#10621](https://github.com/pydantic/pydantic/pull/10621)\n* Use overloads for `Field` and `PrivateAttr` functions by [@Viicos](https://github.com/Viicos) in [#10651](https://github.com/pydantic/pydantic/pull/10651)\n* Clean up the `mypy` plugin implementation by [@Viicos](https://github.com/Viicos) in [#10669](https://github.com/pydantic/pydantic/pull/10669)\n* Properly check for `typing_extensions` variant of `TypeAliasType` by [@Daraan](https://github.com/Daraan) in [#10713](https://github.com/pydantic/pydantic/pull/10713)\n* Allow any mapping in `BaseModel.model_copy()` by [@Viicos](https://github.com/Viicos) in [#10751](https://github.com/pydantic/pydantic/pull/10751)\n* Fix `isinstance` behavior for urls by [@sydney-runkle](https://github.com/sydney-runkle) in [#10766](https://github.com/pydantic/pydantic/pull/10766)\n* Ensure `cached_property` can be set on Pydantic models by [@Viicos](https://github.com/Viicos) in [#10774](https://github.com/pydantic/pydantic/pull/10774)\n* Fix equality checks for primitives in literals by [@sydney-runkle](https://github.com/sydney-runkle) in [pydantic/pydantic-core#1459](https://github.com/pydantic/pydantic-core/pull/1459)\n* Properly enforce `host_required` for URLs by [@Viicos](https://github.com/Viicos) in [pydantic/pydantic-core#1488](https://github.com/pydantic/pydantic-core/pull/1488)\n* Fix when `coerce_numbers_to_str` enabled and string has invalid Unicode character by [@andrey-berenda](https://github.com/andrey-berenda) in [pydantic/pydantic-core#1515](https://github.com/pydantic/pydantic-core/pull/1515)\n* Fix serializing `complex` values in `Enum`s by [@changhc](https://github.com/changhc) in [pydantic/pydantic-core#1524](https://github.com/pydantic/pydantic-core/pull/1524)\n* Refactor `_typing_extra` module by [@Viicos](https://github.com/Viicos) in [#10725](https://github.com/pydantic/pydantic/pull/10725)\n* Support intuitive equality for urls by [@sydney-runkle](https://github.com/sydney-runkle) in [#10798](https://github.com/pydantic/pydantic/pull/10798)\n* Add `bytearray` to `TypeAdapter.validate_json` signature by [@samuelcolvin](https://github.com/samuelcolvin) in [#10802](https://github.com/pydantic/pydantic/pull/10802)\n* Ensure class access of method descriptors is performed when used as a default with `Field` by [@Viicos](https://github.com/Viicos) in [#10816](https://github.com/pydantic/pydantic/pull/10816)\n* Fix circular import with `validate_call` by [@sydney-runkle](https://github.com/sydney-runkle) in [#10807](https://github.com/pydantic/pydantic/pull/10807)\n* Fix error when using type aliases referencing other type aliases by [@Viicos](https://github.com/Viicos) in [#10809](https://github.com/pydantic/pydantic/pull/10809)\n* Fix `IncEx` type alias to be compatible with mypy by [@Viicos](https://github.com/Viicos) in [#10813](https://github.com/pydantic/pydantic/pull/10813)\n* Make `__signature__` a lazy property, do not deepcopy defaults by [@Viicos](https://github.com/Viicos) in [#10818](https://github.com/pydantic/pydantic/pull/10818)\n* Make `__signature__` lazy for dataclasses, too by [@sydney-runkle](https://github.com/sydney-runkle) in [#10832](https://github.com/pydantic/pydantic/pull/10832)\n* Subclass all single host url classes from `AnyUrl` to preserve behavior from v2.9 by [@sydney-runkle](https://github.com/sydney-runkle) in [#10856](https://github.com/pydantic/pydantic/pull/10856)\n\n### New Contributors\n\n* [@jakob-keller](https://github.com/jakob-keller) made their first contribution in [#10331](https://github.com/pydantic/pydantic/pull/10331)\n* [@MovisLi](https://github.com/MovisLi) made their first contribution in [#10374](https://github.com/pydantic/pydantic/pull/10374)\n* [@joaopalmeiro](https://github.com/joaopalmeiro) made their first contribution in [#10405](https://github.com/pydantic/pydantic/pull/10405)\n* [@theunkn0wn1](https://github.com/theunkn0wn1) made their first contribution in [#10378](https://github.com/pydantic/pydantic/pull/10378)\n* [@cdwilson](https://github.com/cdwilson) made their first contribution in [#10412](https://github.com/pydantic/pydantic/pull/10412)\n* [@dlax](https://github.com/dlax) made their first contribution in [#10421](https://github.com/pydantic/pydantic/pull/10421)\n* [@kschwab](https://github.com/kschwab) made their first contribution in [#10479](https://github.com/pydantic/pydantic/pull/10479)\n* [@santibreo](https://github.com/santibreo) made their first contribution in [#10453](https://github.com/pydantic/pydantic/pull/10453)\n* [@FlorianSW](https://github.com/FlorianSW) made their first contribution in [#10478](https://github.com/pydantic/pydantic/pull/10478)\n* [@tkasuz](https://github.com/tkasuz) made their first contribution in [#10555](https://github.com/pydantic/pydantic/pull/10555)\n* [@AlekseyLobanov](https://github.com/AlekseyLobanov) made their first contribution in [#10601](https://github.com/pydantic/pydantic/pull/10601)\n* [@NiclasvanEyk](https://github.com/NiclasvanEyk) made their first contribution in [#10667](https://github.com/pydantic/pydantic/pull/10667)\n* [@mschoettle](https://github.com/mschoettle) made their first contribution in [#10677](https://github.com/pydantic/pydantic/pull/10677)\n* [@Daraan](https://github.com/Daraan) made their first contribution in [#10713](https://github.com/pydantic/pydantic/pull/10713)\n* [@k4nar](https://github.com/k4nar) made their first contribution in [#10736](https://github.com/pydantic/pydantic/pull/10736)\n* [@UriyaHarpeness](https://github.com/UriyaHarpeness) made their first contribution in [#10740](https://github.com/pydantic/pydantic/pull/10740)\n* [@frfahim](https://github.com/frfahim) made their first contribution in [#10727](https://github.com/pydantic/pydantic/pull/10727)\n\n## v2.10.0b2 (2024-11-13)\n\nPre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.0b2) for details.\n\n## v2.10.0b1 (2024-11-06)\n\nPre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.0b1) for details.\n\n\n... see [here](https://docs.pydantic.dev/changelog/#v0322-2019-08-17) for earlier changes.\n",
        "description_content_type": "text/markdown",
        "author_email": "Samuel Colvin <s@muelcolvin.com>, Eric Jolibois <em.jolibois@gmail.com>, Hasan Ramezani <hasan.r67@gmail.com>, Adrian Garcia Badaracco <1755071+adriangb@users.noreply.github.com>, Terrence Dorsey <terry@pydantic.dev>, David Montague <david@pydantic.dev>, Serge Matveenko <lig@countzero.co>, Marcelo Trylesinski <marcelotryle@gmail.com>, Sydney Runkle <sydneymarierunkle@gmail.com>, David Hewitt <mail@davidhewitt.io>, Alex Hall <alex.mojaki@gmail.com>, Victorien Plot <contact@vctrn.dev>, Douwe Maan <hi@douwe.me>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Framework :: Hypothesis",
          "Framework :: Pydantic",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "annotated-types>=0.6.0",
          "pydantic-core==2.41.5",
          "typing-extensions>=4.14.1",
          "typing-inspection>=0.4.2",
          "email-validator>=2.0.0; extra == 'email'",
          "tzdata; (python_version >= '3.9' and platform_system == 'Windows') and extra == 'timezone'"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://github.com/pydantic/pydantic",
          "Documentation, https://docs.pydantic.dev",
          "Funding, https://github.com/sponsors/samuelcolvin",
          "Source, https://github.com/pydantic/pydantic",
          "Changelog, https://docs.pydantic.dev/latest/changelog/"
        ],
        "provides_extra": [
          "email",
          "timezone"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/pydantic-2.12.5.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "dbt-core",
        "version": "1.11.2",
        "summary": "With dbt, data analysts and engineers can build analytics the way engineers build applications.",
        "description": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/dbt-labs/dbt-core/fa1ea14ddfb1d5ae319d5141844910dd53ab2834/etc/dbt-core.svg\" alt=\"dbt logo\" width=\"750\"/>\n</p>\n<p align=\"center\">\n  <a href=\"https://github.com/dbt-labs/dbt-core/actions/workflows/main.yml\">\n    <img src=\"https://github.com/dbt-labs/dbt-core/actions/workflows/main.yml/badge.svg?event=push\" alt=\"CI Badge\"/>\n  </a>\n</p>\n\n**[dbt](https://www.getdbt.com/)** enables data analysts and engineers to transform their data using the same practices that software engineers use to build applications.\n\n![architecture](https://raw.githubusercontent.com/dbt-labs/dbt-core/6c6649f9129d5d108aa3b0526f634cd8f3a9d1ed/etc/dbt-arch.png)\n\n## Understanding dbt\n\nAnalysts using dbt can transform their data by simply writing select statements, while dbt handles turning these statements into tables and views in a data warehouse.\n\nThese select statements, or \"models\", form a dbt project. Models frequently build on top of one another â€“ dbt makes it easy to [manage relationships](https://docs.getdbt.com/docs/ref) between models, and [visualize these relationships](https://docs.getdbt.com/docs/documentation), as well as assure the quality of your transformations through [testing](https://docs.getdbt.com/docs/testing).\n\n![dbt dag](https://raw.githubusercontent.com/dbt-labs/dbt-core/6c6649f9129d5d108aa3b0526f634cd8f3a9d1ed/etc/dbt-dag.png)\n\n## Getting started\n\n- [Install dbt](https://docs.getdbt.com/docs/installation)\n- Read the [introduction](https://docs.getdbt.com/docs/introduction/) and [viewpoint](https://docs.getdbt.com/docs/about/viewpoint/)\n\n## Join the dbt Community\n\n- Be part of the conversation in the [dbt Community Slack](http://community.getdbt.com/)\n- Read more on the [dbt Community Discourse](https://discourse.getdbt.com)\n\n## Reporting bugs and contributing code\n\n- Want to report a bug or request a feature? Let us know on [Slack](http://community.getdbt.com/), or open [an issue](https://github.com/dbt-labs/dbt-core/issues/new)\n- Want to help us build dbt? Check out the [Contributing Guide](https://github.com/dbt-labs/dbt-core/blob/HEAD/CONTRIBUTING.md)\n\n## Code of Conduct\n\nEveryone interacting in the dbt project's codebases, issue trackers, chat rooms, and mailing lists is expected to follow the [dbt Code of Conduct](https://community.getdbt.com/code-of-conduct).\n",
        "description_content_type": "text/markdown",
        "author_email": "dbt Labs <info@dbtlabs.com>",
        "maintainer_email": "dbt Labs <info@dbtlabs.com>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX :: Linux",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_dist": [
          "agate<1.10,>=1.7.0",
          "click<9.0,>=8.2.0",
          "daff>=1.3.46",
          "dbt-adapters<2.0,>=1.15.5",
          "dbt-common<2.0,>=1.37.2",
          "dbt-extractor<=0.6,>=0.5.0",
          "dbt-protos<2.0,>=1.0.405",
          "dbt-semantic-interfaces<0.10,>=0.9.0",
          "jinja2<4,>=3.1.3",
          "jsonschema<5.0,>=4.19.1",
          "mashumaro[msgpack]<3.15,>=3.9",
          "networkx<4.0,>=2.3",
          "packaging>20.9",
          "pathspec<0.13,>=0.9",
          "protobuf<7.0,>=6.0",
          "pydantic<3",
          "pytz>=2015.7",
          "pyyaml>=6.0",
          "requests<3.0.0",
          "snowplow-tracker<2.0,>=1.0.2",
          "sqlparse<0.5.5,>=0.5.0",
          "typing-extensions>=4.4"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Homepage, https://github.com/dbt-labs/dbt-core",
          "Repository, https://github.com/dbt-labs/dbt-core.git",
          "Issues, https://github.com/dbt-labs/dbt-core/issues",
          "Changelog, https://github.com/dbt-labs/dbt-core/blob/main/CHANGELOG.md"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/dbt_core-1.11.2.dist-info",
      "installer": "pip",
      "requested": true
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "dbt-protos",
        "version": "1.0.419",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "license",
          "license-file",
          "requires-dist",
          "requires-python",
          "summary"
        ],
        "summary": "Public proto bindings for dbt",
        "description": "# dbt public protos\n\nCentral public protos repository for use in dbt.\n\nThis repository and library are 100% generated.\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/dbt-labs/proto-python-public",
        "author": "dbt Labs, Inc.",
        "author_email": "info@dbtlabs.com",
        "license": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Programming Language :: Python :: 3",
          "Operating System :: OS Independent",
          "License :: OSI Approved :: Apache Software License"
        ],
        "requires_dist": [
          "protobuf>=3.17.1"
        ],
        "requires_python": ">=3.6"
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/dbt_protos-1.0.419.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "charset-normalizer",
        "version": "3.4.4",
        "dynamic": [
          "license-file"
        ],
        "summary": "The Real First Universal Charset Detector. Open, modern and actively maintained alternative to Chardet.",
        "description": "<h1 align=\"center\">Charset Detection, for Everyone ðŸ‘‹</h1>\n\n<p align=\"center\">\n  <sup>The Real First Universal Charset Detector</sup><br>\n  <a href=\"https://pypi.org/project/charset-normalizer\">\n    <img src=\"https://img.shields.io/pypi/pyversions/charset_normalizer.svg?orange=blue\" />\n  </a>\n  <a href=\"https://pepy.tech/project/charset-normalizer/\">\n    <img alt=\"Download Count Total\" src=\"https://static.pepy.tech/badge/charset-normalizer/month\" />\n  </a>\n  <a href=\"https://bestpractices.coreinfrastructure.org/projects/7297\">\n    <img src=\"https://bestpractices.coreinfrastructure.org/projects/7297/badge\">\n  </a>\n</p>\n<p align=\"center\">\n  <sup><i>Featured Packages</i></sup><br>\n  <a href=\"https://github.com/jawah/niquests\">\n   <img alt=\"Static Badge\" src=\"https://img.shields.io/badge/Niquests-Most_Advanced_HTTP_Client-cyan\">\n  </a>\n  <a href=\"https://github.com/jawah/wassima\">\n   <img alt=\"Static Badge\" src=\"https://img.shields.io/badge/Wassima-Certifi_Replacement-cyan\">\n  </a>\n</p>\n<p align=\"center\">\n  <sup><i>In other language (unofficial port - by the community)</i></sup><br>\n  <a href=\"https://github.com/nickspring/charset-normalizer-rs\">\n   <img alt=\"Static Badge\" src=\"https://img.shields.io/badge/Rust-red\">\n  </a>\n</p>\n\n> A library that helps you read text from an unknown charset encoding.<br /> Motivated by `chardet`,\n> I'm trying to resolve the issue by taking a new approach.\n> All IANA character set names for which the Python core library provides codecs are supported.\n\n<p align=\"center\">\n  >>>>> <a href=\"https://charsetnormalizerweb.ousret.now.sh\" target=\"_blank\">ðŸ‘‰ Try Me Online Now, Then Adopt Me ðŸ‘ˆ </a> <<<<<\n</p>\n\nThis project offers you an alternative to **Universal Charset Encoding Detector**, also known as **Chardet**.\n\n| Feature                                          | [Chardet](https://github.com/chardet/chardet) |                                         Charset Normalizer                                         | [cChardet](https://github.com/PyYoshi/cChardet) |\n|--------------------------------------------------|:---------------------------------------------:|:--------------------------------------------------------------------------------------------------:|:-----------------------------------------------:|\n| `Fast`                                           |                       âŒ                       |                                                 âœ…                                                  |                        âœ…                        |\n| `Universal**`                                    |                       âŒ                       |                                                 âœ…                                                  |                        âŒ                        |\n| `Reliable` **without** distinguishable standards |                       âŒ                       |                                                 âœ…                                                  |                        âœ…                        |\n| `Reliable` **with** distinguishable standards    |                       âœ…                       |                                                 âœ…                                                  |                        âœ…                        |\n| `License`                                        |           LGPL-2.1<br>_restrictive_           |                                                MIT                                                 |            MPL-1.1<br>_restrictive_             |\n| `Native Python`                                  |                       âœ…                       |                                                 âœ…                                                  |                        âŒ                        |\n| `Detect spoken language`                         |                       âŒ                       |                                                 âœ…                                                  |                       N/A                       |\n| `UnicodeDecodeError Safety`                      |                       âŒ                       |                                                 âœ…                                                  |                        âŒ                        |\n| `Whl Size (min)`                                 |                   193.6 kB                    |                                               42 kB                                                |                     ~200 kB                     |\n| `Supported Encoding`                             |                      33                       | ðŸŽ‰ [99](https://charset-normalizer.readthedocs.io/en/latest/user/support.html#supported-encodings) |                       40                        |\n\n<p align=\"center\">\n<img src=\"https://i.imgflip.com/373iay.gif\" alt=\"Reading Normalized Text\" width=\"226\"/><img src=\"https://media.tenor.com/images/c0180f70732a18b4965448d33adba3d0/tenor.gif\" alt=\"Cat Reading Text\" width=\"200\"/>\n</p>\n\n*\\*\\* : They are clearly using specific code for a specific encoding even if covering most of used one*<br>\n\n## âš¡ Performance\n\nThis package offer better performance than its counterpart Chardet. Here are some numbers.\n\n| Package                                       | Accuracy | Mean per file (ms) | File per sec (est) |\n|-----------------------------------------------|:--------:|:------------------:|:------------------:|\n| [chardet](https://github.com/chardet/chardet) |   86 %   |       63 ms        |    16 file/sec     |\n| charset-normalizer                            | **98 %** |     **10 ms**      |    100 file/sec    |\n\n| Package                                       | 99th percentile | 95th percentile | 50th percentile |\n|-----------------------------------------------|:---------------:|:---------------:|:---------------:|\n| [chardet](https://github.com/chardet/chardet) |     265 ms      |      71 ms      |      7 ms       |\n| charset-normalizer                            |     100 ms      |      50 ms      |      5 ms       |\n\n_updated as of december 2024 using CPython 3.12_\n\nChardet's performance on larger file (1MB+) are very poor. Expect huge difference on large payload.\n\n> Stats are generated using 400+ files using default parameters. More details on used files, see GHA workflows.\n> And yes, these results might change at any time. The dataset can be updated to include more files.\n> The actual delays heavily depends on your CPU capabilities. The factors should remain the same.\n> Keep in mind that the stats are generous and that Chardet accuracy vs our is measured using Chardet initial capability\n> (e.g. Supported Encoding) Challenge-them if you want.\n\n## âœ¨ Installation\n\nUsing pip:\n\n```sh\npip install charset-normalizer -U\n```\n\n## ðŸš€ Basic Usage\n\n### CLI\nThis package comes with a CLI.\n\n```\nusage: normalizer [-h] [-v] [-a] [-n] [-m] [-r] [-f] [-t THRESHOLD]\n                  file [file ...]\n\nThe Real First Universal Charset Detector. Discover originating encoding used\non text file. Normalize text to unicode.\n\npositional arguments:\n  files                 File(s) to be analysed\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -v, --verbose         Display complementary information about file if any.\n                        Stdout will contain logs about the detection process.\n  -a, --with-alternative\n                        Output complementary possibilities if any. Top-level\n                        JSON WILL be a list.\n  -n, --normalize       Permit to normalize input file. If not set, program\n                        does not write anything.\n  -m, --minimal         Only output the charset detected to STDOUT. Disabling\n                        JSON output.\n  -r, --replace         Replace file when trying to normalize it instead of\n                        creating a new one.\n  -f, --force           Replace file without asking if you are sure, use this\n                        flag with caution.\n  -t THRESHOLD, --threshold THRESHOLD\n                        Define a custom maximum amount of chaos allowed in\n                        decoded content. 0. <= chaos <= 1.\n  --version             Show version information and exit.\n```\n\n```bash\nnormalizer ./data/sample.1.fr.srt\n```\n\nor\n\n```bash\npython -m charset_normalizer ./data/sample.1.fr.srt\n```\n\nðŸŽ‰ Since version 1.4.0 the CLI produce easily usable stdout result in JSON format.\n\n```json\n{\n    \"path\": \"/home/default/projects/charset_normalizer/data/sample.1.fr.srt\",\n    \"encoding\": \"cp1252\",\n    \"encoding_aliases\": [\n        \"1252\",\n        \"windows_1252\"\n    ],\n    \"alternative_encodings\": [\n        \"cp1254\",\n        \"cp1256\",\n        \"cp1258\",\n        \"iso8859_14\",\n        \"iso8859_15\",\n        \"iso8859_16\",\n        \"iso8859_3\",\n        \"iso8859_9\",\n        \"latin_1\",\n        \"mbcs\"\n    ],\n    \"language\": \"French\",\n    \"alphabets\": [\n        \"Basic Latin\",\n        \"Latin-1 Supplement\"\n    ],\n    \"has_sig_or_bom\": false,\n    \"chaos\": 0.149,\n    \"coherence\": 97.152,\n    \"unicode_path\": null,\n    \"is_preferred\": true\n}\n```\n\n### Python\n*Just print out normalized text*\n```python\nfrom charset_normalizer import from_path\n\nresults = from_path('./my_subtitle.srt')\n\nprint(str(results.best()))\n```\n\n*Upgrade your code without effort*\n```python\nfrom charset_normalizer import detect\n```\n\nThe above code will behave the same as **chardet**. We ensure that we offer the best (reasonable) BC result possible.\n\nSee the docs for advanced usage : [readthedocs.io](https://charset-normalizer.readthedocs.io/en/latest/)\n\n## ðŸ˜‡ Why\n\nWhen I started using Chardet, I noticed that it was not suited to my expectations, and I wanted to propose a\nreliable alternative using a completely different method. Also! I never back down on a good challenge!\n\nI **don't care** about the **originating charset** encoding, because **two different tables** can\nproduce **two identical rendered string.**\nWhat I want is to get readable text, the best I can.\n\nIn a way, **I'm brute forcing text decoding.** How cool is that ? ðŸ˜Ž\n\nDon't confuse package **ftfy** with charset-normalizer or chardet. ftfy goal is to repair Unicode string whereas charset-normalizer to convert raw file in unknown encoding to unicode.\n\n## ðŸ° How\n\n  - Discard all charset encoding table that could not fit the binary content.\n  - Measure noise, or the mess once opened (by chunks) with a corresponding charset encoding.\n  - Extract matches with the lowest mess detected.\n  - Additionally, we measure coherence / probe for a language.\n\n**Wait a minute**, what is noise/mess and coherence according to **YOU ?**\n\n*Noise :* I opened hundred of text files, **written by humans**, with the wrong encoding table. **I observed**, then\n**I established** some ground rules about **what is obvious** when **it seems like** a mess (aka. defining noise in rendered text).\n I know that my interpretation of what is noise is probably incomplete, feel free to contribute in order to\n improve or rewrite it.\n\n*Coherence :* For each language there is on earth, we have computed ranked letter appearance occurrences (the best we can). So I thought\nthat intel is worth something here. So I use those records against decoded text to check if I can detect intelligent design.\n\n## âš¡ Known limitations\n\n  - Language detection is unreliable when text contains two or more languages sharing identical letters. (eg. HTML (english tags) + Turkish content (Sharing Latin characters))\n  - Every charset detector heavily depends on sufficient content. In common cases, do not bother run detection on very tiny content.\n\n## âš ï¸ About Python EOLs\n\n**If you are running:**\n\n- Python >=2.7,<3.5: Unsupported\n- Python 3.5: charset-normalizer < 2.1\n- Python 3.6: charset-normalizer < 3.1\n- Python 3.7: charset-normalizer < 4.0\n\nUpgrade your Python interpreter as soon as possible.\n\n## ðŸ‘¤ Contributing\n\nContributions, issues and feature requests are very much welcome.<br />\nFeel free to check [issues page](https://github.com/ousret/charset_normalizer/issues) if you want to contribute.\n\n## ðŸ“ License\n\nCopyright Â© [Ahmed TAHRI @Ousret](https://github.com/Ousret).<br />\nThis project is [MIT](https://github.com/Ousret/charset_normalizer/blob/master/LICENSE) licensed.\n\nCharacters frequencies used in this project Â© 2012 [Denny VrandeÄiÄ‡](http://simia.net/letters/)\n\n## ðŸ’¼ For Enterprise\n\nProfessional support for charset-normalizer is available as part of the [Tidelift\nSubscription][1]. Tidelift gives software development teams a single source for\npurchasing and maintaining their software, with professional grade assurances\nfrom the experts who know it best, while seamlessly integrating with existing\ntools.\n\n[1]: https://tidelift.com/subscription/pkg/pypi-charset-normalizer?utm_source=pypi-charset-normalizer&utm_medium=readme\n\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/7297/badge)](https://www.bestpractices.dev/projects/7297)\n\n# Changelog\nAll notable changes to charset-normalizer will be documented in this file. This project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/).\n\n## [3.4.4](https://github.com/Ousret/charset_normalizer/compare/3.4.2...3.4.4) (2025-10-13)\n\n### Changed\n- Bound `setuptools` to a specific constraint `setuptools>=68,<=81`.\n- Raised upper bound of mypyc for the optional pre-built extension to v1.18.2\n\n### Removed\n- `setuptools-scm` as a build dependency.\n\n### Misc\n- Enforced hashes in `dev-requirements.txt` and created `ci-requirements.txt` for security purposes.\n- Additional pre-built wheels for riscv64, s390x, and armv7l architectures.\n- Restore ` multiple.intoto.jsonl` in GitHub releases in addition to individual attestation file per wheel.\n\n## [3.4.3](https://github.com/Ousret/charset_normalizer/compare/3.4.2...3.4.3) (2025-08-09)\n\n### Changed\n- mypy(c) is no longer a required dependency at build time if `CHARSET_NORMALIZER_USE_MYPYC` isn't set to `1`. (#595) (#583)\n- automatically lower confidence on small bytes samples that are not Unicode in `detect` output legacy function. (#391)\n\n### Added\n- Custom build backend to overcome inability to mark mypy as an optional dependency in the build phase.\n- Support for Python 3.14\n\n### Fixed\n- sdist archive contained useless directories.\n- automatically fallback on valid UTF-16 or UTF-32 even if the md says it's noisy. (#633)\n\n### Misc\n- SBOM are automatically published to the relevant GitHub release to comply with regulatory changes.\n  Each published wheel comes with its SBOM. We choose CycloneDX as the format.\n- Prebuilt optimized wheel are no longer distributed by default for CPython 3.7 due to a change in cibuildwheel.\n\n## [3.4.2](https://github.com/Ousret/charset_normalizer/compare/3.4.1...3.4.2) (2025-05-02)\n\n### Fixed\n- Addressed the DeprecationWarning in our CLI regarding `argparse.FileType` by backporting the target class into the package. (#591)\n- Improved the overall reliability of the detector with CJK Ideographs. (#605) (#587)\n\n### Changed\n- Optional mypyc compilation upgraded to version 1.15 for Python >= 3.8\n\n## [3.4.1](https://github.com/Ousret/charset_normalizer/compare/3.4.0...3.4.1) (2024-12-24)\n\n### Changed\n- Project metadata are now stored using `pyproject.toml` instead of `setup.cfg` using setuptools as the build backend.\n- Enforce annotation delayed loading for a simpler and consistent types in the project.\n- Optional mypyc compilation upgraded to version 1.14 for Python >= 3.8\n\n### Added\n- pre-commit configuration.\n- noxfile.\n\n### Removed\n- `build-requirements.txt` as per using `pyproject.toml` native build configuration.\n- `bin/integration.py` and `bin/serve.py` in favor of downstream integration test (see noxfile).\n- `setup.cfg` in favor of `pyproject.toml` metadata configuration.\n- Unused `utils.range_scan` function.\n\n### Fixed\n- Converting content to Unicode bytes may insert `utf_8` instead of preferred `utf-8`. (#572)\n- Deprecation warning \"'count' is passed as positional argument\" when converting to Unicode bytes on Python 3.13+\n\n## [3.4.0](https://github.com/Ousret/charset_normalizer/compare/3.3.2...3.4.0) (2024-10-08)\n\n### Added\n- Argument `--no-preemptive` in the CLI to prevent the detector to search for hints.\n- Support for Python 3.13 (#512)\n\n### Fixed\n- Relax the TypeError exception thrown when trying to compare a CharsetMatch with anything else than a CharsetMatch.\n- Improved the general reliability of the detector based on user feedbacks. (#520) (#509) (#498) (#407) (#537)\n- Declared charset in content (preemptive detection) not changed when converting to utf-8 bytes. (#381)\n\n## [3.3.2](https://github.com/Ousret/charset_normalizer/compare/3.3.1...3.3.2) (2023-10-31)\n\n### Fixed\n- Unintentional memory usage regression when using large payload that match several encoding (#376)\n- Regression on some detection case showcased in the documentation (#371)\n\n### Added\n- Noise (md) probe that identify malformed arabic representation due to the presence of letters in isolated form (credit to my wife)\n\n## [3.3.1](https://github.com/Ousret/charset_normalizer/compare/3.3.0...3.3.1) (2023-10-22)\n\n### Changed\n- Optional mypyc compilation upgraded to version 1.6.1 for Python >= 3.8\n- Improved the general detection reliability based on reports from the community\n\n## [3.3.0](https://github.com/Ousret/charset_normalizer/compare/3.2.0...3.3.0) (2023-09-30)\n\n### Added\n- Allow to execute the CLI (e.g. normalizer) through `python -m charset_normalizer.cli` or `python -m charset_normalizer`\n- Support for 9 forgotten encoding that are supported by Python but unlisted in `encoding.aliases` as they have no alias (#323)\n\n### Removed\n- (internal) Redundant utils.is_ascii function and unused function is_private_use_only\n- (internal) charset_normalizer.assets is moved inside charset_normalizer.constant\n\n### Changed\n- (internal) Unicode code blocks in constants are updated using the latest v15.0.0 definition to improve detection\n- Optional mypyc compilation upgraded to version 1.5.1 for Python >= 3.8\n\n### Fixed\n- Unable to properly sort CharsetMatch when both chaos/noise and coherence were close due to an unreachable condition in \\_\\_lt\\_\\_ (#350)\n\n## [3.2.0](https://github.com/Ousret/charset_normalizer/compare/3.1.0...3.2.0) (2023-06-07)\n\n### Changed\n- Typehint for function `from_path` no longer enforce `PathLike` as its first argument\n- Minor improvement over the global detection reliability\n\n### Added\n- Introduce function `is_binary` that relies on main capabilities, and optimized to detect binaries\n- Propagate `enable_fallback` argument throughout `from_bytes`, `from_path`, and `from_fp` that allow a deeper control over the detection (default True)\n- Explicit support for Python 3.12\n\n### Fixed\n- Edge case detection failure where a file would contain 'very-long' camel cased word (Issue #289)\n\n## [3.1.0](https://github.com/Ousret/charset_normalizer/compare/3.0.1...3.1.0) (2023-03-06)\n\n### Added\n- Argument `should_rename_legacy` for legacy function `detect` and disregard any new arguments without errors (PR #262)\n\n### Removed\n- Support for Python 3.6 (PR #260)\n\n### Changed\n- Optional speedup provided by mypy/c 1.0.1\n\n## [3.0.1](https://github.com/Ousret/charset_normalizer/compare/3.0.0...3.0.1) (2022-11-18)\n\n### Fixed\n- Multi-bytes cutter/chunk generator did not always cut correctly (PR #233)\n\n### Changed\n- Speedup provided by mypy/c 0.990 on Python >= 3.7\n\n## [3.0.0](https://github.com/Ousret/charset_normalizer/compare/2.1.1...3.0.0) (2022-10-20)\n\n### Added\n- Extend the capability of explain=True when cp_isolation contains at most two entries (min one), will log in details of the Mess-detector results\n- Support for alternative language frequency set in charset_normalizer.assets.FREQUENCIES\n- Add parameter `language_threshold` in `from_bytes`, `from_path` and `from_fp` to adjust the minimum expected coherence ratio\n- `normalizer --version` now specify if current version provide extra speedup (meaning mypyc compilation whl)\n\n### Changed\n- Build with static metadata using 'build' frontend\n- Make the language detection stricter\n- Optional: Module `md.py` can be compiled using Mypyc to provide an extra speedup up to 4x faster than v2.1\n\n### Fixed\n- CLI with opt --normalize fail when using full path for files\n- TooManyAccentuatedPlugin induce false positive on the mess detection when too few alpha character have been fed to it\n- Sphinx warnings when generating the documentation\n\n### Removed\n- Coherence detector no longer return 'Simple English' instead return 'English'\n- Coherence detector no longer return 'Classical Chinese' instead return 'Chinese'\n- Breaking: Method `first()` and `best()` from CharsetMatch\n- UTF-7 will no longer appear as \"detected\" without a recognized SIG/mark (is unreliable/conflict with ASCII)\n- Breaking: Class aliases CharsetDetector, CharsetDoctor, CharsetNormalizerMatch and CharsetNormalizerMatches\n- Breaking: Top-level function `normalize`\n- Breaking: Properties `chaos_secondary_pass`, `coherence_non_latin` and `w_counter` from CharsetMatch\n- Support for the backport `unicodedata2`\n\n## [3.0.0rc1](https://github.com/Ousret/charset_normalizer/compare/3.0.0b2...3.0.0rc1) (2022-10-18)\n\n### Added\n- Extend the capability of explain=True when cp_isolation contains at most two entries (min one), will log in details of the Mess-detector results\n- Support for alternative language frequency set in charset_normalizer.assets.FREQUENCIES\n- Add parameter `language_threshold` in `from_bytes`, `from_path` and `from_fp` to adjust the minimum expected coherence ratio\n\n### Changed\n- Build with static metadata using 'build' frontend\n- Make the language detection stricter\n\n### Fixed\n- CLI with opt --normalize fail when using full path for files\n- TooManyAccentuatedPlugin induce false positive on the mess detection when too few alpha character have been fed to it\n\n### Removed\n- Coherence detector no longer return 'Simple English' instead return 'English'\n- Coherence detector no longer return 'Classical Chinese' instead return 'Chinese'\n\n## [3.0.0b2](https://github.com/Ousret/charset_normalizer/compare/3.0.0b1...3.0.0b2) (2022-08-21)\n\n### Added\n- `normalizer --version` now specify if current version provide extra speedup (meaning mypyc compilation whl)\n\n### Removed\n- Breaking: Method `first()` and `best()` from CharsetMatch\n- UTF-7 will no longer appear as \"detected\" without a recognized SIG/mark (is unreliable/conflict with ASCII)\n\n### Fixed\n- Sphinx warnings when generating the documentation\n\n## [3.0.0b1](https://github.com/Ousret/charset_normalizer/compare/2.1.0...3.0.0b1) (2022-08-15)\n\n### Changed\n- Optional: Module `md.py` can be compiled using Mypyc to provide an extra speedup up to 4x faster than v2.1\n\n### Removed\n- Breaking: Class aliases CharsetDetector, CharsetDoctor, CharsetNormalizerMatch and CharsetNormalizerMatches\n- Breaking: Top-level function `normalize`\n- Breaking: Properties `chaos_secondary_pass`, `coherence_non_latin` and `w_counter` from CharsetMatch\n- Support for the backport `unicodedata2`\n\n## [2.1.1](https://github.com/Ousret/charset_normalizer/compare/2.1.0...2.1.1) (2022-08-19)\n\n### Deprecated\n- Function `normalize` scheduled for removal in 3.0\n\n### Changed\n- Removed useless call to decode in fn is_unprintable (#206)\n\n### Fixed\n- Third-party library (i18n xgettext) crashing not recognizing utf_8 (PEP 263) with underscore from [@aleksandernovikov](https://github.com/aleksandernovikov) (#204)\n\n## [2.1.0](https://github.com/Ousret/charset_normalizer/compare/2.0.12...2.1.0) (2022-06-19)\n\n### Added\n- Output the Unicode table version when running the CLI with `--version` (PR #194)\n\n### Changed\n- Re-use decoded buffer for single byte character sets from [@nijel](https://github.com/nijel) (PR #175)\n- Fixing some performance bottlenecks from [@deedy5](https://github.com/deedy5) (PR #183)\n\n### Fixed\n- Workaround potential bug in cpython with Zero Width No-Break Space located in Arabic Presentation Forms-B, Unicode 1.1 not acknowledged as space (PR #175)\n- CLI default threshold aligned with the API threshold from [@oleksandr-kuzmenko](https://github.com/oleksandr-kuzmenko) (PR #181)\n\n### Removed\n- Support for Python 3.5 (PR #192)\n\n### Deprecated\n- Use of backport unicodedata from `unicodedata2` as Python is quickly catching up, scheduled for removal in 3.0 (PR #194)\n\n## [2.0.12](https://github.com/Ousret/charset_normalizer/compare/2.0.11...2.0.12) (2022-02-12)\n\n### Fixed\n- ASCII miss-detection on rare cases (PR #170)\n\n## [2.0.11](https://github.com/Ousret/charset_normalizer/compare/2.0.10...2.0.11) (2022-01-30)\n\n### Added\n- Explicit support for Python 3.11 (PR #164)\n\n### Changed\n- The logging behavior have been completely reviewed, now using only TRACE and DEBUG levels (PR #163 #165)\n\n## [2.0.10](https://github.com/Ousret/charset_normalizer/compare/2.0.9...2.0.10) (2022-01-04)\n\n### Fixed\n- Fallback match entries might lead to UnicodeDecodeError for large bytes sequence (PR #154)\n\n### Changed\n- Skipping the language-detection (CD) on ASCII (PR #155)\n\n## [2.0.9](https://github.com/Ousret/charset_normalizer/compare/2.0.8...2.0.9) (2021-12-03)\n\n### Changed\n- Moderating the logging impact (since 2.0.8) for specific environments (PR #147)\n\n### Fixed\n- Wrong logging level applied when setting kwarg `explain` to True (PR #146)\n\n## [2.0.8](https://github.com/Ousret/charset_normalizer/compare/2.0.7...2.0.8) (2021-11-24)\n### Changed\n- Improvement over Vietnamese detection (PR #126)\n- MD improvement on trailing data and long foreign (non-pure latin) data (PR #124)\n- Efficiency improvements in cd/alphabet_languages from [@adbar](https://github.com/adbar) (PR #122)\n- call sum() without an intermediary list following PEP 289 recommendations from [@adbar](https://github.com/adbar) (PR #129)\n- Code style as refactored by Sourcery-AI (PR #131)\n- Minor adjustment on the MD around european words (PR #133)\n- Remove and replace SRTs from assets / tests (PR #139)\n- Initialize the library logger with a `NullHandler` by default from [@nmaynes](https://github.com/nmaynes) (PR #135)\n- Setting kwarg `explain` to True will add provisionally (bounded to function lifespan) a specific stream handler (PR #135)\n\n### Fixed\n- Fix large (misleading) sequence giving UnicodeDecodeError (PR #137)\n- Avoid using too insignificant chunk (PR #137)\n\n### Added\n- Add and expose function `set_logging_handler` to configure a specific StreamHandler from [@nmaynes](https://github.com/nmaynes) (PR #135)\n- Add `CHANGELOG.md` entries, format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/) (PR #141)\n\n## [2.0.7](https://github.com/Ousret/charset_normalizer/compare/2.0.6...2.0.7) (2021-10-11)\n### Added\n- Add support for Kazakh (Cyrillic) language detection (PR #109)\n\n### Changed\n- Further, improve inferring the language from a given single-byte code page (PR #112)\n- Vainly trying to leverage PEP263 when PEP3120 is not supported (PR #116)\n- Refactoring for potential performance improvements in loops from [@adbar](https://github.com/adbar) (PR #113)\n- Various detection improvement (MD+CD) (PR #117)\n\n### Removed\n- Remove redundant logging entry about detected language(s) (PR #115)\n\n### Fixed\n- Fix a minor inconsistency between Python 3.5 and other versions regarding language detection (PR #117 #102)\n\n## [2.0.6](https://github.com/Ousret/charset_normalizer/compare/2.0.5...2.0.6) (2021-09-18)\n### Fixed\n- Unforeseen regression with the loss of the backward-compatibility with some older minor of Python 3.5.x (PR #100)\n- Fix CLI crash when using --minimal output in certain cases (PR #103)\n\n### Changed\n- Minor improvement to the detection efficiency (less than 1%) (PR #106 #101)\n\n## [2.0.5](https://github.com/Ousret/charset_normalizer/compare/2.0.4...2.0.5) (2021-09-14)\n### Changed\n- The project now comply with: flake8, mypy, isort and black to ensure a better overall quality (PR #81)\n- The BC-support with v1.x was improved, the old staticmethods are restored (PR #82)\n- The Unicode detection is slightly improved (PR #93)\n- Add syntax sugar \\_\\_bool\\_\\_ for results CharsetMatches list-container (PR #91)\n\n### Removed\n- The project no longer raise warning on tiny content given for detection, will be simply logged as warning instead (PR #92)\n\n### Fixed\n- In some rare case, the chunks extractor could cut in the middle of a multi-byte character and could mislead the mess detection (PR #95)\n- Some rare 'space' characters could trip up the UnprintablePlugin/Mess detection (PR #96)\n- The MANIFEST.in was not exhaustive (PR #78)\n\n## [2.0.4](https://github.com/Ousret/charset_normalizer/compare/2.0.3...2.0.4) (2021-07-30)\n### Fixed\n- The CLI no longer raise an unexpected exception when no encoding has been found (PR #70)\n- Fix accessing the 'alphabets' property when the payload contains surrogate characters (PR #68)\n- The logger could mislead (explain=True) on detected languages and the impact of one MBCS match (PR #72)\n- Submatch factoring could be wrong in rare edge cases (PR #72)\n- Multiple files given to the CLI were ignored when publishing results to STDOUT. (After the first path) (PR #72)\n- Fix line endings from CRLF to LF for certain project files (PR #67)\n\n### Changed\n- Adjust the MD to lower the sensitivity, thus improving the global detection reliability (PR #69 #76)\n- Allow fallback on specified encoding if any (PR #71)\n\n## [2.0.3](https://github.com/Ousret/charset_normalizer/compare/2.0.2...2.0.3) (2021-07-16)\n### Changed\n- Part of the detection mechanism has been improved to be less sensitive, resulting in more accurate detection results. Especially ASCII. (PR #63)\n- According to the community wishes, the detection will fall back on ASCII or UTF-8 in a last-resort case. (PR #64)\n\n## [2.0.2](https://github.com/Ousret/charset_normalizer/compare/2.0.1...2.0.2) (2021-07-15)\n### Fixed\n- Empty/Too small JSON payload miss-detection fixed. Report from [@tseaver](https://github.com/tseaver) (PR #59)\n\n### Changed\n- Don't inject unicodedata2 into sys.modules from [@akx](https://github.com/akx) (PR #57)\n\n## [2.0.1](https://github.com/Ousret/charset_normalizer/compare/2.0.0...2.0.1) (2021-07-13)\n### Fixed\n- Make it work where there isn't a filesystem available, dropping assets frequencies.json. Report from [@sethmlarson](https://github.com/sethmlarson). (PR #55)\n- Using explain=False permanently disable the verbose output in the current runtime (PR #47)\n- One log entry (language target preemptive) was not show in logs when using explain=True (PR #47)\n- Fix undesired exception (ValueError) on getitem of instance CharsetMatches (PR #52)\n\n### Changed\n- Public function normalize default args values were not aligned with from_bytes (PR #53)\n\n### Added\n- You may now use charset aliases in cp_isolation and cp_exclusion arguments (PR #47)\n\n## [2.0.0](https://github.com/Ousret/charset_normalizer/compare/1.4.1...2.0.0) (2021-07-02)\n### Changed\n- 4x to 5 times faster than the previous 1.4.0 release. At least 2x faster than Chardet.\n- Accent has been made on UTF-8 detection, should perform rather instantaneous.\n- The backward compatibility with Chardet has been greatly improved. The legacy detect function returns an identical charset name whenever possible.\n- The detection mechanism has been slightly improved, now Turkish content is detected correctly (most of the time)\n- The program has been rewritten to ease the readability and maintainability. (+Using static typing)+\n- utf_7 detection has been reinstated.\n\n### Removed\n- This package no longer require anything when used with Python 3.5 (Dropped cached_property)\n- Removed support for these languages: Catalan, Esperanto, Kazakh, Baque, VolapÃ¼k, Azeri, Galician, Nynorsk, Macedonian, and Serbocroatian.\n- The exception hook on UnicodeDecodeError has been removed.\n\n### Deprecated\n- Methods coherence_non_latin, w_counter, chaos_secondary_pass of the class CharsetMatch are now deprecated and scheduled for removal in v3.0\n\n### Fixed\n- The CLI output used the relative path of the file(s). Should be absolute.\n\n## [1.4.1](https://github.com/Ousret/charset_normalizer/compare/1.4.0...1.4.1) (2021-05-28)\n### Fixed\n- Logger configuration/usage no longer conflict with others (PR #44)\n\n## [1.4.0](https://github.com/Ousret/charset_normalizer/compare/1.3.9...1.4.0) (2021-05-21)\n### Removed\n- Using standard logging instead of using the package loguru.\n- Dropping nose test framework in favor of the maintained pytest.\n- Choose to not use dragonmapper package to help with gibberish Chinese/CJK text.\n- Require cached_property only for Python 3.5 due to constraint. Dropping for every other interpreter version.\n- Stop support for UTF-7 that does not contain a SIG.\n- Dropping PrettyTable, replaced with pure JSON output in CLI.\n\n### Fixed\n- BOM marker in a CharsetNormalizerMatch instance could be False in rare cases even if obviously present. Due to the sub-match factoring process.\n- Not searching properly for the BOM when trying utf32/16 parent codec.\n\n### Changed\n- Improving the package final size by compressing frequencies.json.\n- Huge improvement over the larges payload.\n\n### Added\n- CLI now produces JSON consumable output.\n- Return ASCII if given sequences fit. Given reasonable confidence.\n\n## [1.3.9](https://github.com/Ousret/charset_normalizer/compare/1.3.8...1.3.9) (2021-05-13)\n\n### Fixed\n- In some very rare cases, you may end up getting encode/decode errors due to a bad bytes payload (PR #40)\n\n## [1.3.8](https://github.com/Ousret/charset_normalizer/compare/1.3.7...1.3.8) (2021-05-12)\n\n### Fixed\n- Empty given payload for detection may cause an exception if trying to access the `alphabets` property. (PR #39)\n\n## [1.3.7](https://github.com/Ousret/charset_normalizer/compare/1.3.6...1.3.7) (2021-05-12)\n\n### Fixed\n- The legacy detect function should return UTF-8-SIG if sig is present in the payload. (PR #38)\n\n## [1.3.6](https://github.com/Ousret/charset_normalizer/compare/1.3.5...1.3.6) (2021-02-09)\n\n### Changed\n- Amend the previous release to allow prettytable 2.0 (PR #35)\n\n## [1.3.5](https://github.com/Ousret/charset_normalizer/compare/1.3.4...1.3.5) (2021-02-08)\n\n### Fixed\n- Fix error while using the package with a python pre-release interpreter (PR #33)\n\n### Changed\n- Dependencies refactoring, constraints revised.\n\n### Added\n- Add python 3.9 and 3.10 to the supported interpreters\n\nMIT License\n\nCopyright (c) 2025 TAHRI Ahmed R.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "encoding",
          "charset",
          "charset-detector",
          "detector",
          "normalization",
          "unicode",
          "chardet",
          "detect"
        ],
        "author_email": "\"Ahmed R. TAHRI\" <tahri.ahmed@proton.me>",
        "maintainer_email": "\"Ahmed R. TAHRI\" <tahri.ahmed@proton.me>",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Text Processing :: Linguistic",
          "Topic :: Utilities",
          "Typing :: Typed"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Changelog, https://github.com/jawah/charset_normalizer/blob/master/CHANGELOG.md",
          "Documentation, https://charset-normalizer.readthedocs.io/",
          "Code, https://github.com/jawah/charset_normalizer",
          "Issue tracker, https://github.com/jawah/charset_normalizer/issues"
        ],
        "provides_extra": [
          "unicode-backport"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/charset_normalizer-3.4.4.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "python-dateutil",
        "version": "2.9.0.post0",
        "summary": "Extensions to the standard Python datetime module",
        "description": "dateutil - powerful extensions to datetime\n==========================================\n\n|pypi| |support| |licence|\n\n|gitter| |readthedocs|\n\n|travis| |appveyor| |pipelines| |coverage|\n\n.. |pypi| image:: https://img.shields.io/pypi/v/python-dateutil.svg?style=flat-square\n    :target: https://pypi.org/project/python-dateutil/\n    :alt: pypi version\n\n.. |support| image:: https://img.shields.io/pypi/pyversions/python-dateutil.svg?style=flat-square\n    :target: https://pypi.org/project/python-dateutil/\n    :alt: supported Python version\n\n.. |travis| image:: https://img.shields.io/travis/dateutil/dateutil/master.svg?style=flat-square&label=Travis%20Build\n    :target: https://travis-ci.org/dateutil/dateutil\n    :alt: travis build status\n\n.. |appveyor| image:: https://img.shields.io/appveyor/ci/dateutil/dateutil/master.svg?style=flat-square&logo=appveyor\n    :target: https://ci.appveyor.com/project/dateutil/dateutil\n    :alt: appveyor build status\n\n.. |pipelines| image:: https://dev.azure.com/pythondateutilazure/dateutil/_apis/build/status/dateutil.dateutil?branchName=master\n    :target: https://dev.azure.com/pythondateutilazure/dateutil/_build/latest?definitionId=1&branchName=master\n    :alt: azure pipelines build status\n\n.. |coverage| image:: https://codecov.io/gh/dateutil/dateutil/branch/master/graphs/badge.svg?branch=master\n    :target: https://codecov.io/gh/dateutil/dateutil?branch=master\n    :alt: Code coverage\n\n.. |gitter| image:: https://badges.gitter.im/dateutil/dateutil.svg\n   :alt: Join the chat at https://gitter.im/dateutil/dateutil\n   :target: https://gitter.im/dateutil/dateutil\n\n.. |licence| image:: https://img.shields.io/pypi/l/python-dateutil.svg?style=flat-square\n    :target: https://pypi.org/project/python-dateutil/\n    :alt: licence\n\n.. |readthedocs| image:: https://img.shields.io/readthedocs/dateutil/latest.svg?style=flat-square&label=Read%20the%20Docs\n   :alt: Read the documentation at https://dateutil.readthedocs.io/en/latest/\n   :target: https://dateutil.readthedocs.io/en/latest/\n\nThe `dateutil` module provides powerful extensions to\nthe standard `datetime` module, available in Python.\n\nInstallation\n============\n`dateutil` can be installed from PyPI using `pip` (note that the package name is\ndifferent from the importable name)::\n\n    pip install python-dateutil\n\nDownload\n========\ndateutil is available on PyPI\nhttps://pypi.org/project/python-dateutil/\n\nThe documentation is hosted at:\nhttps://dateutil.readthedocs.io/en/stable/\n\nCode\n====\nThe code and issue tracker are hosted on GitHub:\nhttps://github.com/dateutil/dateutil/\n\nFeatures\n========\n\n* Computing of relative deltas (next month, next year,\n  next Monday, last week of month, etc);\n* Computing of relative deltas between two given\n  date and/or datetime objects;\n* Computing of dates based on very flexible recurrence rules,\n  using a superset of the `iCalendar <https://www.ietf.org/rfc/rfc2445.txt>`_\n  specification. Parsing of RFC strings is supported as well.\n* Generic parsing of dates in almost any string format;\n* Timezone (tzinfo) implementations for tzfile(5) format\n  files (/etc/localtime, /usr/share/zoneinfo, etc), TZ\n  environment string (in all known formats), iCalendar\n  format files, given ranges (with help from relative deltas),\n  local machine timezone, fixed offset timezone, UTC timezone,\n  and Windows registry-based time zones.\n* Internal up-to-date world timezone information based on\n  Olson's database.\n* Computing of Easter Sunday dates for any given year,\n  using Western, Orthodox or Julian algorithms;\n* A comprehensive test suite.\n\nQuick example\n=============\nHere's a snapshot, just to give an idea about the power of the\npackage. For more examples, look at the documentation.\n\nSuppose you want to know how much time is left, in\nyears/months/days/etc, before the next easter happening on a\nyear with a Friday 13th in August, and you want to get today's\ndate out of the \"date\" unix system command. Here is the code:\n\n.. code-block:: python3\n\n    >>> from dateutil.relativedelta import *\n    >>> from dateutil.easter import *\n    >>> from dateutil.rrule import *\n    >>> from dateutil.parser import *\n    >>> from datetime import *\n    >>> now = parse(\"Sat Oct 11 17:13:46 UTC 2003\")\n    >>> today = now.date()\n    >>> year = rrule(YEARLY,dtstart=now,bymonth=8,bymonthday=13,byweekday=FR)[0].year\n    >>> rdelta = relativedelta(easter(year), today)\n    >>> print(\"Today is: %s\" % today)\n    Today is: 2003-10-11\n    >>> print(\"Year with next Aug 13th on a Friday is: %s\" % year)\n    Year with next Aug 13th on a Friday is: 2004\n    >>> print(\"How far is the Easter of that year: %s\" % rdelta)\n    How far is the Easter of that year: relativedelta(months=+6)\n    >>> print(\"And the Easter of that year is: %s\" % (today+rdelta))\n    And the Easter of that year is: 2004-04-11\n\nBeing exactly 6 months ahead was **really** a coincidence :)\n\nContributing\n============\n\nWe welcome many types of contributions - bug reports, pull requests (code, infrastructure or documentation fixes). For more information about how to contribute to the project, see the ``CONTRIBUTING.md`` file in the repository.\n\n\nAuthor\n======\nThe dateutil module was written by Gustavo Niemeyer <gustavo@niemeyer.net>\nin 2003.\n\nIt is maintained by:\n\n* Gustavo Niemeyer <gustavo@niemeyer.net> 2003-2011\n* Tomi PievilÃ¤inen <tomi.pievilainen@iki.fi> 2012-2014\n* Yaron de Leeuw <me@jarondl.net> 2014-2016\n* Paul Ganssle <paul@ganssle.io> 2015-\n\nStarting with version 2.4.1 and running until 2.8.2, all source and binary\ndistributions will be signed by a PGP key that has, at the very least, been\nsigned by the key which made the previous release. A table of release signing\nkeys can be found below:\n\n===========  ============================\nReleases     Signing key fingerprint\n===========  ============================\n2.4.1-2.8.2  `6B49 ACBA DCF6 BD1C A206 67AB CD54 FCE3 D964 BEFB`_\n===========  ============================\n\nNew releases *may* have signed tags, but binary and source distributions\nuploaded to PyPI will no longer have GPG signatures attached.\n\nContact\n=======\nOur mailing list is available at `dateutil@python.org <https://mail.python.org/mailman/listinfo/dateutil>`_. As it is hosted by the PSF, it is subject to the `PSF code of\nconduct <https://www.python.org/psf/conduct/>`_.\n\nLicense\n=======\n\nAll contributions after December 1, 2017 released under dual license - either `Apache 2.0 License <https://www.apache.org/licenses/LICENSE-2.0>`_ or the `BSD 3-Clause License <https://opensource.org/licenses/BSD-3-Clause>`_. Contributions before December 1, 2017 - except those those explicitly relicensed - are released only under the BSD 3-Clause License.\n\n\n.. _6B49 ACBA DCF6 BD1C A206 67AB CD54 FCE3 D964 BEFB:\n   https://pgp.mit.edu/pks/lookup?op=vindex&search=0xCD54FCE3D964BEFB\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/dateutil/dateutil",
        "author": "Gustavo Niemeyer",
        "author_email": "gustavo@niemeyer.net",
        "maintainer": "Paul Ganssle",
        "maintainer_email": "dateutil@python.org",
        "license": "Dual License",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.3",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          "Programming Language :: Python :: 3.6",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Software Development :: Libraries"
        ],
        "requires_dist": [
          "six >=1.5"
        ],
        "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,>=2.7",
        "project_url": [
          "Documentation, https://dateutil.readthedocs.io/en/stable/",
          "Source, https://github.com/dateutil/dateutil"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/python_dateutil-2.9.0.post0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "attrs",
        "version": "25.4.0",
        "summary": "Classes Without Boilerplate",
        "description": "<p align=\"center\">\n  <a href=\"https://www.attrs.org/\">\n    <img src=\"https://raw.githubusercontent.com/python-attrs/attrs/main/docs/_static/attrs_logo.svg\" width=\"35%\" alt=\"attrs\" />\n  </a>\n</p>\n\n\n*attrs* is the Python package that will bring back the **joy** of **writing classes** by relieving you from the drudgery of implementing object protocols (aka [dunder methods](https://www.attrs.org/en/latest/glossary.html#term-dunder-methods)).\nTrusted by NASA for [Mars missions since 2020](https://github.com/readme/featured/nasa-ingenuity-helicopter)!\n\nIts main goal is to help you to write **concise** and **correct** software without slowing down your code.\n\n\n## Sponsors\n\n*attrs* would not be possible without our [amazing sponsors](https://github.com/sponsors/hynek).\nEspecially those generously supporting us at the *The Organization* tier and higher:\n\n<!-- sponsor-break-begin -->\n\n<p align=\"center\">\n\n<!-- [[[cog\nimport pathlib, tomllib\n\nfor sponsor in tomllib.loads(pathlib.Path(\"pyproject.toml\").read_text())[\"tool\"][\"sponcon\"][\"sponsors\"]:\n      print(f'<a href=\"{sponsor[\"url\"]}\"><img title=\"{sponsor[\"title\"]}\" src=\"https://www.attrs.org/en/25.4.0/_static/sponsors/{sponsor[\"img\"]}\" width=\"190\" /></a>')\n]]] -->\n<a href=\"https://www.variomedia.de/\"><img title=\"Variomedia AG\" src=\"https://www.attrs.org/en/25.4.0/_static/sponsors/Variomedia.svg\" width=\"190\" /></a>\n<a href=\"https://tidelift.com/?utm_source=lifter&utm_medium=referral&utm_campaign=hynek\"><img title=\"Tidelift\" src=\"https://www.attrs.org/en/25.4.0/_static/sponsors/Tidelift.svg\" width=\"190\" /></a>\n<a href=\"https://privacy-solutions.org/\"><img title=\"Privacy Solutions\" src=\"https://www.attrs.org/en/25.4.0/_static/sponsors/Privacy-Solutions.svg\" width=\"190\" /></a>\n<a href=\"https://filepreviews.io/\"><img title=\"FilePreviews\" src=\"https://www.attrs.org/en/25.4.0/_static/sponsors/FilePreviews.svg\" width=\"190\" /></a>\n<a href=\"https://polar.sh/\"><img title=\"Polar\" src=\"https://www.attrs.org/en/25.4.0/_static/sponsors/Polar.svg\" width=\"190\" /></a>\n<!-- [[[end]]] -->\n\n</p>\n\n<!-- sponsor-break-end -->\n\n<p align=\"center\">\n   <strong>Please consider <a href=\"https://github.com/sponsors/hynek\">joining them</a> to help make <em>attrs</em>â€™s maintenance more sustainable!</strong>\n</p>\n\n<!-- teaser-end -->\n\n## Example\n\n*attrs* gives you a class decorator and a way to declaratively define the attributes on that class:\n\n<!-- code-begin -->\n\n```pycon\n>>> from attrs import asdict, define, make_class, Factory\n\n>>> @define\n... class SomeClass:\n...     a_number: int = 42\n...     list_of_numbers: list[int] = Factory(list)\n...\n...     def hard_math(self, another_number):\n...         return self.a_number + sum(self.list_of_numbers) * another_number\n\n\n>>> sc = SomeClass(1, [1, 2, 3])\n>>> sc\nSomeClass(a_number=1, list_of_numbers=[1, 2, 3])\n\n>>> sc.hard_math(3)\n19\n>>> sc == SomeClass(1, [1, 2, 3])\nTrue\n>>> sc != SomeClass(2, [3, 2, 1])\nTrue\n\n>>> asdict(sc)\n{'a_number': 1, 'list_of_numbers': [1, 2, 3]}\n\n>>> SomeClass()\nSomeClass(a_number=42, list_of_numbers=[])\n\n>>> C = make_class(\"C\", [\"a\", \"b\"])\n>>> C(\"foo\", \"bar\")\nC(a='foo', b='bar')\n```\n\nAfter *declaring* your attributes, *attrs* gives you:\n\n- a concise and explicit overview of the class's attributes,\n- a nice human-readable `__repr__`,\n- equality-checking methods,\n- an initializer,\n- and much more,\n\n*without* writing dull boilerplate code again and again and *without* runtime performance penalties.\n\n---\n\nThis example uses *attrs*'s modern APIs that have been introduced in version 20.1.0, and the *attrs* package import name that has been added in version 21.3.0.\nThe classic APIs (`@attr.s`, `attr.ib`, plus their serious-business aliases) and the `attr` package import name will remain **indefinitely**.\n\nCheck out [*On The Core API Names*](https://www.attrs.org/en/latest/names.html) for an in-depth explanation!\n\n\n### Hate Type Annotations!?\n\nNo problem!\nTypes are entirely **optional** with *attrs*.\nSimply assign `attrs.field()` to the attributes instead of annotating them with types:\n\n```python\nfrom attrs import define, field\n\n@define\nclass SomeClass:\n    a_number = field(default=42)\n    list_of_numbers = field(factory=list)\n```\n\n\n## Data Classes\n\nOn the tin, *attrs* might remind you of `dataclasses` (and indeed, `dataclasses` [are a descendant](https://hynek.me/articles/import-attrs/) of *attrs*).\nIn practice it does a lot more and is more flexible.\nFor instance, it allows you to define [special handling of NumPy arrays for equality checks](https://www.attrs.org/en/stable/comparison.html#customization), allows more ways to [plug into the initialization process](https://www.attrs.org/en/stable/init.html#hooking-yourself-into-initialization), has a replacement for `__init_subclass__`, and allows for stepping through the generated methods using a debugger.\n\nFor more details, please refer to our [comparison page](https://www.attrs.org/en/stable/why.html#data-classes), but generally speaking, we are more likely to commit crimes against nature to make things work that one would expect to work, but that are quite complicated in practice.\n\n\n## Project Information\n\n- [**Changelog**](https://www.attrs.org/en/stable/changelog.html)\n- [**Documentation**](https://www.attrs.org/)\n- [**PyPI**](https://pypi.org/project/attrs/)\n- [**Source Code**](https://github.com/python-attrs/attrs)\n- [**Contributing**](https://github.com/python-attrs/attrs/blob/main/.github/CONTRIBUTING.md)\n- [**Third-party Extensions**](https://github.com/python-attrs/attrs/wiki/Extensions-to-attrs)\n- **Get Help**: use the `python-attrs` tag on [Stack Overflow](https://stackoverflow.com/questions/tagged/python-attrs)\n\n\n### *attrs* for Enterprise\n\nAvailable as part of the [Tidelift Subscription](https://tidelift.com/?utm_source=lifter&utm_medium=referral&utm_campaign=hynek).\n\nThe maintainers of *attrs* and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source packages you use to build your applications.\nSave time, reduce risk, and improve code health, while paying the maintainers of the exact packages you use.\n\n## Release Information\n\n### Backwards-incompatible Changes\n\n- Class-level `kw_only=True` behavior is now consistent with `dataclasses`.\n\n  Previously, a class that sets `kw_only=True` makes all attributes keyword-only, including those from base classes.\n  If an attribute sets `kw_only=False`, that setting is ignored, and it is still made keyword-only.\n\n  Now, only the attributes defined in that class that doesn't explicitly set `kw_only=False` are made keyword-only.\n\n  This shouldn't be a problem for most users, unless you have a pattern like this:\n\n  ```python\n  @attrs.define(kw_only=True)\n  class Base:\n      a: int\n      b: int = attrs.field(default=1, kw_only=False)\n\n  @attrs.define\n  class Subclass(Base):\n      c: int\n  ```\n\n  Here, we have a `kw_only=True` *attrs* class (`Base`) with an attribute that sets `kw_only=False` and has a default (`Base.b`), and then create a subclass (`Subclass`) with required arguments (`Subclass.c`).\n  Previously this would work, since it would make `Base.b` keyword-only, but now this fails since `Base.b` is positional, and we have a required positional argument (`Subclass.c`) following another argument with defaults.\n  [#1457](https://github.com/python-attrs/attrs/issues/1457)\n\n\n### Changes\n\n- Values passed to the `__init__()` method of `attrs` classes are now correctly passed to `__attrs_pre_init__()` instead of their default values (in cases where *kw_only* was not specified).\n  [#1427](https://github.com/python-attrs/attrs/issues/1427)\n- Added support for Python 3.14 and [PEP 749](https://peps.python.org/pep-0749/).\n  [#1446](https://github.com/python-attrs/attrs/issues/1446),\n  [#1451](https://github.com/python-attrs/attrs/issues/1451)\n- `attrs.validators.deep_mapping()` now allows to leave out either *key_validator* xor *value_validator*.\n  [#1448](https://github.com/python-attrs/attrs/issues/1448)\n- `attrs.validators.deep_iterator()` and `attrs.validators.deep_mapping()` now accept lists and tuples for all validators and wrap them into a `attrs.validators.and_()`.\n  [#1449](https://github.com/python-attrs/attrs/issues/1449)\n- Added a new **experimental** way to inspect classes:\n\n  `attrs.inspect(cls)` returns the _effective_ class-wide parameters that were used by *attrs* to construct the class.\n\n  The returned class is the same data structure that *attrs* uses internally to decide how to construct the final class.\n  [#1454](https://github.com/python-attrs/attrs/issues/1454)\n- Fixed annotations for `attrs.field(converter=...)`.\n  Previously, a `tuple` of converters was only accepted if it had exactly one element.\n  [#1461](https://github.com/python-attrs/attrs/issues/1461)\n- The performance of `attrs.asdict()` has been improved by 45â€“260%.\n  [#1463](https://github.com/python-attrs/attrs/issues/1463)\n- The performance of `attrs.astuple()` has been improved by 49â€“270%.\n  [#1469](https://github.com/python-attrs/attrs/issues/1469)\n- The type annotation for `attrs.validators.or_()` now allows for different types of validators.\n\n  This was only an issue on Pyright.\n  [#1474](https://github.com/python-attrs/attrs/issues/1474)\n\n\n\n---\n\n[Full changelog â†’](https://www.attrs.org/en/stable/changelog.html)\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "attribute",
          "boilerplate",
          "class"
        ],
        "author_email": "Hynek Schlawack <hs@ox.cx>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Typing :: Typed"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Documentation, https://www.attrs.org/",
          "Changelog, https://www.attrs.org/en/stable/changelog.html",
          "GitHub, https://github.com/python-attrs/attrs",
          "Funding, https://github.com/sponsors/hynek",
          "Tidelift, https://tidelift.com/subscription/pkg/pypi-attrs?utm_source=pypi-attrs&utm_medium=pypi"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/attrs-25.4.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "mashumaro",
        "version": "3.14",
        "platform": [
          "all"
        ],
        "summary": "Fast and well tested serialization library",
        "description": "<div align=\"center\">\n\n<img alt=\"logo\" width=\"175\" src=\"https://raw.githubusercontent.com/Fatal1ty/mashumaro/ac2f924591d488dbd9a776a6b1ae7dede2d8c73e/img/logo.svg\">\n\n###### Fast and well tested serialization library\n\n[![Build Status](https://github.com/Fatal1ty/mashumaro/workflows/tests/badge.svg)](https://github.com/Fatal1ty/mashumaro/actions)\n[![Coverage Status](https://coveralls.io/repos/github/Fatal1ty/mashumaro/badge.svg?branch=master)](https://coveralls.io/github/Fatal1ty/mashumaro?branch=master)\n[![Latest Version](https://img.shields.io/pypi/v/mashumaro.svg)](https://pypi.python.org/pypi/mashumaro)\n[![Python Version](https://img.shields.io/pypi/pyversions/mashumaro.svg)](https://pypi.python.org/pypi/mashumaro)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n</div>\n\nIn Python, you often need to dump and load objects based on the schema you\nhave. It can be a dataclass model, a list of third-party generic classes or\nwhatever. Mashumaro not only lets you save and load things in different ways,\nbut it also does it _super quick_.\n\n**Key features**\n* ðŸš€ One of the fastest libraries\n* â˜ï¸ Mature and time-tested\n* ðŸ‘¶ Easy to use out of the box\n* âš™ï¸ Highly customizable\n* ðŸŽ‰ Built-in support for JSON, YAML, TOML, MessagePack\n* ðŸ“¦ Built-in support for almost all Python types including typing-extensions\n* ðŸ“ JSON Schema generation\n\nTable of contents\n-------------------------------------------------------------------------------\n* [Table of contents](#table-of-contents)\n* [Introduction](#introduction)\n* [Installation](#installation)\n* [Changelog](#changelog)\n* [Supported data types](#supported-data-types)\n* [Usage example](#usage-example)\n* [How does it work?](#how-does-it-work)\n* [Benchmark](#benchmark)\n* [Supported serialization formats](#supported-serialization-formats)\n    * [Basic form](#basic-form)\n    * [JSON](#json)\n        * [json library](#json-library)\n        * [orjson library](#orjson-library)\n    * [YAML](#yaml)\n    * [TOML](#toml)\n    * [MessagePack](#messagepack)\n* [Customization](#customization)\n    * [SerializableType interface](#serializabletype-interface)\n        * [User-defined types](#user-defined-types)\n        * [User-defined generic types](#user-defined-generic-types)\n    * [SerializationStrategy](#serializationstrategy)\n        * [Third-party types](#third-party-types)\n        * [Third-party generic types](#third-party-generic-types)\n    * [Field options](#field-options)\n        * [`serialize` option](#serialize-option)\n        * [`deserialize` option](#deserialize-option)\n        * [`serialization_strategy` option](#serialization_strategy-option)\n        * [`alias` option](#alias-option)\n    * [Config options](#config-options)\n        * [`debug` config option](#debug-config-option)\n        * [`code_generation_options` config option](#code_generation_options-config-option)\n        * [`serialization_strategy` config option](#serialization_strategy-config-option)\n        * [`aliases` config option](#aliases-config-option)\n        * [`serialize_by_alias` config option](#serialize_by_alias-config-option)\n        * [`allow_deserialization_not_by_alias` config option](#allow_deserialization_not_by_alias-config-option)\n        * [`omit_none` config option](#omit_none-config-option)\n        * [`omit_default` config option](#omit_default-config-option)\n        * [`namedtuple_as_dict` config option](#namedtuple_as_dict-config-option)\n        * [`allow_postponed_evaluation` config option](#allow_postponed_evaluation-config-option)\n        * [`dialect` config option](#dialect-config-option)\n        * [`orjson_options` config option](#orjson_options-config-option)\n        * [`discriminator` config option](#discriminator-config-option)\n        * [`lazy_compilation` config option](#lazy_compilation-config-option)\n        * [`sort_keys` config option](#sort_keys-config-option)\n        * [`forbid_extra_keys` config option](#forbid_extra_keys-config-option)\n    * [Passing field values as is](#passing-field-values-as-is)\n    * [Extending existing types](#extending-existing-types)\n    * [Field aliases](#field-aliases)\n    * [Dialects](#dialects)\n        * [`serialization_strategy` dialect option](#serialization_strategy-dialect-option)\n        * [`serialize_by_alias` dialect option](#serialize_by_alias-dialect-option)\n        * [`omit_none` dialect option](#omit_none-dialect-option)\n        * [`omit_default` dialect option](#omit_default-dialect-option)\n        * [`namedtuple_as_dict` dialect option](#namedtuple_as_dict-dialect-option)\n        * [`no_copy_collections` dialect option](#no_copy_collections-dialect-option)\n        * [Changing the default dialect](#changing-the-default-dialect)\n    * [Discriminator](#discriminator)\n        * [Subclasses distinguishable by a field](#subclasses-distinguishable-by-a-field)\n        * [Subclasses without a common field](#subclasses-without-a-common-field)\n        * [Class level discriminator](#class-level-discriminator)\n        * [Working with union of classes](#working-with-union-of-classes)\n        * [Using a custom variant tagger function](#using-a-custom-variant-tagger-function)\n    * [Code generation options](#code-generation-options)\n        * [Add `omit_none` keyword argument](#add-omit_none-keyword-argument)\n        * [Add `by_alias` keyword argument](#add-by_alias-keyword-argument)\n        * [Add `dialect` keyword argument](#add-dialect-keyword-argument)\n        * [Add `context` keyword argument](#add-context-keyword-argument)\n    * [Generic dataclasses](#generic-dataclasses)\n        * [Generic dataclass inheritance](#generic-dataclass-inheritance)\n        * [Generic dataclass in a field type](#generic-dataclass-in-a-field-type)\n    * [GenericSerializableType interface](#genericserializabletype-interface)\n    * [Serialization hooks](#serialization-hooks)\n        * [Before deserialization](#before-deserialization)\n        * [After deserialization](#after-deserialization)\n        * [Before serialization](#before-serialization)\n        * [After serialization](#after-serialization)\n* [JSON Schema](#json-schema)\n    * [Building JSON Schema](#building-json-schema)\n    * [JSON Schema constraints](#json-schema-constraints)\n    * [Extending JSON Schema](#extending-json-schema)\n    * [JSON Schema and custom serialization methods](#json-schema-and-custom-serialization-methods)\n\nIntroduction\n-------------------------------------------------------------------------------\n\nThis library provides two fundamentally different approaches to converting\nyour data to and from various formats. Each of them is useful in different\nsituations:\n\n* Codecs\n* Mixins\n\nCodecs are represented by a set of decoder / encoder classes and\ndecode / encode functions for each supported format. You can use them\nto convert data of any python built-in and third-party type to JSON, YAML,\nTOML, MessagePack or a basic form accepted by other serialization formats.\nFor example, you can convert a list of datetime objects to JSON array\ncontaining string-represented datetimes and vice versa.\n\nMixins are primarily for dataclass models. They are represented by mixin\nclasses that add methods for converting to and from JSON, YAML, TOML,\nMessagePack or a basic form accepted by other serialization formats.\nIf you have a root dataclass model, then it will be the easiest way to make it\nserializable. All you have to do is inherit a particular mixin class.\n\nIn addition to serialization functionality, this library also provides JSON\nSchema builder that can be used in places where interoperability matters.\n\nInstallation\n-------------------------------------------------------------------------------\n\nUse pip to install:\n```shell\n$ pip install mashumaro\n```\n\nThe current version of `mashumaro` supports Python versions 3.8 â€” 3.13.\n\n\nIt's not recommended to use any version of Python that has reached its\n[end of life](https://devguide.python.org/versions/) and is no longer receiving\nsecurity updates or bug fixes from the Python development team.\nFor convenience, there is a table below that outlines the\nlast version of `mashumaro` that can be installed on unmaintained versions\nof Python.\n\n| Python Version | Last Version of mashumaro                                          | Python EOL |\n|----------------|--------------------------------------------------------------------|------------|\n| 3.7            | [3.9.1](https://github.com/Fatal1ty/mashumaro/releases/tag/v3.9.1) | 2023-06-27 |\n| 3.6            | [3.1.1](https://github.com/Fatal1ty/mashumaro/releases/tag/v3.1.1) | 2021-12-23 |\n\n\nChangelog\n-------------------------------------------------------------------------------\n\nThis project follows the principles of [Semantic Versioning](https://semver.org).\nChangelog is available on [GitHub Releases page](https://github.com/Fatal1ty/mashumaro/releases).\n\nSupported data types\n-------------------------------------------------------------------------------\n\nThere is support for generic types from the standard [`typing`](https://docs.python.org/3/library/typing.html) module:\n* [`List`](https://docs.python.org/3/library/typing.html#typing.List)\n* [`Tuple`](https://docs.python.org/3/library/typing.html#typing.Tuple)\n* [`NamedTuple`](https://docs.python.org/3/library/typing.html#typing.NamedTuple)\n* [`Set`](https://docs.python.org/3/library/typing.html#typing.Set)\n* [`FrozenSet`](https://docs.python.org/3/library/typing.html#typing.FrozenSet)\n* [`Deque`](https://docs.python.org/3/library/typing.html#typing.Deque)\n* [`Dict`](https://docs.python.org/3/library/typing.html#typing.Dict)\n* [`OrderedDict`](https://docs.python.org/3/library/typing.html#typing.OrderedDict)\n* [`DefaultDict`](https://docs.python.org/3/library/typing.html#typing.DefaultDict)\n* [`TypedDict`](https://docs.python.org/3/library/typing.html#typing.TypedDict)\n* [`Mapping`](https://docs.python.org/3/library/typing.html#typing.Mapping)\n* [`MutableMapping`](https://docs.python.org/3/library/typing.html#typing.MutableMapping)\n* [`Counter`](https://docs.python.org/3/library/typing.html#typing.Counter)\n* [`ChainMap`](https://docs.python.org/3/library/typing.html#typing.ChainMap)\n* [`Sequence`](https://docs.python.org/3/library/typing.html#typing.Sequence)\n\nfor standard generic types on [PEP 585](https://www.python.org/dev/peps/pep-0585/) compatible Python (3.9+):\n* [`list`](https://docs.python.org/3/library/stdtypes.html#list)\n* [`tuple`](https://docs.python.org/3/library/stdtypes.html#tuple)\n* [`namedtuple`](https://docs.python.org/3/library/collections.html#collections.namedtuple)\n* [`set`](https://docs.python.org/3/library/stdtypes.html#set)\n* [`frozenset`](https://docs.python.org/3/library/stdtypes.html#frozenset)\n* [`collections.abc.Set`](https://docs.python.org/3/library/collections.abc.html#collections.abc.Set)\n* [`collections.abc.MutableSet`](https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableSet)\n* [`collections.deque`](https://docs.python.org/3/library/collections.html#collections.deque)\n* [`dict`](https://docs.python.org/3/library/stdtypes.html#dict)\n* [`collections.OrderedDict`](https://docs.python.org/3/library/collections.html#collections.OrderedDict)\n* [`collections.defaultdict`](https://docs.python.org/3/library/collections.html#collections.defaultdict)\n* [`collections.abc.Mapping`](https://docs.python.org/3/library/collections.abc.html#collections.abc.Mapping)\n* [`collections.abc.MutableMapping`](https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping)\n* [`collections.Counter`](https://docs.python.org/3/library/collections.html#collections.Counter)\n* [`collections.ChainMap`](https://docs.python.org/3/library/collections.html#collections.ChainMap)\n* [`collections.abc.Sequence`](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence)\n* [`collections.abc.MutableSequence`](https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableSequence)\n\nfor special primitives from the [`typing`](https://docs.python.org/3/library/typing.html) module:\n* [`Any`](https://docs.python.org/3/library/typing.html#typing.Any)\n* [`Optional`](https://docs.python.org/3/library/typing.html#typing.Optional)\n* [`Union`](https://docs.python.org/3/library/typing.html#typing.Union)\n* [`TypeVar`](https://docs.python.org/3/library/typing.html#typing.TypeVar)\n* [`TypeVarTuple`](https://docs.python.org/3/library/typing.html#typing.TypeVarTuple)\n* [`NewType`](https://docs.python.org/3/library/typing.html#newtype)\n* [`Annotated`](https://docs.python.org/3/library/typing.html#typing.Annotated)\n* [`Literal`](https://docs.python.org/3/library/typing.html#typing.Literal)\n* [`LiteralString`](https://docs.python.org/3/library/typing.html#typing.LiteralString)\n* [`Final`](https://docs.python.org/3/library/typing.html#typing.Final)\n* [`Self`](https://docs.python.org/3/library/typing.html#typing.Self)\n* [`Unpack`](https://docs.python.org/3/library/typing.html#typing.Unpack)\n\nfor standard interpreter types from [`types`](https://docs.python.org/3/library/types.html#standard-interpreter-types) module:\n* [`NoneType`](https://docs.python.org/3/library/types.html#types.NoneType)\n* [`UnionType`](https://docs.python.org/3/library/types.html#types.UnionType)\n* [`MappingProxyType`](https://docs.python.org/3/library/types.html#types.MappingProxyType)\n\nfor enumerations based on classes from the standard [`enum`](https://docs.python.org/3/library/enum.html) module:\n* [`Enum`](https://docs.python.org/3/library/enum.html#enum.Enum)\n* [`IntEnum`](https://docs.python.org/3/library/enum.html#enum.IntEnum)\n* [`StrEnum`](https://docs.python.org/3/library/enum.html#enum.StrEnum)\n* [`Flag`](https://docs.python.org/3/library/enum.html#enum.Flag)\n* [`IntFlag`](https://docs.python.org/3/library/enum.html#enum.IntFlag)\n\nfor common built-in types:\n* [`int`](https://docs.python.org/3/library/functions.html#int)\n* [`float`](https://docs.python.org/3/library/functions.html#float)\n* [`bool`](https://docs.python.org/3/library/stdtypes.html#bltin-boolean-values)\n* [`str`](https://docs.python.org/3/library/stdtypes.html#str)\n* [`bytes`](https://docs.python.org/3/library/stdtypes.html#bytes)\n* [`bytearray`](https://docs.python.org/3/library/stdtypes.html#bytearray)\n\nfor built-in datetime oriented types (see [more](#deserialize-option) details):\n* [`datetime`](https://docs.python.org/3/library/datetime.html#datetime.datetime)\n* [`date`](https://docs.python.org/3/library/datetime.html#datetime.date)\n* [`time`](https://docs.python.org/3/library/datetime.html#datetime.time)\n* [`timedelta`](https://docs.python.org/3/library/datetime.html#datetime.timedelta)\n* [`timezone`](https://docs.python.org/3/library/datetime.html#datetime.timezone)\n* [`ZoneInfo`](https://docs.python.org/3/library/zoneinfo.html#zoneinfo.ZoneInfo)\n\nfor pathlike types:\n* [`PurePath`](https://docs.python.org/3/library/pathlib.html#pathlib.PurePath)\n* [`Path`](https://docs.python.org/3/library/pathlib.html#pathlib.Path)\n* [`PurePosixPath`](https://docs.python.org/3/library/pathlib.html#pathlib.PurePosixPath)\n* [`PosixPath`](https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath)\n* [`PureWindowsPath`](https://docs.python.org/3/library/pathlib.html#pathlib.PureWindowsPath)\n* [`WindowsPath`](https://docs.python.org/3/library/pathlib.html#pathlib.WindowsPath)\n* [`os.PathLike`](https://docs.python.org/3/library/os.html#os.PathLike)\n\nfor other less popular built-in types:\n* [`uuid.UUID`](https://docs.python.org/3/library/uuid.html#uuid.UUID)\n* [`decimal.Decimal`](https://docs.python.org/3/library/decimal.html#decimal.Decimal)\n* [`fractions.Fraction`](https://docs.python.org/3/library/fractions.html#fractions.Fraction)\n* [`ipaddress.IPv4Address`](https://docs.python.org/3/library/ipaddress.html#ipaddress.IPv4Address)\n* [`ipaddress.IPv6Address`](https://docs.python.org/3/library/ipaddress.html#ipaddress.IPv6Address)\n* [`ipaddress.IPv4Network`](https://docs.python.org/3/library/ipaddress.html#ipaddress.IPv4Network)\n* [`ipaddress.IPv6Network`](https://docs.python.org/3/library/ipaddress.html#ipaddress.IPv6Network)\n* [`ipaddress.IPv4Interface`](https://docs.python.org/3/library/ipaddress.html#ipaddress.IPv4Interface)\n* [`ipaddress.IPv6Interface`](https://docs.python.org/3/library/ipaddress.html#ipaddress.IPv6Interface)\n* [`typing.Pattern`](https://docs.python.org/3/library/typing.html#typing.Pattern)\n* [`re.Pattern`](https://docs.python.org/3/library/re.html#re.Pattern)\n\nfor backported types from [`typing-extensions`](https://github.com/python/typing_extensions):\n* [`OrderedDict`](https://docs.python.org/3/library/typing.html#typing.OrderedDict)\n* [`TypedDict`](https://docs.python.org/3/library/typing.html#typing.TypedDict)\n* [`Annotated`](https://docs.python.org/3/library/typing.html#typing.Annotated)\n* [`Literal`](https://docs.python.org/3/library/typing.html#typing.Literal)\n* [`LiteralString`](https://docs.python.org/3/library/typing.html#typing.LiteralString)\n* [`Self`](https://docs.python.org/3/library/typing.html#typing.Self)\n* [`TypeVarTuple`](https://docs.python.org/3/library/typing.html#typing.TypeVarTuple)\n* [`Unpack`](https://docs.python.org/3/library/typing.html#typing.Unpack)\n\nfor arbitrary types:\n* [user-defined types](#user-defined-types)\n* [third-party types](#third-party-types)\n* [user-defined generic types](#user-defined-generic-types)\n* [third-party generic types](#third-party-generic-types)\n\nUsage example\n-------------------------------------------------------------------------------\n\nSuppose we're developing a financial application and we operate with currencies\nand stocks:\n\n```python\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nclass Currency(Enum):\n    USD = \"USD\"\n    EUR = \"EUR\"\n\n@dataclass\nclass CurrencyPosition:\n    currency: Currency\n    balance: float\n\n@dataclass\nclass StockPosition:\n    ticker: str\n    name: str\n    balance: int\n```\n\nNow we want a dataclass for portfolio that will be serialized to and from JSON.\nWe inherit `DataClassJSONMixin` that adds this functionality:\n\n```python\nfrom mashumaro.mixins.json import DataClassJSONMixin\n\n...\n\n@dataclass\nclass Portfolio(DataClassJSONMixin):\n    currencies: list[CurrencyPosition]\n    stocks: list[StockPosition]\n```\n\nLet's create a portfolio instance and check methods `from_json` and `to_json`:\n\n```python\nportfolio = Portfolio(\n    currencies=[\n        CurrencyPosition(Currency.USD, 238.67),\n        CurrencyPosition(Currency.EUR, 361.84),\n    ],\n    stocks=[\n        StockPosition(\"AAPL\", \"Apple\", 10),\n        StockPosition(\"AMZN\", \"Amazon\", 10),\n    ]\n)\n\nportfolio_json = portfolio.to_json()\nassert Portfolio.from_json(portfolio_json) == portfolio\n```\n\nIf we need to serialize something different from a root dataclass,\nwe can use codecs. In the following example we create a JSON decoder and encoder\nfor a list of currencies:\n\n```python\nfrom mashumaro.codecs.json import JSONDecoder, JSONEncoder\n\n...\n\ndecoder = JSONDecoder(list[CurrencyPosition])\nencoder = JSONEncoder(list[CurrencyPosition])\n\ncurrencies = [\n    CurrencyPosition(Currency.USD, 238.67),\n    CurrencyPosition(Currency.EUR, 361.84),\n]\ncurrencies_json = encoder.encode(currencies)\nassert decoder.decode(currencies_json) == currencies\n\n```\n\nHow does it work?\n-------------------------------------------------------------------------------\n\nThis library works by taking the schema of the data and generating a\nspecific decoder and encoder for exactly that schema, taking into account the\nspecifics of serialization format. This is much faster than inspection of\ndata types on every call of decoding or encoding at runtime.\n\nThese specific decoders and encoders are generated by\n[codecs and mixins](#supported-serialization-formats):\n* When using codecs, these methods are compiled during the creation of the\n  decoder or encoder.\n* When using serialization\nmixins, these methods are compiled during import time (or at runtime in some\ncases) and are set as attributes to your dataclasses. To minimize the import\ntime, you can explicitly enable\n[lazy compilation](#lazy_compilation-config-option).\n\nBenchmark\n-------------------------------------------------------------------------------\n\n* macOS 14.0 Sonoma\n* Apple M1\n* 16GB RAM\n* Python 3.12.0\n\nBenchmark using [pyperf](https://github.com/psf/pyperf) with GitHub Issue model. Please note that the\nfollowing charts use logarithmic scale, as it is convenient for displaying\nvery large ranges of values.\n\n<picture>\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/Fatal1ty/mashumaro/d5f98a2bea64b8ed57c07db408beee5709969c4c/benchmark/charts/load_light.svg\">\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/Fatal1ty/mashumaro/d5f98a2bea64b8ed57c07db408beee5709969c4c/benchmark/charts/load_dark.svg\">\n  <img src=\"https://raw.githubusercontent.com/Fatal1ty/mashumaro/d5f98a2bea64b8ed57c07db408beee5709969c4c/benchmark/charts/load_light.svg\" width=\"604\">\n</picture>\n<picture>\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/Fatal1ty/mashumaro/d5f98a2bea64b8ed57c07db408beee5709969c4c/benchmark/charts/dump_light.svg\">\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/Fatal1ty/mashumaro/d5f98a2bea64b8ed57c07db408beee5709969c4c/benchmark/charts/dump_dark.svg\">\n  <img src=\"https://raw.githubusercontent.com/Fatal1ty/mashumaro/d5f98a2bea64b8ed57c07db408beee5709969c4c/benchmark/charts/dump_light.svg\" width=\"604\">\n</picture>\n\n> [!NOTE]\\\n> Benchmark results may vary depending on the specific configuration and\n> parameters used for serialization and deserialization. However, we have made\n> an attempt to use the available options that can speed up and smooth out the\n> differences in how libraries work.\n\nTo run benchmark in your environment:\n```bash\ngit clone git@github.com:Fatal1ty/mashumaro.git\ncd mashumaro\npython3 -m venv env && source env/bin/activate\npip install -e .\npip install -r requirements-dev.txt\n./benchmark/run.sh\n```\n\nSupported serialization formats\n-------------------------------------------------------------------------------\n\nThis library has built-in support for multiple popular formats:\n\n* [JSON](https://www.json.org)\n* [YAML](https://yaml.org)\n* [TOML](https://toml.io)\n* [MessagePack](https://msgpack.org)\n\nThere are preconfigured codecs and mixin classes. However, you're free\nto override some settings if necessary.\n\n> [!IMPORTANT]\\\n> As for codecs, you are\n> offered to choose between convenience and efficiency. When you need to decode\n> or encode typed data more than once, it's highly recommended to create\n> and reuse a decoder or encoder specifically for that data type. For one-time\n> use with default settings it may be convenient to use global functions that\n> create a disposable decoder or encoder under the hood. Remember that you\n> should not use these convenient global functions more that once for the same\n> data type if performance is important to you.\n\n### Basic form\n\nBasic form denotes a python object consisting only of basic data types\nsupported by most serialization formats. These types are:\n[`str`](https://docs.python.org/3/library/stdtypes.html#str),\n[`int`](https://docs.python.org/3/library/functions.html#int),\n[`float`](https://docs.python.org/3/library/functions.html#float),\n[`bool`](https://docs.python.org/3/library/stdtypes.html#bltin-boolean-values),\n[`list`](https://docs.python.org/3/library/stdtypes.html#list),\n[`dict`](https://docs.python.org/3/library/stdtypes.html#dict).\n\nThis is also a starting point you can play with for a comprehensive\ntransformation of your data.\n\nEfficient decoder and encoder can be used as follows:\n\n```python\nfrom mashumaro.codecs import BasicDecoder, BasicEncoder\n# or from mashumaro.codecs.basic import BasicDecoder, BasicEncoder\n\ndecoder = BasicDecoder(<shape_type>, ...)\ndecoder.decode(...)\n\nencoder = BasicEncoder(<shape_type>, ...)\nencoder.encode(...)\n```\n\nConvenient functions are recommended to be used as follows:\n```python\nimport mashumaro.codecs.basic as basic_codec\n\nbasic_codec.decode(..., <shape_type>)\nbasic_codec.encode(..., <shape_type>)\n```\n\nMixin can be used as follows:\n```python\nfrom mashumaro import DataClassDictMixin\n# or from mashumaro.mixins.dict import DataClassDictMixin\n\n@dataclass\nclass MyModel(DataClassDictMixin):\n    ...\n\nMyModel.from_dict(...)\nMyModel(...).to_dict()\n```\n\n> [!TIP]\\\n> You don't need to inherit `DataClassDictMixin` along with other serialization\n> mixins because it's a base class for them.\n\n### JSON\n\n[JSON](https://www.json.org) is a lightweight data-interchange format. You can\nchoose between standard library\n[json](https://docs.python.org/3/library/json.html) for compatibility and\nthird-party dependency [orjson](https://pypi.org/project/orjson/) for better\nperformance.\n\n#### json library\n\nEfficient decoder and encoder can be used as follows:\n```python\nfrom mashumaro.codecs.json import JSONDecoder, JSONEncoder\n\ndecoder = JSONDecoder(<shape_type>, ...)\ndecoder.decode(...)\n\nencoder = JSONEncoder(<shape_type>, ...)\nencoder.encode(...)\n```\n\nConvenient functions can be used as follows:\n```python\nfrom mashumaro.codecs.json import json_decode, json_encode\n\njson_decode(..., <shape_type>)\njson_encode(..., <shape_type>)\n```\n\nConvenient function aliases are recommended to be used as follows:\n```python\nimport mashumaro.codecs.json as json_codec\n\njson_codec.decode(...<shape_type>)\njson_codec.encode(..., <shape_type>)\n```\n\nMixin can be used as follows:\n```python\nfrom mashumaro.mixins.json import DataClassJSONMixin\n\n@dataclass\nclass MyModel(DataClassJSONMixin):\n    ...\n\nMyModel.from_json(...)\nMyModel(...).to_json()\n```\n\n#### orjson library\n\nIn order to use [`orjson`](https://pypi.org/project/orjson/) library, it must\nbe installed manually or using an extra option for `mashumaro`:\n\n```shell\npip install mashumaro[orjson]\n```\n\nThe following data types will be handled by\n[`orjson`](https://pypi.org/project/orjson/) library by default:\n* [`datetime`](https://docs.python.org/3/library/datetime.html#datetime.datetime)\n* [`date`](https://docs.python.org/3/library/datetime.html#datetime.date)\n* [`time`](https://docs.python.org/3/library/datetime.html#datetime.time)\n* [`uuid.UUID`](https://docs.python.org/3/library/uuid.html#uuid.UUID)\n\nEfficient decoder and encoder can be used as follows:\n```python\nfrom mashumaro.codecs.orjson import ORJSONDecoder, ORJSONEncoder\n\ndecoder = ORJSONDecoder(<shape_type>, ...)\ndecoder.decode(...)\n\nencoder = ORJSONEncoder(<shape_type>, ...)\nencoder.encode(...)\n```\n\nConvenient functions can be used as follows:\n```python\nfrom mashumaro.codecs.orjson import json_decode, json_encode\n\njson_decode(..., <shape_type>)\njson_encode(..., <shape_type>)\n```\n\nConvenient function aliases are recommended to be used as follows:\n```python\nimport mashumaro.codecs.orjson as json_codec\n\njson_codec.decode(...<shape_type>)\njson_codec.encode(..., <shape_type>)\n```\n\nMixin can be used as follows:\n```python\nfrom mashumaro.mixins.orjson import DataClassORJSONMixin\n\n@dataclass\nclass MyModel(DataClassORJSONMixin):\n    ...\n\nMyModel.from_json(...)\nMyModel(...).to_json()\nMyModel(...).to_jsonb()\n```\n\n### YAML\n\n[YAML](https://yaml.org) is a human-friendly data serialization language for\nall programming languages. In order to use this format, the\n[`pyyaml`](https://pypi.org/project/PyYAML/) package must be installed.\nYou can install it manually or using an extra option for `mashumaro`:\n\n```shell\npip install mashumaro[yaml]\n```\n\nEfficient decoder and encoder can be used as follows:\n```python\nfrom mashumaro.codecs.yaml import YAMLDecoder, YAMLEncoder\n\ndecoder = YAMLDecoder(<shape_type>, ...)\ndecoder.decode(...)\n\nencoder = YAMLEncoder(<shape_type>, ...)\nencoder.encode(...)\n```\n\nConvenient functions can be used as follows:\n```python\nfrom mashumaro.codecs.yaml import yaml_decode, yaml_encode\n\nyaml_decode(..., <shape_type>)\nyaml_encode(..., <shape_type>)\n```\n\nConvenient function aliases are recommended to be used as follows:\n```python\nimport mashumaro.codecs.yaml as yaml_codec\n\nyaml_codec.decode(...<shape_type>)\nyaml_codec.encode(..., <shape_type>)\n```\n\nMixin can be used as follows:\n```python\nfrom mashumaro.mixins.yaml import DataClassYAMLMixin\n\n@dataclass\nclass MyModel(DataClassYAMLMixin):\n    ...\n\nMyModel.from_yaml(...)\nMyModel(...).to_yaml()\n```\n\n### TOML\n\n[TOML](https://toml.io) is config file format for humans.\nIn order to use this format, the [`tomli`](https://pypi.org/project/tomli/) and\n[`tomli-w`](https://pypi.org/project/tomli-w/) packages must be installed.\nIn Python 3.11+, `tomli` is included as\n[`tomlib`](https://docs.python.org/3/library/tomllib.html) standard library\nmodule and is used for this format. You can install the missing packages\nmanually or using an extra option\nfor `mashumaro`:\n\n```shell\npip install mashumaro[toml]\n```\n\nThe following data types will be handled by\n[`tomli`](https://pypi.org/project/tomli/)/\n[`tomli-w`](https://pypi.org/project/tomli-w/) library by default:\n* [`datetime`](https://docs.python.org/3/library/datetime.html#datetime.datetime)\n* [`date`](https://docs.python.org/3/library/datetime.html#datetime.date)\n* [`time`](https://docs.python.org/3/library/datetime.html#datetime.time)\n\nFields with value `None` will be omitted on serialization because TOML\ndoesn't support null values.\n\nEfficient decoder and encoder can be used as follows:\n```python\nfrom mashumaro.codecs.toml import TOMLDecoder, TOMLEncoder\n\ndecoder = TOMLDecoder(<shape_type>, ...)\ndecoder.decode(...)\n\nencoder = TOMLEncoder(<shape_type>, ...)\nencoder.encode(...)\n```\n\nConvenient functions can be used as follows:\n```python\nfrom mashumaro.codecs.toml import toml_decode, toml_encode\n\ntoml_decode(..., <shape_type>)\ntoml_encode(..., <shape_type>)\n```\n\nConvenient function aliases are recommended to be used as follows:\n```python\nimport mashumaro.codecs.toml as toml_codec\n\ntoml_codec.decode(...<shape_type>)\ntoml_codec.encode(..., <shape_type>)\n```\n\nMixin can be used as follows:\n```python\nfrom mashumaro.mixins.toml import DataClassTOMLMixin\n\n@dataclass\nclass MyModel(DataClassTOMLMixin):\n    ...\n\nMyModel.from_toml(...)\nMyModel(...).to_toml()\n```\n\n### MessagePack\n\n[MessagePack](https://msgpack.org) is an efficient binary serialization format.\nIn order to use this mixin, the [`msgpack`](https://pypi.org/project/msgpack/)\npackage must be installed. You can install it manually or using an extra\noption for `mashumaro`:\n\n```shell\npip install mashumaro[msgpack]\n```\n\nThe following data types will be handled by\n[`msgpack`](https://pypi.org/project/msgpack/) library by default:\n* [`bytes`](https://docs.python.org/3/library/stdtypes.html#bytes)\n* [`bytearray`](https://docs.python.org/3/library/stdtypes.html#bytearray)\n\nEfficient decoder and encoder can be used as follows:\n```python\nfrom mashumaro.codecs.msgpack import MessagePackDecoder, MessagePackEncoder\n\ndecoder = MessagePackDecoder(<shape_type>, ...)\ndecoder.decode(...)\n\nencoder = MessagePackEncoder(<shape_type>, ...)\nencoder.encode(...)\n```\n\nConvenient functions can be used as follows:\n```python\nfrom mashumaro.codecs.msgpack import msgpack_decode, msgpack_encode\n\nmsgpack_decode(..., <shape_type>)\nmsgpack_encode(..., <shape_type>)\n```\n\nConvenient function aliases are recommended to be used as follows:\n```python\nimport mashumaro.codecs.msgpack as msgpack_codec\n\nmsgpack_codec.decode(...<shape_type>)\nmsgpack_codec.encode(..., <shape_type>)\n```\n\nMixin can be used as follows:\n```python\nfrom mashumaro.mixins.msgpack import DataClassMessagePackMixin\n\n@dataclass\nclass MyModel(DataClassMessagePackMixin):\n    ...\n\nMyModel.from_msgpack(...)\nMyModel(...).to_msgpack()\n```\n\nCustomization\n-------------------------------------------------------------------------------\n\nCustomization options of `mashumaro` are extensive and will most likely cover your needs.\nWhen it comes to non-standard data types and non-standard serialization support, you can do the following:\n* Turn an existing regular or generic class into a serializable one\nby inheriting the [`SerializableType`](#serializabletype-interface) class\n* Write different serialization strategies for an existing regular or generic type that is not under your control\nusing [`SerializationStrategy`](#serializationstrategy) class\n* Define serialization / deserialization methods:\n  * for a specific dataclass field by using [field options](#field-options)\n  * for a specific data type used in the dataclass by using [`Config`](#config-options) class\n* Alter input and output data with serialization / deserialization [hooks](#serialization-hooks)\n* Separate serialization scheme from a dataclass in a reusable manner using [dialects](#dialects)\n* Choose from predefined serialization engines for the specific data types, e.g. `datetime` and `NamedTuple`\n\n### SerializableType interface\n\nIf you have a custom class or hierarchy of classes whose instances you want\nto serialize with `mashumaro`, the first option is to implement\n`SerializableType` interface.\n\n#### User-defined types\n\nLet's look at this not very practicable example:\n\n```python\nfrom dataclasses import dataclass\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.types import SerializableType\n\nclass Airport(SerializableType):\n    def __init__(self, code, city):\n        self.code, self.city = code, city\n\n    def _serialize(self):\n        return [self.code, self.city]\n\n    @classmethod\n    def _deserialize(cls, value):\n        return cls(*value)\n\n    def __eq__(self, other):\n        return self.code, self.city == other.code, other.city\n\n@dataclass\nclass Flight(DataClassDictMixin):\n    origin: Airport\n    destination: Airport\n\nJFK = Airport(\"JFK\", \"New York City\")\nLAX = Airport(\"LAX\", \"Los Angeles\")\n\ninput_data = {\n    \"origin\": [\"JFK\", \"New York City\"],\n    \"destination\": [\"LAX\", \"Los Angeles\"]\n}\nmy_flight = Flight.from_dict(input_data)\nassert my_flight == Flight(JFK, LAX)\nassert my_flight.to_dict() == input_data\n```\n\nYou can see how `Airport` instances are seamlessly created from lists of two\nstrings and serialized into them.\n\nBy default `_deserialize` method will get raw input data without any\ntransformations before. This should be enough in many cases, especially when\nyou need to perform non-standard transformations yourself, but let's extend\nour example:\n\n```python\nclass Itinerary(SerializableType):\n    def __init__(self, flights):\n        self.flights = flights\n\n    def _serialize(self):\n        return self.flights\n\n    @classmethod\n    def _deserialize(cls, flights):\n        return cls(flights)\n\n@dataclass\nclass TravelPlan(DataClassDictMixin):\n    budget: float\n    itinerary: Itinerary\n\ninput_data = {\n    \"budget\": 10_000,\n    \"itinerary\": [\n        {\n            \"origin\": [\"JFK\", \"New York City\"],\n            \"destination\": [\"LAX\", \"Los Angeles\"]\n        },\n        {\n            \"origin\": [\"LAX\", \"Los Angeles\"],\n            \"destination\": [\"SFO\", \"San Fransisco\"]\n        }\n    ]\n}\n```\n\nIf we pass the flight list as is into `Itinerary._deserialize`, our itinerary\nwill have something that we may not expect â€” `list[dict]` instead of\n`list[Flight]`. The solution is quite simple. Instead of calling\n`Flight._deserialize` yourself, just use annotations:\n\n```python\nclass Itinerary(SerializableType, use_annotations=True):\n    def __init__(self, flights):\n        self.flights = flights\n\n    def _serialize(self) -> list[Flight]:\n        return self.flights\n\n    @classmethod\n    def _deserialize(cls, flights: list[Flight]):\n        return cls(flights)\n\nmy_plan = TravelPlan.from_dict(input_data)\nassert isinstance(my_plan.itinerary.flights[0], Flight)\nassert isinstance(my_plan.itinerary.flights[1], Flight)\nassert my_plan.to_dict() == input_data\n```\n\nHere we add annotations to the only argument of `_deserialize` method and\nto the return value of `_serialize` method as well. The latter is needed for\ncorrect serialization.\n\n> [!IMPORTANT]\\\n> The importance of explicit passing `use_annotations=True` when defining a\n> class is that otherwise implicit using annotations might break compatibility\n> with old code that wasn't aware of this feature. It will be enabled by\n> default in the future major release.\n\n#### User-defined generic types\n\nThe great thing to note about using annotations in `SerializableType` is that\nthey work seamlessly with [generic](https://docs.python.org/3/library/typing.html#user-defined-generic-types)\nand [variadic generic](https://peps.python.org/pep-0646/) types.\nLet's see how this can be useful:\n\n```python\nfrom datetime import date\nfrom typing import TypeVar\nfrom dataclasses import dataclass\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.types import SerializableType\n\nKT = TypeVar(\"KT\")\nVT = TypeVar(\"VT\")\n\nclass DictWrapper(dict[KT, VT], SerializableType, use_annotations=True):\n    def _serialize(self) -> dict[KT, VT]:\n        return dict(self)\n\n    @classmethod\n    def _deserialize(cls, value: dict[KT, VT]) -> 'DictWrapper[KT, VT]':\n        return cls(value)\n\n@dataclass\nclass DataClass(DataClassDictMixin):\n    x: DictWrapper[date, str]\n    y: DictWrapper[str, date]\n\ninput_data = {\n    \"x\": {\"2022-12-07\": \"2022-12-07\"},\n    \"y\": {\"2022-12-07\": \"2022-12-07\"}\n}\nobj = DataClass.from_dict(input_data)\nassert obj == DataClass(\n    x=DictWrapper({date(2022, 12, 7): \"2022-12-07\"}),\n    y=DictWrapper({\"2022-12-07\": date(2022, 12, 7)})\n)\nassert obj.to_dict() == input_data\n```\n\nYou can see that formatted date is deserialized to `date` object before passing\nto `DictWrapper._deserialize` in a key or value according to the generic\nparameters.\n\nIf you have generic dataclass types, you can use `SerializableType` for them as well, but it's not necessary since\nthey're [supported](#generic-dataclasses) out of the box.\n\n### SerializationStrategy\n\nIf you want to add support for a custom third-party type that is not under your control,\nyou can write serialization and deserialization logic inside `SerializationStrategy` class,\nwhich will be reusable and so well suited in case that third-party type is widely used.\n`SerializationStrategy` is also good if you want to create strategies that are slightly different from each other,\nbecause you can add the strategy differentiator in the `__init__` method.\n\n#### Third-party types\n\nTo demonstrate how `SerializationStrategy` works let's write a simple strategy for datetime serialization\nin different formats. In this example we will use the same strategy class for two dataclass fields,\nbut a string representing the date and time will be different.\n\n```python\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom mashumaro import DataClassDictMixin, field_options\nfrom mashumaro.types import SerializationStrategy\n\nclass FormattedDateTime(SerializationStrategy):\n    def __init__(self, fmt):\n        self.fmt = fmt\n\n    def serialize(self, value: datetime) -> str:\n        return value.strftime(self.fmt)\n\n    def deserialize(self, value: str) -> datetime:\n        return datetime.strptime(value, self.fmt)\n\n@dataclass\nclass DateTimeFormats(DataClassDictMixin):\n    short: datetime = field(\n        metadata=field_options(\n            serialization_strategy=FormattedDateTime(\"%d%m%Y%H%M%S\")\n        )\n    )\n    verbose: datetime = field(\n        metadata=field_options(\n            serialization_strategy=FormattedDateTime(\"%A %B %d, %Y, %H:%M:%S\")\n        )\n    )\n\nformats = DateTimeFormats(\n    short=datetime(2019, 1, 1, 12),\n    verbose=datetime(2019, 1, 1, 12),\n)\ndictionary = formats.to_dict()\n# {'short': '01012019120000', 'verbose': 'Tuesday January 01, 2019, 12:00:00'}\nassert DateTimeFormats.from_dict(dictionary) == formats\n```\n\nSimilarly to `SerializableType`, `SerializationStrategy` could also take advantage of annotations:\n\n```python\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.types import SerializationStrategy\n\nclass TsSerializationStrategy(SerializationStrategy, use_annotations=True):\n    def serialize(self, value: datetime) -> float:\n        return value.timestamp()\n\n    def deserialize(self, value: float) -> datetime:\n        # value will be converted to float before being passed to this method\n        return datetime.fromtimestamp(value)\n\n@dataclass\nclass Example(DataClassDictMixin):\n    dt: datetime\n\n    class Config:\n        serialization_strategy = {\n            datetime: TsSerializationStrategy(),\n        }\n\nexample = Example.from_dict({\"dt\": \"1672531200\"})\nprint(example)\n# Example(dt=datetime.datetime(2023, 1, 1, 3, 0))\nprint(example.to_dict())\n# {'dt': 1672531200.0}\n```\n\nHere the passed string value `\"1672531200\"` will be converted to `float` before being passed to `deserialize` method\nthanks to the `float` annotation.\n\n> [!IMPORTANT]\\\n> As well as for `SerializableType`, the value of `use_annotatons` will be\n> `True` by default in the future major release.\n\n#### Third-party generic types\n\nTo create a generic version of a serialization strategy you need to follow these steps:\n* inherit [`Generic[...]`](https://docs.python.org/3/library/typing.html#typing.Generic) type\nwith the number of parameters matching the number of parameters\nof the target generic type\n* Write generic annotations for `serialize` method's return type and for `deserialize` method's argument type\n* Use the origin type of the target generic type in the [`serialization_strategy`](#serialization_strategy-config-option) config section\n([`typing.get_origin`](https://docs.python.org/3/library/typing.html#typing.get_origin) might be helpful)\n\nThere is no need to add `use_annotations=True` here because it's enabled implicitly\nfor generic serialization strategies.\n\nFor example, there is a third-party [multidict](https://pypi.org/project/multidict/) package that has a generic `MultiDict` type.\nA generic serialization strategy for it might look like this:\n\n```python\nfrom dataclasses import dataclass\nfrom datetime import date\nfrom pprint import pprint\nfrom typing import Generic, List, Tuple, TypeVar\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.types import SerializationStrategy\n\nfrom multidict import MultiDict\n\nT = TypeVar(\"T\")\n\nclass MultiDictSerializationStrategy(SerializationStrategy, Generic[T]):\n    def serialize(self, value: MultiDict[T]) -> List[Tuple[str, T]]:\n        return [(k, v) for k, v in value.items()]\n\n    def deserialize(self, value: List[Tuple[str, T]]) -> MultiDict[T]:\n        return MultiDict(value)\n\n\n@dataclass\nclass Example(DataClassDictMixin):\n    floats: MultiDict[float]\n    date_lists: MultiDict[List[date]]\n\n    class Config:\n        serialization_strategy = {\n            MultiDict: MultiDictSerializationStrategy()\n        }\n\nexample = Example(\n    floats=MultiDict([(\"x\", 1.1), (\"x\", 2.2)]),\n    date_lists=MultiDict(\n        [(\"x\", [date(2023, 1, 1), date(2023, 1, 2)]),\n         (\"x\", [date(2023, 2, 1), date(2023, 2, 2)])]\n    ),\n)\npprint(example.to_dict())\n# {'date_lists': [['x', ['2023-01-01', '2023-01-02']],\n#                 ['x', ['2023-02-01', '2023-02-02']]],\n#  'floats': [['x', 1.1], ['x', 2.2]]}\nassert Example.from_dict(example.to_dict()) == example\n```\n\n### Field options\n\nIn some cases creating a new class just for one little thing could be\nexcessive. Moreover, you may need to deal with third party classes that you are\nnot allowed to change. You can use [`dataclasses.field`](https://docs.python.org/3/library/dataclasses.html#dataclasses.field) function to\nconfigure some serialization aspects through its `metadata` parameter. Next\nsection describes all supported options to use in `metadata` mapping.\n\nIf you don't want to remember the names of the options you can use\n`field_options` helper function:\n\n```python\nfrom dataclasses import dataclass, field\nfrom mashumaro import field_options\n\n@dataclass\nclass A:\n    x: int = field(metadata=field_options(...))\n```\n\n#### `serialize` option\n\nThis option allows you to change the serialization method. When using\nthis option, the serialization behaviour depends on what type of value the\noption has. It could be either `Callable[[Any], Any]` or `str`.\n\nA value of type `Callable[[Any], Any]` is a generic way to specify any callable\nobject like a function, a class method, a class instance method, an instance\nof a callable class or even a lambda function to be called for serialization.\n\nA value of type `str` sets a specific engine for serialization. Keep in mind\nthat all possible engines depend on the data type that this option is used\nwith. At this moment there are next serialization engines to choose from:\n\n| Applicable data types      | Supported engines    | Description                                                                                                                                                                                                  |\n|:---------------------------|:---------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `NamedTuple`, `namedtuple` | `as_list`, `as_dict` | How to pack named tuples. By default `as_list` engine is used that means your named tuple class instance will be packed into a list of its values. You can pack it into a dictionary using `as_dict` engine. |\n| `Any`                      | `omit`               | Skip the field during serialization                                                                                                                                                                          |\n\n> [!TIP]\\\n> You can pass a field value as is without changes on serialization using\n[`pass_through`](#passing-field-values-as-is).\n\nExample:\n\n```python\nfrom datetime import datetime\nfrom dataclasses import dataclass, field\nfrom typing import NamedTuple\nfrom mashumaro import DataClassDictMixin\n\nclass MyNamedTuple(NamedTuple):\n    x: int\n    y: float\n\n@dataclass\nclass A(DataClassDictMixin):\n    dt: datetime = field(\n        metadata={\n            \"serialize\": lambda v: v.strftime('%Y-%m-%d %H:%M:%S')\n        }\n    )\n    t: MyNamedTuple = field(metadata={\"serialize\": \"as_dict\"})\n```\n\n#### `deserialize` option\n\nThis option allows you to change the deserialization method. When using\nthis option, the deserialization behaviour depends on what type of value the\noption has. It could be either `Callable[[Any], Any]` or `str`.\n\nA value of type `Callable[[Any], Any]` is a generic way to specify any callable\nobject like a function, a class method, a class instance method, an instance\nof a callable class or even a lambda function to be called for deserialization.\n\nA value of type `str` sets a specific engine for deserialization. Keep in mind\nthat all possible engines depend on the data type that this option is used\nwith. At this moment there are next deserialization engines to choose from:\n\n| Applicable data types      | Supported engines                                                                                                                   | Description                                                                                                                                                                                                                                                                                             |\n|:---------------------------|:------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `datetime`, `date`, `time` | [`ciso8601`](https://github.com/closeio/ciso8601#supported-subset-of-iso-8601), [`pendulum`](https://github.com/sdispater/pendulum) | How to parse datetime string. By default native [`fromisoformat`](https://docs.python.org/3/library/datetime.html#datetime.datetime.fromisoformat) of corresponding class will be used for `datetime`, `date` and `time` fields. It's the fastest way in most cases, but you can choose an alternative. |\n| `NamedTuple`, `namedtuple` | `as_list`, `as_dict`                                                                                                                | How to unpack named tuples. By default `as_list` engine is used that means your named tuple class instance will be created from a list of its values. You can unpack it from a dictionary using `as_dict` engine.                                                                                       |\n\n> [!TIP]\\\n> You can pass a field value as is without changes on deserialization using\n[`pass_through`](#passing-field-values-as-is).\n\nExample:\n\n```python\nfrom datetime import datetime\nfrom dataclasses import dataclass, field\nfrom typing import List, NamedTuple\nfrom mashumaro import DataClassDictMixin\nimport ciso8601\nimport dateutil\n\nclass MyNamedTuple(NamedTuple):\n    x: int\n    y: float\n\n@dataclass\nclass A(DataClassDictMixin):\n    x: datetime = field(\n        metadata={\"deserialize\": \"pendulum\"}\n    )\n\nclass B(DataClassDictMixin):\n    x: datetime = field(\n        metadata={\"deserialize\": ciso8601.parse_datetime_as_naive}\n    )\n\n@dataclass\nclass C(DataClassDictMixin):\n    dt: List[datetime] = field(\n        metadata={\n            \"deserialize\": lambda l: list(map(dateutil.parser.isoparse, l))\n        }\n    )\n\n@dataclass\nclass D(DataClassDictMixin):\n    x: MyNamedTuple = field(metadata={\"deserialize\": \"as_dict\"})\n```\n\n#### `serialization_strategy` option\n\nThis option is useful when you want to change the serialization logic\nfor a dataclass field depending on some defined parameters using a reusable\nserialization scheme. You can find an example in the\n[`SerializationStrategy`](#serializationstrategy) chapter.\n\n> [!TIP]\\\n> You can pass a field value as is without changes on\n> serialization / deserialization using\n[`pass_through`](#passing-field-values-as-is).\n\n#### `alias` option\n\nThis option can be used to assign [field aliases](#field-aliases):\n\n\n```python\nfrom dataclasses import dataclass, field\nfrom mashumaro import DataClassDictMixin, field_options\n\n@dataclass\nclass DataClass(DataClassDictMixin):\n    a: int = field(metadata=field_options(alias=\"FieldA\"))\n    b: int = field(metadata=field_options(alias=\"#invalid\"))\n\nx = DataClass.from_dict({\"FieldA\": 1, \"#invalid\": 2})  # DataClass(a=1, b=2)\n```\n\n### Config options\n\nIf inheritance is not an empty word for you, you'll fall in love with the\n`Config` class. You can register `serialize` and `deserialize` methods, define\ncode generation options and other things just in one place. Or in some\nclasses in different ways if you need flexibility. Inheritance is always on the\nfirst place.\n\nThere is a base class `BaseConfig` that you can inherit for the sake of\nconvenience, but it's not mandatory.\n\nIn the following example you can see how\nthe `debug` flag is changed from class to class: `ModelA` will have debug mode enabled but\n`ModelB` will not.\n\n```python\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.config import BaseConfig\n\nclass BaseModel(DataClassDictMixin):\n    class Config(BaseConfig):\n        debug = True\n\nclass ModelA(BaseModel):\n    a: int\n\nclass ModelB(BaseModel):\n    b: int\n\n    class Config(BaseConfig):\n        debug = False\n```\n\nNext section describes all supported options to use in the config.\n\n#### `debug` config option\n\nIf you enable the `debug` option the generated code for your data class\nwill be printed.\n\n#### `code_generation_options` config option\n\nSome users may need functionality that wouldn't exist without extra cost such\nas valuable cpu time to execute additional instructions. Since not everyone\nneeds such instructions, they can be enabled by a constant in the list,\nso the fastest basic behavior of the library will always remain by default.\nThe following table provides a brief overview of all the available constants\ndescribed below.\n\n| Constant                                                        | Description                                                          |\n|:----------------------------------------------------------------|:---------------------------------------------------------------------|\n| [`TO_DICT_ADD_OMIT_NONE_FLAG`](#add-omit_none-keyword-argument) | Adds `omit_none` keyword-only argument to `to_*` methods.            |\n| [`TO_DICT_ADD_BY_ALIAS_FLAG`](#add-by_alias-keyword-argument)   | Adds `by_alias` keyword-only argument to `to_*` methods.             |\n| [`ADD_DIALECT_SUPPORT`](#add-dialect-keyword-argument)          | Adds `dialect` keyword-only argument to `from_*` and `to_*` methods. |\n| [`ADD_SERIALIZATION_CONTEXT`](#add-context-keyword-argument)    | Adds `context` keyword-only argument to `to_*` methods.              |\n\n#### `serialization_strategy` config option\n\nYou can register custom [`SerializationStrategy`](#serializationstrategy), `serialize` and `deserialize`\nmethods for specific types just in one place. It could be configured using\na dictionary with types as keys. The value could be either a\n[`SerializationStrategy`](#serializationstrategy) instance or a dictionary with `serialize` and\n`deserialize` values with the same meaning as in the\n[field options](#field-options).\n\n```python\nfrom dataclasses import dataclass\nfrom datetime import datetime, date\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.config import BaseConfig\nfrom mashumaro.types import SerializationStrategy\n\nclass FormattedDateTime(SerializationStrategy):\n    def __init__(self, fmt):\n        self.fmt = fmt\n\n    def serialize(self, value: datetime) -> str:\n        return value.strftime(self.fmt)\n\n    def deserialize(self, value: str) -> datetime:\n        return datetime.strptime(value, self.fmt)\n\n@dataclass\nclass DataClass(DataClassDictMixin):\n\n    x: datetime\n    y: date\n\n    class Config(BaseConfig):\n        serialization_strategy = {\n            datetime: FormattedDateTime(\"%Y\"),\n            date: {\n                # you can use specific str values for datetime here as well\n                \"deserialize\": \"pendulum\",\n                \"serialize\": date.isoformat,\n            },\n        }\n\ninstance = DataClass.from_dict({\"x\": \"2021\", \"y\": \"2021\"})\n# DataClass(x=datetime.datetime(2021, 1, 1, 0, 0), y=Date(2021, 1, 1))\ndictionary = instance.to_dict()\n# {'x': '2021', 'y': '2021-01-01'}\n```\n\nNote that you can register different methods for multiple logical types which\nare based on the same type using `NewType` and `Annotated`,\nsee [Extending existing types](#extending-existing-types) for details.\n\nIt's also possible to define a generic (de)serialization method for a generic\ntype by registering a method for its\n[origin](https://docs.python.org/3/library/typing.html#typing.get_origin) type.\nAlthough this technique is widely used when working with [third-party generic\ntypes](#third-party-generic-types) using generic strategies, it can also be\napplied in simple scenarios:\n\n```python\nfrom dataclasses import dataclass\nfrom mashumaro import DataClassDictMixin\n\n@dataclass\nclass C(DataClassDictMixin):\n    ints: list[int]\n    floats: list[float]\n\n    class Config:\n        serialization_strategy = {\n            list: {  # origin type for list[int] and list[float] is list\n                \"serialize\": lambda x: list(map(str, x)),\n            }\n        }\n\nassert C([1], [2.2]).to_dict() == {'ints': ['1'], 'floats': ['2.2']}\n```\n\n#### `aliases` config option\n\nSometimes it's better to write the [field aliases](#field-aliases) in one place. You can mix\naliases here with [aliases in the field options](#alias-option), but the last ones will always\ntake precedence.\n\n```python\nfrom dataclasses import dataclass\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.config import BaseConfig\n\n@dataclass\nclass DataClass(DataClassDictMixin):\n    a: int\n    b: int\n\n    class Config(BaseConfig):\n        aliases = {\n            \"a\": \"FieldA\",\n            \"b\": \"FieldB\",\n        }\n\nDataClass.from_dict({\"FieldA\": 1, \"FieldB\": 2})  # DataClass(a=1, b=2)\n```\n\n#### `serialize_by_alias` config option\n\nAll the fields with [aliases](#field-aliases) will be serialized by them by\ndefault when this option is enabled. You can mix this config option with\n[`by_alias`](#add-by_alias-keyword-argument) keyword argument.\n\n```python\nfrom dataclasses import dataclass, field\nfrom mashumaro import DataClassDictMixin, field_options\nfrom mashumaro.config import BaseConfig\n\n@dataclass\nclass DataClass(DataClassDictMixin):\n    field_a: int = field(metadata=field_options(alias=\"FieldA\"))\n\n    class Config(BaseConfig):\n        serialize_by_alias = True\n\nDataClass(field_a=1).to_dict()  # {'FieldA': 1}\n```\n\n#### `allow_deserialization_not_by_alias` config option\n\nWhen using aliases, the deserializer defaults to requiring the keys to match\nwhat is defined as the alias.\nIf the flexibility to deserialize aliased and unaliased keys is required then\nthe config option `allow_deserialization_not_by_alias ` can be set to\nenable the feature.\n\n```python\nfrom dataclasses import dataclass, field\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.config import BaseConfig\n\n\n@dataclass\nclass AliasedDataClass(DataClassDictMixin):\n    foo: int = field(metadata={\"alias\": \"alias_foo\"})\n    bar: int = field(metadata={\"alias\": \"alias_bar\"})\n\n    class Config(BaseConfig):\n        allow_deserialization_not_by_alias = True\n\n\nalias_dict = {\"alias_foo\": 1, \"alias_bar\": 2}\nt1 = AliasedDataClass.from_dict(alias_dict)\n\nno_alias_dict = {\"foo\": 1, \"bar\": 2}\n# This would raise `mashumaro.exceptions.MissingField`\n# if allow_deserialization_not_by_alias was False\nt2 = AliasedDataClass.from_dict(no_alias_dict)\nassert t1 == t2\n```\n\n#### `omit_none` config option\n\nAll the fields with `None` values will be skipped during serialization by\ndefault when this option is enabled. You can mix this config option with\n[`omit_none`](#add-omit_none-keyword-argument) keyword argument.\n\n```python\nfrom dataclasses import dataclass\nfrom typing import Optional\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.config import BaseConfig\n\n@dataclass\nclass DataClass(DataClassDictMixin):\n    x: Optional[int] = 42\n\n    class Config(BaseConfig):\n        omit_none = True\n\nDataClass(x=None).to_dict()  # {}\n```\n\n#### `omit_default` config option\n\nWhen this option enabled, all the fields that have values equal to the defaults\nor the default_factory results will be skipped during serialization.\n\n```python\nfrom dataclasses import dataclass, field\nfrom typing import List, Optional, Tuple\nfrom mashumaro import DataClassDictMixin, field_options\nfrom mashumaro.config import BaseConfig\n\n@dataclass\nclass Foo:\n    foo: str\n\n@dataclass\nclass DataClass(DataClassDictMixin):\n    a: int = 42\n    b: Tuple[int, ...] = field(default=(1, 2, 3))\n    c: List[Foo] = field(default_factory=lambda: [Foo(\"foo\")])\n    d: Optional[str] = None\n\n    class Config(BaseConfig):\n        omit_default = True\n\nDataClass(a=42, b=(1, 2, 3), c=[Foo(\"foo\")]).to_dict()  # {}\n```\n\n#### `namedtuple_as_dict` config option\n\nDataclasses are a great way to declare and use data models. But it's not the only way.\nPython has a typed version of [namedtuple](https://docs.python.org/3/library/collections.html#collections.namedtuple)\ncalled [NamedTuple](https://docs.python.org/3/library/typing.html#typing.NamedTuple)\nwhich looks similar to dataclasses:\n\n```python\nfrom typing import NamedTuple\n\nclass Point(NamedTuple):\n    x: int\n    y: int\n```\n\nthe same with a dataclass will look like this:\n\n```python\nfrom dataclasses import dataclass\n\n@dataclass\nclass Point:\n    x: int\n    y: int\n```\n\nAt first glance, you can use both options. But imagine that you need to create\na bunch of instances of the `Point` class. Due to how dataclasses work you will\nhave more memory consumption compared to named tuples. In such a case it could\nbe more appropriate to use named tuples.\n\nBy default, all named tuples are packed into lists. But with `namedtuple_as_dict`\noption you have a drop-in replacement for dataclasses:\n\n```python\nfrom dataclasses import dataclass\nfrom typing import List, NamedTuple\nfrom mashumaro import DataClassDictMixin\n\nclass Point(NamedTuple):\n    x: int\n    y: int\n\n@dataclass\nclass DataClass(DataClassDictMixin):\n    points: List[Point]\n\n    class Config:\n        namedtuple_as_dict = True\n\nobj = DataClass.from_dict({\"points\": [{\"x\": 0, \"y\": 0}, {\"x\": 1, \"y\": 1}]})\nprint(obj.to_dict())  # {\"points\": [{\"x\": 0, \"y\": 0}, {\"x\": 1, \"y\": 1}]}\n```\n\nIf you want to serialize only certain named tuple fields as dictionaries, you\ncan use the corresponding [serialization](#serialize-option) and\n[deserialization](#deserialize-option) engines.\n\n#### `allow_postponed_evaluation` config option\n\n[PEP 563](https://www.python.org/dev/peps/pep-0563/) solved the problem of forward references by postponing the evaluation\nof annotations, so you can write the following code:\n\n```python\nfrom __future__ import annotations\nfrom dataclasses import dataclass\nfrom mashumaro import DataClassDictMixin\n\n@dataclass\nclass A(DataClassDictMixin):\n    x: B\n\n@dataclass\nclass B(DataClassDictMixin):\n    y: int\n\nobj = A.from_dict({'x': {'y': 1}})\n```\n\nYou don't need to write anything special here, forward references work out of\nthe box. If a field of a dataclass has a forward reference in the type\nannotations, building of `from_*` and `to_*` methods of this dataclass\nwill be postponed until they are called once. However, if for some reason you\ndon't want the evaluation to be possibly postponed, you can disable it using\n`allow_postponed_evaluation` option:\n\n```python\nfrom __future__ import annotations\nfrom dataclasses import dataclass\nfrom mashumaro import DataClassDictMixin\n\n@dataclass\nclass A(DataClassDictMixin):\n    x: B\n\n    class Config:\n        allow_postponed_evaluation = False\n\n# UnresolvedTypeReferenceError: Class A has unresolved type reference B\n# in some of its fields\n\n@dataclass\nclass B(DataClassDictMixin):\n    y: int\n```\n\nIn this case you will get `UnresolvedTypeReferenceError` regardless of whether\nclass B is declared below or not.\n\n#### `dialect` config option\n\nThis option is described [below](#changing-the-default-dialect) in the\nDialects section.\n\n#### `orjson_options` config option\n\nThis option changes default options for `orjson.dumps` encoder which is\nused in [`DataClassORJSONMixin`](#dataclassorjsonmixin). For example, you can\ntell orjson to handle non-`str` `dict` keys as the built-in `json.dumps`\nencoder does. See [orjson documentation](https://github.com/ijl/orjson#option)\nto read more about these options.\n\n```python\nimport orjson\nfrom dataclasses import dataclass\nfrom typing import Dict\nfrom mashumaro.config import BaseConfig\nfrom mashumaro.mixins.orjson import DataClassORJSONMixin\n\n@dataclass\nclass MyClass(DataClassORJSONMixin):\n    x: Dict[int, int]\n\n    class Config(BaseConfig):\n        orjson_options = orjson.OPT_NON_STR_KEYS\n\nassert MyClass({1: 2}).to_json() == {\"1\": 2}\n```\n\n#### `discriminator` config option\n\nThis option is described in the\n[Class level discriminator](#class-level-discriminator) section.\n\n#### `lazy_compilation` config option\n\nBy using this option, the compilation of the `from_*` and `to_*` methods will\nbe deferred until they are called first time. This will reduce the import time\nand, in certain instances, may enhance the speed of deserialization\nby leveraging the data that is accessible after the class has been created.\n\n> [!CAUTION]\\\n> If you need to save a reference to `from_*` or `to_*` method, you should\n> do it after the method is compiled. To be safe, you can always use lambda\n> function:\n> ```python\n> from_dict = lambda x: MyModel.from_dict(x)\n> to_dict = lambda x: x.to_dict()\n> ```\n\n#### `sort_keys` config option\n\nWhen set, the keys on serialized dataclasses will be sorted in alphabetical order.\n\nUnlike the `sort_keys` option in the standard library's `json.dumps` function, this option acts at class creation time and has no effect on the performance of serialization.\n\n```python\nfrom dataclasses import dataclass\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.config import BaseConfig\n\n@dataclass\nclass SortedDataClass(DataClassDictMixin):\n    foo: int\n    bar: int\n\n    class Config(BaseConfig):\n        sort_keys = True\n\nt = SortedDataClass(1, 2)\nassert t.to_dict() == {\"bar\": 2, \"foo\": 1}\n```\n\n#### `forbid_extra_keys` config option\n\nWhen set, the deserialization of dataclasses will fail if the input dictionary contains keys that are not present in the dataclass.\n\n```python\nfrom dataclasses import dataclass\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.config import BaseConfig\n\n@dataclass\nclass DataClass(DataClassDictMixin):\n    a: int\n\n    class Config(BaseConfig):\n        forbid_extra_keys = True\n\nDataClass.from_dict({\"a\": 1, \"b\": 2})  # ExtraKeysError: Extra keys: {'b'}\n```\n\nIt plays well with `aliases` and `allow_deserialization_not_by_alias` options.\n\n### Passing field values as is\n\nIn some cases it's needed to pass a field value as is without any changes\nduring serialization / deserialization. There is a predefined\n[`pass_through`](https://github.com/Fatal1ty/mashumaro/blob/master/mashumaro/helper.py#L58)\nobject that can be used as `serialization_strategy` or\n`serialize` / `deserialize` options:\n\n```python\nfrom dataclasses import dataclass, field\nfrom mashumaro import DataClassDictMixin, pass_through\n\nclass MyClass:\n    def __init__(self, some_value):\n        self.some_value = some_value\n\n@dataclass\nclass A1(DataClassDictMixin):\n    x: MyClass = field(\n        metadata={\n            \"serialize\": pass_through,\n            \"deserialize\": pass_through,\n        }\n    )\n\n@dataclass\nclass A2(DataClassDictMixin):\n    x: MyClass = field(\n        metadata={\n            \"serialization_strategy\": pass_through,\n        }\n    )\n\n@dataclass\nclass A3(DataClassDictMixin):\n    x: MyClass\n\n    class Config:\n        serialization_strategy = {\n            MyClass: pass_through,\n        }\n\n@dataclass\nclass A4(DataClassDictMixin):\n    x: MyClass\n\n    class Config:\n        serialization_strategy = {\n            MyClass: {\n                \"serialize\": pass_through,\n                \"deserialize\": pass_through,\n            }\n        }\n\nmy_class_instance = MyClass(42)\n\nassert A1.from_dict({'x': my_class_instance}).x == my_class_instance\nassert A2.from_dict({'x': my_class_instance}).x == my_class_instance\nassert A3.from_dict({'x': my_class_instance}).x == my_class_instance\nassert A4.from_dict({'x': my_class_instance}).x == my_class_instance\n\na1_dict = A1(my_class_instance).to_dict()\na2_dict = A2(my_class_instance).to_dict()\na3_dict = A3(my_class_instance).to_dict()\na4_dict = A4(my_class_instance).to_dict()\n\nassert a1_dict == a2_dict == a3_dict == a4_dict == {\"x\": my_class_instance}\n```\n\n### Extending existing types\n\nThere are situations where you might want some values of the same type to be\ntreated as their own type. You can create new logical types with\n[`NewType`](https://docs.python.org/3/library/typing.html#newtype),\n[`Annotated`](https://docs.python.org/3/library/typing.html#typing.Annotated)\nor [`TypeAliasType`](https://docs.python.org/3/library/typing.html#typing.TypeAliasType)\nand register serialization strategies for them:\n\n```python\nfrom typing import Mapping, NewType, Annotated\nfrom dataclasses import dataclass\nfrom mashumaro import DataClassDictMixin\n\nSessionID = NewType(\"SessionID\", str)\nAccountID = Annotated[str, \"AccountID\"]\n\ntype DeviceID = str\n\n@dataclass\nclass Context(DataClassDictMixin):\n    account_sessions: Mapping[AccountID, SessionID]\n    account_devices: list[DeviceID]\n\n    class Config:\n        serialization_strategy = {\n            AccountID: {\n                \"deserialize\": lambda x: ...,\n                \"serialize\": lambda x: ...,\n            },\n            SessionID: {\n                \"deserialize\": lambda x: ...,\n                \"serialize\": lambda x: ...,\n            },\n            DeviceID: {\n                \"deserialize\": lambda x: ...,\n                \"serialize\": lambda x: ...,\n            }\n        }\n```\n\nAlthough using `NewType` is usually the most reliable way to avoid logical\nerrors, you have to pay for it with notable overhead. If you are creating\ndataclass instances manually, then you know that type checkers will\nenforce you to enclose a value in your `\"NewType\"` callable, which leads\nto performance degradation:\n\n```python\npython -m timeit -s \"from typing import NewType; MyInt = NewType('MyInt', int)\" \"MyInt(42)\"\n10000000 loops, best of 5: 31.1 nsec per loop\n\npython -m timeit -s \"from typing import NewType; MyInt = NewType('MyInt', int)\" \"42\"\n50000000 loops, best of 5: 4.35 nsec per loop\n```\n\nHowever, when you create dataclass instances using the `from_*` method provided\nby one of the mixins or using one of the decoders, there will be no performance\ndegradation, because the value won't be enclosed in the callable in the\ngenerated code. Therefore, if performance is more important to you than\ncatching logical errors by type checkers, and you are actively creating or\nchanging dataclasses manually, then you should take a closer look at using\n`Annotated`.\n\n### Field aliases\n\nIn some cases it's better to have different names for a field in your dataclass\nand in its serialized view. For example, a third-party legacy API you are\nworking with might operate with camel case style, but you stick to snake case\nstyle in your code base. Or you want to load data with keys that are\ninvalid identifiers in Python. Aliases can solve this problem.\n\nThere are multiple ways to assign an alias:\n* Using `Alias(...)` annotation in a field type\n* Using `alias` parameter in field metadata\n* Using `aliases` parameter in a dataclass config\n\nBy default, aliases only affect deserialization, but it can be extended to\nserialization as well. If you want to serialize all the fields by aliases you\nhave two options to do so:\n* [`serialize_by_alias` config option](#serialize_by_alias-config-option)\n* [`serialize_by_alias` dialect option](#serialize_by_alias-dialect-option)\n* [`by_alias` keyword argument in `to_*` methods](#add-by_alias-keyword-argument)\n\nHere is an example with `Alias` annotation in a field type:\n\n```python\nfrom dataclasses import dataclass\nfrom typing import Annotated\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.types import Alias\n\n@dataclass\nclass DataClass(DataClassDictMixin):\n    foo_bar: Annotated[int, Alias(\"fooBar\")]\n\nobj = DataClass.from_dict({\"fooBar\": 42})  # DataClass(foo_bar=42)\nobj.to_dict()  # {\"foo_bar\": 42}  # no aliases on serialization by default\n```\n\nThe same with field metadata:\n\n```python\nfrom dataclasses import dataclass, field\nfrom mashumaro import field_options\n\n@dataclass\nclass DataClass:\n    foo_bar: str = field(metadata=field_options(alias=\"fooBar\"))\n```\n\nAnd with a dataclass config:\n\n```python\nfrom dataclasses import dataclass\nfrom mashumaro.config import BaseConfig\n\n@dataclass\nclass DataClass:\n    foo_bar: str\n\n    class Config(BaseConfig):\n        aliases = {\"foo_bar\": \"fooBar\"}\n```\n\n> [!TIP]\\\n> If you want to deserialize all the fields by its names along with aliases,\n> there is [a config option](#allow_deserialization_not_by_alias-config-option)\n> for that.\n\n### Dialects\n\nSometimes it's needed to have different serialization and deserialization\nmethods depending on the data source where entities of the dataclass are\nstored or on the API to which the entities are being sent or received from.\nThere is a special `Dialect` type that may contain all the differences from the\ndefault serialization and deserialization methods. You can create different\ndialects and use each of them for the same dataclass depending on\nthe situation.\n\nSuppose we have the following dataclass with a field of type `date`:\n```python\n@dataclass\nclass Entity(DataClassDictMixin):\n    dt: date\n```\n\nBy default, a field of `date` type serializes to a string in ISO 8601 format,\nso the serialized entity will look like `{'dt': '2021-12-31'}`. But what if we\nhave, for example, two sensitive legacy Ethiopian and Japanese APIs that use\ntwo different formats for dates â€” `dd/mm/yyyy` and `yyyyå¹´mmæœˆddæ—¥`? Instead of\ncreating two similar dataclasses we can have one dataclass and two dialects:\n```python\nfrom dataclasses import dataclass\nfrom datetime import date, datetime\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.config import ADD_DIALECT_SUPPORT\nfrom mashumaro.dialect import Dialect\nfrom mashumaro.types import SerializationStrategy\n\nclass DateTimeSerializationStrategy(SerializationStrategy):\n    def __init__(self, fmt: str):\n        self.fmt = fmt\n\n    def serialize(self, value: date) -> str:\n        return value.strftime(self.fmt)\n\n    def deserialize(self, value: str) -> date:\n        return datetime.strptime(value, self.fmt).date()\n\nclass EthiopianDialect(Dialect):\n    serialization_strategy = {\n        date: DateTimeSerializationStrategy(\"%d/%m/%Y\")\n    }\n\nclass JapaneseDialect(Dialect):\n    serialization_strategy = {\n        date: DateTimeSerializationStrategy(\"%Yå¹´%mæœˆ%dæ—¥\")\n    }\n\n@dataclass\nclass Entity(DataClassDictMixin):\n    dt: date\n\n    class Config:\n        code_generation_options = [ADD_DIALECT_SUPPORT]\n\nentity = Entity(date(2021, 12, 31))\nentity.to_dict(dialect=EthiopianDialect)  # {'dt': '31/12/2021'}\nentity.to_dict(dialect=JapaneseDialect)   # {'dt': '2021å¹´12æœˆ31æ—¥'}\nEntity.from_dict({'dt': '2021å¹´12æœˆ31æ—¥'}, dialect=JapaneseDialect)\n```\n\n#### `serialization_strategy` dialect option\n\nThis dialect option has the same meaning as the\n[similar config option](#serialization_strategy-config-option)\nbut for the dialect scope. You can register custom [`SerializationStrategy`](#serializationstrategy),\n`serialize` and `deserialize` methods for the specific types.\n\n#### `serialize_by_alias` dialect option\n\nThis dialect option has the same meaning as the\n[similar config option](#serialize_by_alias-config-option)\nbut for the dialect scope.\n\n#### `omit_none` dialect option\n\nThis dialect option has the same meaning as the\n[similar config option](#omit_none-config-option) but for the dialect scope.\n\n#### `omit_default` dialect option\n\nThis dialect option has the same meaning as the\n[similar config option](#omitdefault-config-option) but for the dialect scope.\n\n#### `namedtuple_as_dict` dialect option\n\nThis dialect option has the same meaning as the\n[similar config option](#namedtuple_as_dict-config-option)\nbut for the dialect scope.\n\n#### `no_copy_collections` dialect option\n\nBy default, all collection data types are serialized as a copy to prevent\nmutation of the original collection. As an example, if a dataclass contains\na field of type `list[str]`, then it will be serialized as a copy of the\noriginal list, so you can safely mutate it after. The downside is that copying\nis always slower than using a reference to the original collection. In some\ncases we know beforehand that mutation doesn't take place or is even desirable,\nso we can benefit from avoiding unnecessary copies by setting\n`no_copy_collections` to a sequence of origin collection data types.\nThis is applicable only for collections containing elements that do not\nrequire conversion.\n\n```python\nfrom dataclasses import dataclass\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.config import BaseConfig\nfrom mashumaro.dialect import Dialect\n\nclass NoCopyDialect(Dialect):\n    no_copy_collections = (list, dict, set)\n\n@dataclass\nclass DataClass(DataClassDictMixin):\n    simple_list: list[str]\n    simple_dict: dict[str, str]\n    simple_set: set[str]\n\n    class Config(BaseConfig):\n        dialect = NoCopyDialect\n\nobj = DataClass([\"foo\"], {\"bar\": \"baz\"}, {\"foobar\"})\ndata = obj.to_dict()\n\nassert data[\"simple_list\"] is obj.simple_list\nassert data[\"simple_dict\"] is obj.simple_dict\nassert data[\"simple_set\"] is obj.simple_set\n```\n\nThis option is enabled for `list` and `dict` in the default dialects that\nbelong to mixins and codecs for the following formats:\n* [JSON (orjson library)](#orjson-library)\n* [TOML](#toml)\n* [MessagePack](#messagepack)\n\n#### Changing the default dialect\n\nYou can change the default serialization and deserialization methods not only\nin the [`serialization_strategy`](#serialization_strategy-config-option) config\noption but also using the `dialect` config option. If you have multiple\ndataclasses without a common parent class the default dialect can help you\nto reduce the number of code lines written:\n\n```python\n@dataclass\nclass Entity(DataClassDictMixin):\n    dt: date\n\n    class Config:\n        dialect = JapaneseDialect\n\nentity = Entity(date(2021, 12, 31))\nentity.to_dict()  # {'dt': '2021å¹´12æœˆ31æ—¥'}\nassert Entity.from_dict({'dt': '2021å¹´12æœˆ31æ—¥'}) == entity\n```\n\nDefault dialect can also be set when using codecs:\n```python\nfrom mashumaro.codecs import BasicDecoder, BasicEncoder\n\n@dataclass\nclass Entity:\n    dt: date\n\ndecoder = BasicDecoder(Entity, default_dialect=JapaneseDialect)\nencoder = BasicEncoder(Entity, default_dialect=JapaneseDialect)\n\nentity = Entity(date(2021, 12, 31))\nencoder.encode(entity) # {'dt': '2021å¹´12æœˆ31æ—¥'}\nassert decoder.decode({'dt': '2021å¹´12æœˆ31æ—¥'}) == entity\n```\n\n### Discriminator\n\nThere is a special `Discriminator` class that allows you to customize how\na union of dataclasses or their hierarchy will be deserialized.\nIt has the following parameters that affects class selection rules:\n\n* `field` â€” optional name of the input dictionary key (also known as tag)\n  by which all the variants can be distinguished\n* `include_subtypes` â€” allow to deserialize subclasses\n* `include_supertypes` â€” allow to deserialize superclasses\n* `variant_tagger_fn` â€” a custom function used to generate tag values\n  associated with a variant\n\nBy default, each variant that you want to discriminate by tags should have a\nclass-level attribute containing an associated tag value. This attribute should\nhave a name defined by `field` parameter. The tag value coule be in the\nfollowing forms:\n\n* without annotations: `type = 42`\n* annotated as ClassVar: `type: ClassVar[int] = 42`\n* annotated as Final: `type: Final[int] = 42`\n* annotated as Literal: `type: Literal[42] = 42`\n* annotated as StrEnum: `type: ResponseType = ResponseType.OK`\n\n> [!NOTE]\\\n> Keep in mind that by default only Final, Literal and StrEnum fields are\n> processed during serialization.\n\nHowever, it is possible to use discriminator without the class-level\nattribute. You can provide a custom function that generates one or many variant\ntag values. This function should take a class as the only argument and return\neither a single value of the basic type like `str` or `int` or a list of them\nto associate multiple tags with a variant. The common practice is to use\na class name as a single tag value:\n\n```python\nvariant_tagger_fn = lambda cls: cls.__name__\n```\n\nNext, we will look at different use cases, as well as their pros and cons.\n\n#### Subclasses distinguishable by a field\n\nOften you have a base dataclass and multiple subclasses that are easily\ndistinguishable from each other by the value of a particular field.\nFor example, there may be different events, messages or requests with\na discriminator field \"event_type\", \"message_type\" or just \"type\". You could've\nlisted all of them within `Union` type, but it would be too verbose and\nimpractical. Moreover, deserialization of the union would be slow, since we\nneed to iterate over each variant in the list until we find the right one.\n\nWe can improve subclass deserialization using `Discriminator` as annotation\nwithin `Annotated` type. We will use `field` parameter and set\n`include_subtypes` to `True`.\n\n> [!IMPORTANT]\\\n> The discriminator field should be accessible from the `__dict__` attribute\n> of a specific descendant, i.e. defined at the level of that descendant.\n> A descendant class without a discriminator field will be ignored, but\n> its descendants won't.\n\nSuppose we have a hierarchy of client events distinguishable by a class\nattribute \"type\":\n\n```python\nfrom dataclasses import dataclass\nfrom ipaddress import IPv4Address\nfrom mashumaro import DataClassDictMixin\n\n@dataclass\nclass ClientEvent(DataClassDictMixin):\n    pass\n\n@dataclass\nclass ClientConnectedEvent(ClientEvent):\n    type = \"connected\"\n    client_ip: IPv4Address\n\n@dataclass\nclass ClientDisconnectedEvent(ClientEvent):\n    type = \"disconnected\"\n    client_ip: IPv4Address\n```\n\nWe use base dataclass `ClientEvent` for a field of another dataclass:\n\n```python\nfrom typing import Annotated, List\n# or from typing_extensions import Annotated\nfrom mashumaro.types import Discriminator\n\n\n@dataclass\nclass AggregatedEvents(DataClassDictMixin):\n    list: List[\n        Annotated[\n            ClientEvent, Discriminator(field=\"type\", include_subtypes=True)\n        ]\n    ]\n```\n\nNow we can deserialize events based on \"type\" value:\n\n```python\nevents = AggregatedEvents.from_dict(\n    {\n        \"list\": [\n            {\"type\": \"connected\", \"client_ip\": \"10.0.0.42\"},\n            {\"type\": \"disconnected\", \"client_ip\": \"10.0.0.42\"},\n        ]\n    }\n)\nassert events == AggregatedEvents(\n    list=[\n        ClientConnectedEvent(client_ip=IPv4Address(\"10.0.0.42\")),\n        ClientDisconnectedEvent(client_ip=IPv4Address(\"10.0.0.42\")),\n    ]\n)\n```\n\n#### Subclasses without a common field\n\nIn rare cases you have to deal with subclasses that don't have a common field\nname which they can be distinguished by. Since `Discriminator` can be\ninitialized without \"field\" parameter you can use it with only\n`include_subclasses` enabled. The drawback is that we will have to go through all\nthe subclasses until we find the suitable one. It's almost like using `Union`\ntype but with subclasses support.\n\nSuppose we're making a brunch. We have some ingredients:\n\n```python\n@dataclass\nclass Ingredient(DataClassDictMixin):\n    name: str\n\n@dataclass\nclass Hummus(Ingredient):\n    made_of: Literal[\"chickpeas\", \"beet\", \"artichoke\"]\n    grams: int\n\n@dataclass\nclass Celery(Ingredient):\n    pieces: int\n```\n\nLet's create a plate:\n\n```python\n@dataclass\nclass Plate(DataClassDictMixin):\n    ingredients: List[\n        Annotated[Ingredient, Discriminator(include_subtypes=True)]\n    ]\n```\n\nAnd now we can put our ingredients on the plate:\n\n```python\nplate = Plate.from_dict(\n    {\n        \"ingredients\": [\n            {\n                \"name\": \"hummus from the shop\",\n                \"made_of\": \"chickpeas\",\n                \"grams\": 150,\n            },\n            {\"name\": \"celery from my garden\", \"pieces\": 5},\n        ]\n    }\n)\nassert plate == Plate(\n    ingredients=[\n        Hummus(name=\"hummus from the shop\", made_of=\"chickpeas\", grams=150),\n        Celery(name=\"celery from my garden\", pieces=5),\n    ]\n)\n```\n\nIn some cases it's necessary to fall back to the base class if there is no\nsuitable subclass. We can set `include_supertypes` to `True`:\n\n```python\n@dataclass\nclass Plate(DataClassDictMixin):\n    ingredients: List[\n        Annotated[\n            Ingredient,\n            Discriminator(include_subtypes=True, include_supertypes=True),\n        ]\n    ]\n\nplate = Plate.from_dict(\n    {\n        \"ingredients\": [\n            {\n                \"name\": \"hummus from the shop\",\n                \"made_of\": \"chickpeas\",\n                \"grams\": 150,\n            },\n            {\"name\": \"celery from my garden\", \"pieces\": 5},\n            {\"name\": \"cumin\"}  # <- new unknown ingredient\n        ]\n    }\n)\nassert plate == Plate(\n    ingredients=[\n        Hummus(name=\"hummus from the shop\", made_of=\"chickpeas\", grams=150),\n        Celery(name=\"celery from my garden\", pieces=5),\n        Ingredient(name=\"cumin\"),  # <- unknown ingredient added\n    ]\n)\n```\n\n#### Class level discriminator\n\nIt may often be more convenient to specify a `Discriminator` once at the class\nlevel and use that class without `Annotated` type for subclass deserialization.\nDepending on the `Discriminator` parameters, it can be used as a replacement for\n[subclasses distinguishable by a field](#subclasses-distinguishable-by-a-field)\nas well as for [subclasses without a common field](#subclasses-without-a-common-field).\nThe only difference is that you can't use `include_supertypes=True` because\nit would lead to a recursion error.\n\nReworked example will look like this:\n\n```python\nfrom dataclasses import dataclass\nfrom ipaddress import IPv4Address\nfrom typing import List\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.config import BaseConfig\nfrom mashumaro.types import Discriminator\n\n@dataclass\nclass ClientEvent(DataClassDictMixin):\n    class Config(BaseConfig):\n        discriminator = Discriminator(  # <- add discriminator\n            field=\"type\",\n            include_subtypes=True,\n        )\n\n@dataclass\nclass ClientConnectedEvent(ClientEvent):\n    type = \"connected\"\n    client_ip: IPv4Address\n\n@dataclass\nclass ClientDisconnectedEvent(ClientEvent):\n    type = \"disconnected\"\n    client_ip: IPv4Address\n\n@dataclass\nclass AggregatedEvents(DataClassDictMixin):\n    list: List[ClientEvent]  # <- use base class here\n```\n\nAnd now we can deserialize events based on \"type\" value as we did earlier:\n\n```python\nevents = AggregatedEvents.from_dict(\n    {\n        \"list\": [\n            {\"type\": \"connected\", \"client_ip\": \"10.0.0.42\"},\n            {\"type\": \"disconnected\", \"client_ip\": \"10.0.0.42\"},\n        ]\n    }\n)\nassert events == AggregatedEvents(\n    list=[\n        ClientConnectedEvent(client_ip=IPv4Address(\"10.0.0.42\")),\n        ClientDisconnectedEvent(client_ip=IPv4Address(\"10.0.0.42\")),\n    ]\n)\n```\n\nWhat's more interesting is that you can now deserialize subclasses simply by\ncalling the superclass `from_*` method, which is very useful:\n```python\ndisconnected_event = ClientEvent.from_dict(\n    {\"type\": \"disconnected\", \"client_ip\": \"10.0.0.42\"}\n)\nassert disconnected_event == ClientDisconnectedEvent(IPv4Address(\"10.0.0.42\"))\n```\n\nThe same is applicable for subclasses without a common field:\n\n```python\n@dataclass\nclass Ingredient(DataClassDictMixin):\n    name: str\n\n    class Config:\n        discriminator = Discriminator(include_subtypes=True)\n\n...\n\ncelery = Ingredient.from_dict({\"name\": \"celery from my garden\", \"pieces\": 5})\nassert celery == Celery(name=\"celery from my garden\", pieces=5)\n```\n\n#### Working with union of classes\n\nDeserialization of union of types distinguishable by a particular field will\nbe much faster using `Discriminator` because there will be no traversal\nof all classes and an attempt to deserialize each of them.\nUsually this approach can be used when you have multiple classes without a\ncommon superclass or when you only need to deserialize some of the subclasses.\nIn the following example we will use `include_supertypes=True` to\ndeserialize two subclasses out of three:\n\n```python\nfrom dataclasses import dataclass\nfrom typing import Annotated, Literal, Union\n# or from typing_extensions import Annotated\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.types import Discriminator\n\n@dataclass\nclass Event(DataClassDictMixin):\n    pass\n\n@dataclass\nclass Event1(Event):\n    code: Literal[1] = 1\n    ...\n\n@dataclass\nclass Event2(Event):\n    code: Literal[2] = 2\n    ...\n\n@dataclass\nclass Event3(Event):\n    code: Literal[3] = 3\n    ...\n\n@dataclass\nclass Message(DataClassDictMixin):\n    event: Annotated[\n        Union[Event1, Event2],\n        Discriminator(field=\"code\", include_supertypes=True),\n    ]\n\nevent1_msg = Message.from_dict({\"event\": {\"code\": 1, ...}})\nevent2_msg = Message.from_dict({\"event\": {\"code\": 2, ...}})\nassert isinstance(event1_msg.event, Event1)\nassert isinstance(event2_msg.event, Event2)\n\n# raises InvalidFieldValue:\nMessage.from_dict({\"event\": {\"code\": 3, ...}})\n```\n\nAgain, it's not necessary to have a common superclass. If you have a union of\ndataclasses without a field that they can be distinguishable by, you can still\nuse `Discriminator`, but deserialization will almost be the same as for `Union`\ntype without `Discriminator` except that it could be possible to deserialize\nsubclasses with `include_subtypes=True`.\n\n> [!IMPORTANT]\\\n> When both `include_subtypes` and `include_supertypes` are enabled,\n> all subclasses will be attempted to be deserialized first,\n> superclasses â€” at the end.\n\nIn the following example you can see how priority works â€” first we try\nto deserialize `ChickpeaHummus`, and if it fails, then we try `Hummus`:\n\n```python\n@dataclass\nclass Hummus(DataClassDictMixin):\n    made_of: Literal[\"chickpeas\", \"artichoke\"]\n    grams: int\n\n@dataclass\nclass ChickpeaHummus(Hummus):\n    made_of: Literal[\"chickpeas\"]\n\n@dataclass\nclass Celery(DataClassDictMixin):\n    pieces: int\n\n@dataclass\nclass Plate(DataClassDictMixin):\n    ingredients: List[\n        Annotated[\n            Union[Hummus, Celery],\n            Discriminator(include_subtypes=True, include_supertypes=True),\n        ]\n    ]\n\nplate = Plate.from_dict(\n    {\n        \"ingredients\": [\n            {\"made_of\": \"chickpeas\", \"grams\": 100},\n            {\"made_of\": \"artichoke\", \"grams\": 50},\n            {\"pieces\": 4},\n        ]\n    }\n)\nassert plate == Plate(\n    ingredients=[\n        ChickpeaHummus(made_of='chickpeas', grams=100),  # <- subclass\n        Hummus(made_of='artichoke', grams=50),  # <- superclass\n        Celery(pieces=4),\n    ]\n)\n```\n\n#### Using a custom variant tagger function\n\nSometimes it is impractical to have a class-level attribute with a tag value,\nespecially when you have a lot of classes. We can have a custom tagger\nfunction instead. This method is applicable for all scenarios of using\nthe discriminator, but for demonstration purposes, let's focus only on one\nof them.\n\nSuppose we want to use the middle part of `Client*Event` as a tag value:\n\n```python\nfrom dataclasses import dataclass\nfrom ipaddress import IPv4Address\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.config import BaseConfig\nfrom mashumaro.types import Discriminator\n\n\ndef client_event_tagger(cls):\n    # not the best way of doing it, it's just a demo\n    return cls.__name__[6:-5].lower()\n\n@dataclass\nclass ClientEvent(DataClassDictMixin):\n    class Config(BaseConfig):\n        discriminator = Discriminator(\n            field=\"type\",\n            include_subtypes=True,\n            variant_tagger_fn=client_event_tagger,\n        )\n\n@dataclass\nclass ClientConnectedEvent(ClientEvent):\n    client_ip: IPv4Address\n\n@dataclass\nclass ClientDisconnectedEvent(ClientEvent):\n    client_ip: IPv4Address\n```\n\nWe can now deserialize subclasses as we did it earlier\n[without variant tagger](#class-level-discriminator):\n```python\ndisconnected_event = ClientEvent.from_dict(\n    {\"type\": \"disconnected\", \"client_ip\": \"10.0.0.42\"}\n)\nassert disconnected_event == ClientDisconnectedEvent(IPv4Address(\"10.0.0.42\"))\n```\n\nIf we need to associate multiple tags with a single variant, we can return\na list of tags:\n\n```python\ndef client_event_tagger(cls):\n    name = cls.__name__[6:-5]\n    return [name.lower(), name.upper()]\n```\n\n### Code generation options\n\n#### Add `omit_none` keyword argument\n\nIf you want to have control over whether to skip `None` values on serialization\nyou can add `omit_none` parameter to `to_*` methods using the\n`code_generation_options` list. The default value of `omit_none`\nparameter depends on whether the [`omit_none`](#omit_none-config-option)\nconfig option or [`omit_none`](#omit_none-dialect-option) dialect option is enabled.\n\n```python\nfrom dataclasses import dataclass\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.config import BaseConfig, TO_DICT_ADD_OMIT_NONE_FLAG\n\n@dataclass\nclass Inner(DataClassDictMixin):\n    x: int = None\n    # \"x\" won't be omitted since there is no TO_DICT_ADD_OMIT_NONE_FLAG here\n\n@dataclass\nclass Model(DataClassDictMixin):\n    x: Inner\n    a: int = None\n    b: str = None  # will be omitted\n\n    class Config(BaseConfig):\n        code_generation_options = [TO_DICT_ADD_OMIT_NONE_FLAG]\n\nModel(x=Inner(), a=1).to_dict(omit_none=True)  # {'x': {'x': None}, 'a': 1}\n```\n\n#### Add `by_alias` keyword argument\n\nIf you want to have control over whether to serialize fields by their\n[aliases](#field-aliases) you can add `by_alias` parameter to `to_*` methods\nusing the `code_generation_options` list. The default value of `by_alias`\nparameter depends on whether the [`serialize_by_alias`](#serialize_by_alias-config-option)\nconfig option is enabled.\n\n```python\nfrom dataclasses import dataclass, field\nfrom mashumaro import DataClassDictMixin, field_options\nfrom mashumaro.config import BaseConfig, TO_DICT_ADD_BY_ALIAS_FLAG\n\n@dataclass\nclass DataClass(DataClassDictMixin):\n    field_a: int = field(metadata=field_options(alias=\"FieldA\"))\n\n    class Config(BaseConfig):\n        code_generation_options = [TO_DICT_ADD_BY_ALIAS_FLAG]\n\nDataClass(field_a=1).to_dict()  # {'field_a': 1}\nDataClass(field_a=1).to_dict(by_alias=True)  # {'FieldA': 1}\n```\n\n#### Add `dialect` keyword argument\n\nSupport for [dialects](#dialects) is disabled by default for performance reasons. You can enable\nit using a `ADD_DIALECT_SUPPORT` constant:\n```python\nfrom dataclasses import dataclass\nfrom datetime import date\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.config import BaseConfig, ADD_DIALECT_SUPPORT\n\n@dataclass\nclass Entity(DataClassDictMixin):\n    dt: date\n\n    class Config(BaseConfig):\n        code_generation_options = [ADD_DIALECT_SUPPORT]\n```\n\n#### Add `context` keyword argument\n\nSometimes it's needed to pass a \"context\" object to the serialization hooks\nthat will take it into account. For example, you could want to have an option\nto remove sensitive data from the serialization result if you need to.\nYou can add `context` parameter to `to_*` methods that will be passed to\n[`__pre_serialize__`](#before-serialization) and\n[`__post_serialize__`](#after-serialization) hooks. The type of this context\nas well as its mutability is up to you.\n\n```python\nfrom dataclasses import dataclass\nfrom typing import Dict, Optional\nfrom uuid import UUID\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.config import BaseConfig, ADD_SERIALIZATION_CONTEXT\n\nclass BaseModel(DataClassDictMixin):\n    class Config(BaseConfig):\n        code_generation_options = [ADD_SERIALIZATION_CONTEXT]\n\n@dataclass\nclass Account(BaseModel):\n    id: UUID\n    username: str\n    name: str\n\n    def __pre_serialize__(self, context: Optional[Dict] = None):\n        return self\n\n    def __post_serialize__(self, d: Dict, context: Optional[Dict] = None):\n        if context and context.get(\"remove_sensitive_data\"):\n            d[\"username\"] = \"***\"\n            d[\"name\"] = \"***\"\n        return d\n\n@dataclass\nclass Session(BaseModel):\n    id: UUID\n    key: str\n    account: Account\n\n    def __pre_serialize__(self, context: Optional[Dict] = None):\n        return self\n\n    def __post_serialize__(self, d: Dict, context: Optional[Dict] = None):\n        if context and context.get(\"remove_sensitive_data\"):\n            d[\"key\"] = \"***\"\n        return d\n\n\nfoo = Session(\n    id=UUID('03321c9f-6a97-421e-9869-918ff2867a71'),\n    key=\"VQ6Q9bX4c8s\",\n    account=Account(\n        id=UUID('4ef2baa7-edef-4d6a-b496-71e6d72c58fb'),\n        username=\"john_doe\",\n        name=\"John\"\n    )\n)\nassert foo.to_dict() == {\n    'id': '03321c9f-6a97-421e-9869-918ff2867a71',\n    'key': 'VQ6Q9bX4c8s',\n    'account': {\n        'id': '4ef2baa7-edef-4d6a-b496-71e6d72c58fb',\n        'username': 'john_doe',\n        'name': 'John'\n    }\n}\nassert foo.to_dict(context={\"remove_sensitive_data\": True}) == {\n    'id': '03321c9f-6a97-421e-9869-918ff2867a71',\n    'key': '***',\n    'account': {\n        'id': '4ef2baa7-edef-4d6a-b496-71e6d72c58fb',\n        'username': '***',\n        'name': '***'\n    }\n}\n```\n\n### Generic dataclasses\n\nAlong with [user-defined generic types](#user-defined-generic-types)\nimplementing `SerializableType` interface, generic and variadic\ngeneric dataclasses can also be used. There are two applicable scenarios\nfor them.\n\n#### Generic dataclass inheritance\n\nIf you have a generic dataclass and want to serialize and deserialize its\ninstances depending on the concrete types, you can use inheritance for that:\n\n```python\nfrom dataclasses import dataclass\nfrom datetime import date\nfrom typing import Generic, Mapping, TypeVar, TypeVarTuple\nfrom mashumaro import DataClassDictMixin\n\nKT = TypeVar(\"KT\")\nVT = TypeVar(\"VT\", date, str)\nTs = TypeVarTuple(\"Ts\")\n\n@dataclass\nclass GenericDataClass(Generic[KT, VT, *Ts]):\n    x: Mapping[KT, VT]\n    y: Tuple[*Ts, KT]\n\n@dataclass\nclass ConcreteDataClass(\n    GenericDataClass[str, date, *Tuple[float, ...]],\n    DataClassDictMixin,\n):\n    pass\n\nConcreteDataClass.from_dict({\"x\": {\"a\": \"2021-01-01\"}, \"y\": [1, 2, \"a\"]})\n# ConcreteDataClass(x={'a': datetime.date(2021, 1, 1)}, y=(1.0, 2.0, 'a'))\n```\n\nYou can override `TypeVar` field with a concrete type or another `TypeVar`.\nPartial specification of concrete types is also allowed. If a generic dataclass\nis inherited without type overriding the types of its fields remain untouched.\n\n#### Generic dataclass in a field type\n\nAnother approach is to specify concrete types in the field type hints. This can\nhelp to have different versions of the same generic dataclass:\n\n```python\nfrom dataclasses import dataclass\nfrom datetime import date\nfrom typing import Generic, TypeVar\nfrom mashumaro import DataClassDictMixin\n\nT = TypeVar('T')\n\n@dataclass\nclass GenericDataClass(Generic[T], DataClassDictMixin):\n    x: T\n\n@dataclass\nclass DataClass(DataClassDictMixin):\n    date: GenericDataClass[date]\n    str: GenericDataClass[str]\n\ninstance = DataClass(\n    date=GenericDataClass(x=date(2021, 1, 1)),\n    str=GenericDataClass(x='2021-01-01'),\n)\ndictionary = {'date': {'x': '2021-01-01'}, 'str': {'x': '2021-01-01'}}\nassert DataClass.from_dict(dictionary) == instance\n```\n\n### GenericSerializableType interface\n\nThere is a generic alternative to [`SerializableType`](#serializabletype-interface)\ncalled `GenericSerializableType`. It makes it possible to decide yourself how\nto serialize and deserialize input data depending on the types provided:\n\n```python\nfrom dataclasses import dataclass\nfrom datetime import date\nfrom typing import Dict, TypeVar\nfrom mashumaro import DataClassDictMixin\nfrom mashumaro.types import GenericSerializableType\n\nKT = TypeVar(\"KT\")\nVT = TypeVar(\"VT\")\n\nclass DictWrapper(Dict[KT, VT], GenericSerializableType):\n    __packers__ = {date: lambda x: x.isoformat(), str: str}\n    __unpackers__ = {date: date.fromisoformat, str: str}\n\n    def _serialize(self, types) -> Dict[KT, VT]:\n        k_type, v_type = types\n        k_conv = self.__packers__[k_type]\n        v_conv = self.__packers__[v_type]\n        return {k_conv(k): v_conv(v) for k, v in self.items()}\n\n    @classmethod\n    def _deserialize(cls, value, types) -> \"DictWrapper[KT, VT]\":\n        k_type, v_type = types\n        k_conv = cls.__unpackers__[k_type]\n        v_conv = cls.__unpackers__[v_type]\n        return cls({k_conv(k): v_conv(v) for k, v in value.items()})\n\n@dataclass\nclass DataClass(DataClassDictMixin):\n    x: DictWrapper[date, str]\n    y: DictWrapper[str, date]\n\ninput_data = {\n    \"x\": {\"2022-12-07\": \"2022-12-07\"},\n    \"y\": {\"2022-12-07\": \"2022-12-07\"},\n}\nobj = DataClass.from_dict(input_data)\nassert obj == DataClass(\n    x=DictWrapper({date(2022, 12, 7): \"2022-12-07\"}),\n    y=DictWrapper({\"2022-12-07\": date(2022, 12, 7)}),\n)\nassert obj.to_dict() == input_data\n```\n\nAs you can see, the code turns out to be massive compared to the\n[alternative](#user-defined-generic-types) but in rare cases such flexibility\ncan be useful. You should think twice about whether it's really worth using it.\n\n### Serialization hooks\n\nIn some cases you need to prepare input / output data or do some extraordinary\nactions at different stages of the deserialization / serialization lifecycle.\nYou can do this with different types of hooks.\n\n#### Before deserialization\n\nFor doing something with a dictionary that will be passed to deserialization\nyou can use `__pre_deserialize__` class method:\n\n```python\n@dataclass\nclass A(DataClassJSONMixin):\n    abc: int\n\n    @classmethod\n    def __pre_deserialize__(cls, d: Dict[Any, Any]) -> Dict[Any, Any]:\n        return {k.lower(): v for k, v in d.items()}\n\nprint(DataClass.from_dict({\"ABC\": 123}))    # DataClass(abc=123)\nprint(DataClass.from_json('{\"ABC\": 123}'))  # DataClass(abc=123)\n```\n\n#### After deserialization\n\nFor doing something with a dataclass instance that was created as a result\nof deserialization you can use `__post_deserialize__` class method:\n\n```python\n@dataclass\nclass A(DataClassJSONMixin):\n    abc: int\n\n    @classmethod\n    def __post_deserialize__(cls, obj: 'A') -> 'A':\n        obj.abc = 456\n        return obj\n\nprint(DataClass.from_dict({\"abc\": 123}))    # DataClass(abc=456)\nprint(DataClass.from_json('{\"abc\": 123}'))  # DataClass(abc=456)\n```\n\n#### Before serialization\n\nFor doing something before serialization you can use `__pre_serialize__`\nmethod:\n\n```python\n@dataclass\nclass A(DataClassJSONMixin):\n    abc: int\n    counter: ClassVar[int] = 0\n\n    def __pre_serialize__(self) -> 'A':\n        self.counter += 1\n        return self\n\nobj = DataClass(abc=123)\nobj.to_dict()\nobj.to_json()\nprint(obj.counter)  # 2\n```\n\nNote that you can add an additional `context` argument using the\n[corresponding](#add-context-keyword-argument) code generation option.\n\n#### After serialization\n\nFor doing something with a dictionary that was created as a result of\nserialization you can use `__post_serialize__` method:\n\n```python\n@dataclass\nclass A(DataClassJSONMixin):\n    user: str\n    password: str\n\n    def __post_serialize__(self, d: Dict[Any, Any]) -> Dict[Any, Any]:\n        d.pop('password')\n        return d\n\nobj = DataClass(user=\"name\", password=\"secret\")\nprint(obj.to_dict())  # {\"user\": \"name\"}\nprint(obj.to_json())  # '{\"user\": \"name\"}'\n```\n\nNote that you can add an additional `context` argument using the\n[corresponding](#add-context-keyword-argument) code generation option.\n\nJSON Schema\n-------------------------------------------------------------------------------\n\nYou can build JSON Schema not only for dataclasses but also for any other\n[supported](#supported-data-types) data\ntypes. There is support for the following standards:\n* [Draft 2020-12](https://json-schema.org/specification.html)\n* [OpenAPI Specification 3.1.0](https://spec.openapis.org/oas/v3.1.0)\n\n### Building JSON Schema\n\nFor simple one-time cases it's recommended to start from using a configurable\n`build_json_schema` function. It returns `JSONSchema` object that can be\nserialized to json or to dict:\n\n```python\nfrom dataclasses import dataclass, field\nfrom typing import List\nfrom uuid import UUID\n\nfrom mashumaro.jsonschema import build_json_schema\n\n\n@dataclass\nclass User:\n    id: UUID\n    name: str = field(metadata={\"description\": \"User name\"})\n\n\nprint(build_json_schema(List[User]).to_json())\n```\n\n<details>\n<summary>Click to show the result</summary>\n\n```json\n{\n    \"type\": \"array\",\n    \"items\": {\n        \"type\": \"object\",\n        \"title\": \"User\",\n        \"properties\": {\n            \"id\": {\n                \"type\": \"string\",\n                \"format\": \"uuid\"\n            },\n            \"name\": {\n                \"type\": \"string\",\n                \"description\": \"User name\"\n            }\n        },\n        \"additionalProperties\": false,\n        \"required\": [\n            \"id\",\n            \"name\"\n        ]\n    }\n}\n```\n</details>\n\nAdditional validation keywords ([see below](#json-schema-constraints))\ncan be added using annotations:\n\n```python\nfrom typing import Annotated, List\nfrom mashumaro.jsonschema import build_json_schema\nfrom mashumaro.jsonschema.annotations import Maximum, MaxItems\n\nprint(\n    build_json_schema(\n        Annotated[\n            List[Annotated[int, Maximum(42)]],\n            MaxItems(4)\n        ]\n    ).to_json()\n)\n```\n\n<details>\n<summary>Click to show the result</summary>\n\n```json\n{\n    \"type\": \"array\",\n    \"items\": {\n        \"type\": \"integer\",\n        \"maximum\": 42\n    },\n    \"maxItems\": 4\n}\n```\n</details>\n\nThe [`$schema`](https://json-schema.org/draft/2020-12/json-schema-core.html#name-the-schema-keyword)\nkeyword can be added by setting `with_dialect_uri` to True:\n\n```python\nprint(build_json_schema(str, with_dialect_uri=True).to_json())\n```\n\n<details>\n<summary>Click to show the result</summary>\n\n```json\n{\n    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n    \"type\": \"string\"\n}\n```\n</details>\n\nBy default, Draft 2022-12 dialect is being used, but you can change it to\nanother one by setting `dialect` parameter:\n\n```python\nfrom mashumaro.jsonschema import OPEN_API_3_1\n\nprint(\n    build_json_schema(\n        str, dialect=OPEN_API_3_1, with_dialect_uri=True\n    ).to_json()\n)\n```\n\n<details>\n<summary>Click to show the result</summary>\n\n```json\n{\n    \"$schema\": \"https://spec.openapis.org/oas/3.1/dialect/base\",\n    \"type\": \"string\"\n}\n```\n</details>\n\nAll dataclass JSON Schemas can or can not be placed in the\n[definitions](https://json-schema.org/draft/2020-12/json-schema-core.html#name-schema-re-use-with-defs)\nsection, depending on the `all_refs` parameter, which default value comes\nfrom a dialect used (`False` for Draft 2022-12, `True` for OpenAPI\nSpecification 3.1.0):\n\n```python\nprint(build_json_schema(List[User], all_refs=True).to_json())\n```\n<details>\n<summary>Click to show the result</summary>\n\n```json\n{\n    \"type\": \"array\",\n    \"$defs\": {\n        \"User\": {\n            \"type\": \"object\",\n            \"title\": \"User\",\n            \"properties\": {\n                \"id\": {\n                    \"type\": \"string\",\n                    \"format\": \"uuid\"\n                },\n                \"name\": {\n                    \"type\": \"string\"\n                }\n            },\n            \"additionalProperties\": false,\n            \"required\": [\n                \"id\",\n                \"name\"\n            ]\n        }\n    },\n    \"items\": {\n        \"$ref\": \"#/$defs/User\"\n    }\n}\n```\n</details>\n\nThe definitions section can be omitted from the final document by setting\n`with_definitions` parameter to `False`:\n\n```python\nprint(\n    build_json_schema(\n        List[User], dialect=OPEN_API_3_1, with_definitions=False\n    ).to_json()\n)\n```\n\n<details>\n<summary>Click to show the result</summary>\n\n```json\n{\n    \"type\": \"array\",\n    \"items\": {\n        \"$ref\": \"#/components/schemas/User\"\n    }\n}\n```\n</details>\n\nReference prefix can be changed by using `ref_prefix` parameter:\n\n```python\nprint(\n    build_json_schema(\n        List[User],\n        all_refs=True,\n        with_definitions=False,\n        ref_prefix=\"#/components/responses\",\n    ).to_json()\n)\n```\n\n<details>\n<summary>Click to show the result</summary>\n\n```json\n{\n    \"type\": \"array\",\n    \"items\": {\n        \"$ref\": \"#/components/responses/User\"\n    }\n}\n```\n</details>\n\nThe omitted definitions could be found later in the `Context` object that\nyou could have created and passed to the function, but it could be easier\nto use `JSONSchemaBuilder` for that. For example, you might found it handy\nto build OpenAPI Specification step by step passing your models to the builder\nand get all the registered definitions later. This builder has reasonable\ndefaults but can be customized if necessary.\n\n```python\nfrom mashumaro.jsonschema import JSONSchemaBuilder, OPEN_API_3_1\n\nbuilder = JSONSchemaBuilder(OPEN_API_3_1)\n\n@dataclass\nclass User:\n    id: UUID\n    name: str\n\n@dataclass\nclass Device:\n    id: UUID\n    model: str\n\nprint(builder.build(List[User]).to_json())\nprint(builder.build(List[Device]).to_json())\nprint(builder.get_definitions().to_json())\n```\n\n<details>\n<summary>Click to show the result</summary>\n\n```json\n{\n    \"type\": \"array\",\n    \"items\": {\n        \"$ref\": \"#/components/schemas/User\"\n    }\n}\n```\n```json\n{\n    \"type\": \"array\",\n    \"items\": {\n        \"$ref\": \"#/components/schemas/Device\"\n    }\n}\n```\n```json\n{\n    \"User\": {\n        \"type\": \"object\",\n        \"title\": \"User\",\n        \"properties\": {\n            \"id\": {\n                \"type\": \"string\",\n                \"format\": \"uuid\"\n            },\n            \"name\": {\n                \"type\": \"string\"\n            }\n        },\n        \"additionalProperties\": false,\n        \"required\": [\n            \"id\",\n            \"name\"\n        ]\n    },\n    \"Device\": {\n        \"type\": \"object\",\n        \"title\": \"Device\",\n        \"properties\": {\n            \"id\": {\n                \"type\": \"string\",\n                \"format\": \"uuid\"\n            },\n            \"model\": {\n                \"type\": \"string\"\n            }\n        },\n        \"additionalProperties\": false,\n        \"required\": [\n            \"id\",\n            \"model\"\n        ]\n    }\n}\n```\n</details>\n\n### JSON Schema constraints\n\nApart from required keywords, that are added automatically for certain data\ntypes, you're free to use additional validation keywords.\nThey're presented by the corresponding classes in\n[`mashumaro.jsonschema.annotations`](https://github.com/Fatal1ty/mashumaro/blob/master/mashumaro/jsonschema/annotations.py):\n\nNumber constraints:\n* [`Minimum`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-minimum)\n* [`Maximum`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-maximum)\n* [`ExclusiveMinimum`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-exclusiveminimum)\n* [`ExclusiveMaximum`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-exclusivemaximum)\n* [`MultipleOf`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-multipleof)\n\nString constraints:\n* [`MinLength`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-minlength)\n* [`MaxLength`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-maxlength)\n* [`Pattern`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-pattern)\n\nArray constraints:\n* [`MinItems`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-minitems)\n* [`MaxItems`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-maxitems)\n* [`UniqueItems`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-uniqueitems)\n* [`Contains`](https://json-schema.org/draft/2020-12/json-schema-core.html#name-contains)\n* [`MinContains`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-mincontains)\n* [`MaxContains`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-maxcontains)\n\nObject constraints:\n* [`MaxProperties`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-maxproperties)\n* [`MinProperties`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-minproperties)\n* [`DependentRequired`](https://json-schema.org/draft/2020-12/json-schema-validation.html#name-dependentrequired)\n\n### Extending JSON Schema\n\nUsing a `Config` class it is possible to override some parts of the schema.\nCurrently, you can do the following:\n* override some field schemas using the \"properties\" key\n* change `additionalProperties` using the \"additionalProperties\" key\n\n```python\nfrom dataclasses import dataclass\nfrom mashumaro.jsonschema import build_json_schema\n\n@dataclass\nclass FooBar:\n    foo: str\n    bar: int\n\n    class Config:\n        json_schema = {\n            \"properties\": {\n                \"foo\": {\n                    \"type\": \"string\",\n                    \"description\": \"bar\"\n                }\n            },\n            \"additionalProperties\": True,\n        }\n\nprint(build_json_schema(FooBar).to_json())\n```\n\n<details>\n<summary>Click to show the result</summary>\n\n```json\n{\n    \"type\": \"object\",\n    \"title\": \"FooBar\",\n    \"properties\": {\n        \"foo\": {\n            \"type\": \"string\",\n            \"description\": \"bar\"\n        },\n        \"bar\": {\n            \"type\": \"integer\"\n        }\n    },\n    \"additionalProperties\": true,\n    \"required\": [\n        \"foo\",\n        \"bar\"\n    ]\n}\n```\n</details>\n\nYou can also change the \"additionalProperties\" key to a specific schema\nby passing it a `JSONSchema` instance instead of a bool value.\n\n### JSON Schema and custom serialization methods\n\nMashumaro provides different ways to override default serialization methods for\ndataclass fields or specific data types. In order for these overrides to be\nreflected in the schema, you need to make sure that the methods have\nannotations of the return value type.\n\n```python\nfrom dataclasses import dataclass, field\nfrom mashumaro.config import BaseConfig\nfrom mashumaro.jsonschema import build_json_schema\n\ndef str_as_list(s: str) -> list[str]:\n    return list(s)\n\ndef int_as_str(i: int) -> str:\n    return str(i)\n\n@dataclass\nclass FooBar:\n    foo: str = field(metadata={\"serialize\": str_as_list})\n    bar: int\n\n    class Config(BaseConfig):\n        serialization_strategy = {\n            int: {\n                \"serialize\": int_as_str\n            }\n        }\n\nprint(build_json_schema(FooBar).to_json())\n```\n\n<details>\n<summary>Click to show the result</summary>\n\n```json\n{\n    \"type\": \"object\",\n    \"title\": \"FooBar\",\n    \"properties\": {\n        \"foo\": {\n            \"type\": \"array\",\n            \"items\": {\n                \"type\": \"string\"\n            }\n        },\n        \"bar\": {\n            \"type\": \"string\"\n        }\n    },\n    \"additionalProperties\": false,\n    \"required\": [\n        \"foo\",\n        \"bar\"\n    ]\n}\n```\n</details>\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/Fatal1ty/mashumaro",
        "author": "Alexander Tikhonov",
        "author_email": "random.gauss@gmail.com",
        "license": "Apache License, Version 2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "License :: OSI Approved :: Apache Software License",
          "Intended Audience :: Developers",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Development Status :: 5 - Production/Stable"
        ],
        "requires_dist": [
          "typing-extensions>=4.1.0",
          "msgpack>=0.5.6; extra == \"msgpack\"",
          "orjson; extra == \"orjson\"",
          "tomli-w>=1.0; extra == \"toml\"",
          "tomli>=1.1.0; python_version < \"3.11\" and extra == \"toml\"",
          "pyyaml>=3.13; extra == \"yaml\""
        ],
        "requires_python": ">=3.8",
        "provides_extra": [
          "msgpack",
          "orjson",
          "toml",
          "yaml"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/mashumaro-3.14.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "dbt-semantic-interfaces",
        "version": "0.9.0",
        "summary": "The shared semantic layer definitions that dbt-core and MetricFlow use",
        "description": "<p align=\"center\">\n    <a target=\"_blank\" href=\"https://twitter.com/dbt_labs\">\n    <img src=\"https://img.shields.io/twitter/follow/dbt_labs?labelColor=image.png&color=163B36&logo=twitter&style=flat\">\n  </a>\n    <a target=\"_blank\" href=\"https://www.getdbt.com/community/\">\n    <img src=\"https://img.shields.io/badge/Slack-join-163B36\">\n  </a>\n    <a href=\"https://github.com/psf/black\"><img src=\"https://img.shields.io/badge/code%20style-black-000000.svg\" /></a>\n</p>\n\n# dbt-semantic-interfaces\n\nThis repo contains the shared semantic classes, default validation, and tests designed to be used by both the dbt-core and MetricFlow projects. By centralizing these shared resources, we aim to maintain consistency and reduce code duplication across both projects.\n\n## Features\n- Protocols for shared semantic classes: Define the interfaces and common attributes that must be implemented by the objects in both projects.\n- Validation: Ensure that the objects comply with the expected structure and constraints.\n- Tests: Ensure that the objects' behavior is consistent and correct across both projects.\n\n## Contributing\nWe welcome contributions to improve this codebase! If you're interested in contributing, please read our [contributing guidelines](CONTRIBUTING.md) and [code of conduct](CODE_OF_CONDUCT.md) first.\n\n## License\nThis package is released under the Apache2 License.\n\n## Support\nIf you encounter any issues or have questions regarding the repo, please open an issue!\n",
        "description_content_type": "text/markdown",
        "author_email": "dbt Labs <info@dbtlabs.com>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "License :: OSI Approved :: Apache Software License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_dist": [
          "click<9.0,>=7.0",
          "importlib-metadata<9,>=6.0",
          "jinja2<4,>=3.1.6",
          "jsonschema<5,>=4.0",
          "more-itertools<11.0,>=8.0",
          "pydantic<3,>=1.10",
          "python-dateutil<3,>=2.0",
          "pyyaml<7,>=6.0",
          "typing-extensions<5,>=4.4"
        ],
        "requires_python": ">=3.8"
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/dbt_semantic_interfaces-0.9.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "PyYAML",
        "version": "6.0.3",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "download-url",
          "home-page",
          "license",
          "license-file",
          "platform",
          "project-url",
          "requires-python",
          "summary"
        ],
        "platform": [
          "Any"
        ],
        "summary": "YAML parser and emitter for Python",
        "description": "YAML is a data serialization format designed for human readability\nand interaction with scripting languages.  PyYAML is a YAML parser\nand emitter for Python.\n\nPyYAML features a complete YAML 1.1 parser, Unicode support, pickle\nsupport, capable extension API, and sensible error messages.  PyYAML\nsupports standard YAML tags and provides Python-specific tags that\nallow to represent an arbitrary Python object.\n\nPyYAML is applicable for a broad range of tasks from complex\nconfiguration files to object serialization and persistence.\n",
        "home_page": "https://pyyaml.org/",
        "download_url": "https://pypi.org/project/PyYAML/",
        "author": "Kirill Simonov",
        "author_email": "xi@resolvent.net",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Programming Language :: Cython",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Text Processing :: Markup"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Bug Tracker, https://github.com/yaml/pyyaml/issues",
          "CI, https://github.com/yaml/pyyaml/actions",
          "Documentation, https://pyyaml.org/wiki/PyYAMLDocumentation",
          "Mailing lists, http://lists.sourceforge.net/lists/listinfo/yaml-core",
          "Source Code, https://github.com/yaml/pyyaml"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/pyyaml-6.0.3.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "daff",
        "version": "1.4.2",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "keywords",
          "license",
          "license-file",
          "summary"
        ],
        "summary": "Diff and patch tables",
        "description": "[![NPM version](https://badge.fury.io/js/daff.svg)](http://badge.fury.io/js/daff)\n[![PyPI version](https://badge.fury.io/py/daff.svg)](http://badge.fury.io/py/daff)\n[![PHP version](https://badge.fury.io/ph/paulfitz%2Fdaff-php.svg)](http://badge.fury.io/ph/paulfitz%2Fdaff-php)\n[![Gem Version](https://badge.fury.io/rb/daff.svg)](http://badge.fury.io/rb/daff)\n\ndaff: data diff\n===============\n\nThis is a library for comparing tables, producing a summary of their\ndifferences, and using such a summary as a patch file.  It is\noptimized for comparing tables that share a common origin, in other\nwords multiple versions of the \"same\" table.\n\nFor a live demo, see:\n> https://paulfitz.github.io/daff/\n\nInstall the library for your favorite language:\n````sh\nnpm install daff -g  # node/javascript\npip install daff     # python\ngem install daff     # ruby\ncomposer require paulfitz/daff-php  # php\ninstall.packages('daff') # R wrapper by Edwin de Jonge\n````\n\nUse on the web from a CDN:\n```\n<script src=\"https://cdn.jsdelivr.net/npm/daff@latest/lib/daff.min.js\"></script>\n```\n\nOther translations are available here:\n> https://github.com/paulfitz/daff/releases/tag/v1.3.16\n\nOr use the library to view csv diffs on github via a chrome extension:\n> https://github.com/theodi/csvhub\n\nThe program\n-----------\n\nYou can run `daff`/`daff.py`/`daff.rb` as a utility program:\n````\n$ daff\ndaff can produce and apply tabular diffs.\nCall as:\n  daff a.csv b.csv\n  daff [--color] [--no-color] [--output OUTPUT.csv] a.csv b.csv\n  daff [--output OUTPUT.html] a.csv b.csv\n  daff [--www] a.csv b.csv\n  daff parent.csv a.csv b.csv\n  daff --input-format sqlite a.db b.db\n  daff patch [--inplace] a.csv patch.csv\n  daff merge [--inplace] parent.csv a.csv b.csv\n  daff trim [--output OUTPUT.csv] source.csv\n  daff render [--output OUTPUT.html] diff.csv\n  daff copy in.csv out.tsv\n  daff in.csv\n  daff git\n  daff version\n\nThe --inplace option to patch and merge will result in modification of a.csv.\n\nIf you need more control, here is the full list of flags:\n  daff diff [--output OUTPUT.csv] [--context NUM] [--all] [--act ACT] a.csv b.csv\n     --act ACT:     show only a certain kind of change (update, insert, delete, column)\n     --all:         do not prune unchanged rows or columns\n     --all-rows:    do not prune unchanged rows\n     --all-columns: do not prune unchanged columns\n     --color:       highlight changes with terminal colors (default in terminals)\n     --context NUM: show NUM rows of context (0=none)\n     --context-columns NUM: show NUM columns of context (0=none)\n     --fail-if-diff: return status is 0 if equal, 1 if different, 2 if problem\n     --id:          specify column to use as primary key (repeat for multi-column key)\n     --ignore:      specify column to ignore completely (can repeat)\n     --index:       include row/columns numbers from original tables\n     --input-format [csv|tsv|ssv|psv|json|sqlite]: set format to expect for input\n     --eol [crlf|lf|cr|auto]: separator between rows of csv output.\n     --no-color:    make sure terminal colors are not used\n     --ordered:     assume row order is meaningful (default for CSV)\n     --output-format [csv|tsv|ssv|psv|json|copy|html]: set format for output\n     --padding [dense|sparse|smart]: set padding method for aligning columns\n     --table NAME:  compare the named table, used with SQL sources. If name changes, use 'n1:n2'\n     --unordered:   assume row order is meaningless (default for json formats)\n     -w / --ignore-whitespace: ignore changes in leading/trailing whitespace\n     -i / --ignore-case: ignore differences in case\n\n  daff render [--output OUTPUT.html] [--css CSS.css] [--fragment] [--plain] diff.csv\n     --css CSS.css: generate a suitable css file to go with the html\n     --fragment:    generate just a html fragment rather than a page\n     --plain:       do not use fancy utf8 characters to make arrows prettier\n     --unquote:     do not quote html characters in html diffs\n     --www:         send output to a browser\n````\n\nFormats supported are CSV, TSV, Sqlite (with `--input-format sqlite` or\nthe `.sqlite` extension), and ndjson.\n\nUsing with git\n--------------\n\nRun `daff git csv` to install daff as a diff and merge handler\nfor `*.csv` files in your repository.  Run `daff git` for instructions\non doing this manually. Your CSV diffs and merges will get smarter,\nsince git will suddenly understand about rows and columns, not just lines:\n\n![Example CSV diff](http://paulfitz.github.io/daff-doc/images/daff_vs_diff.png)\n\nThe library\n-----------\n\nYou can use `daff` as a library from any supported language.  We take\nhere the example of Javascript.  To use `daff` on a webpage,\nfirst include `daff.js`:\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/daff@1.4.2/lib/daff.min.js\"></script>\n```\nYou can find a [minimal demo](https://paulfitz.github.io/daff/minimal-demo.html) on the project website.\nOr if using node outside the browser:\n```js\nvar daff = require('daff');\n```\n\nFor concreteness, assume we have two versions of a table,\n`data1` and `data2`:\n```js\nconst data1 = [\n    ['Country','Capital'],\n    ['Ireland','Dublin'],\n    ['France','Paris'],\n    ['Spain','Barcelona']\n];\nconst data2 = [\n    ['Country','Code','Capital'],\n    ['Ireland','ie','Dublin'],\n    ['France','fr','Paris'],\n    ['Spain','es','Madrid'],\n    ['Germany','de','Berlin']\n];\n```\n\nTo make those tables accessible to the library, we wrap them\nin `daff.TableView`:\n```js\nconst table1 = new daff.TableView(data1);\nconst table2 = new daff.TableView(data2);\n```\n\nWe can now compute the alignment between the rows and columns\nin the two tables:\n```js\nconst alignment = daff.compareTables(table1,table2).align();\n```\n\nTo produce a diff from the alignment, we first need a table\nfor the output:\n```js\nconst data_diff = [];\nconst table_diff = new daff.TableView(data_diff);\n```\n\nUsing default options for the diff:\n```js\nconst flags = new daff.CompareFlags();\nconst highlighter = new daff.TableDiff(alignment,flags);\nhighlighter.hilite(table_diff);\n```\n\nThe diff is now in `data_diff` in highlighter format, see\nspecification here:\n> http://paulfitz.github.io/daff-doc/spec.html\n>\n> https://specs.frictionlessdata.io/tabular-diff/\n\n```js\n[ [ '!', '', '+++', '' ],\n  [ '@@', 'Country', 'Code', 'Capital' ],\n  [ '+', 'Ireland', 'ie', 'Dublin' ],\n  [ '+', 'France', 'fr', 'Paris' ],\n  [ '->', 'Spain', 'es', 'Barcelona->Madrid' ],\n  [ '+++', 'Germany', 'de', 'Berlin' ] ]\n```\n\nFor visualization, you may want to convert this to a HTML table\nwith appropriate classes on cells so you can color-code inserts,\ndeletes, updates, etc.  You can do this with:\n```js\nconst diff2html = new daff.DiffRender();\ndiff2html.render(table_diff);\nconst table_diff_html = diff2html.html();\n```\n\nFor 3-way differences (that is, comparing two tables given knowledge\nof a common ancestor) use `daff.compareTables3` (give ancestor\ntable as the first argument).\n\nHere is how to apply that difference as a patch:\n```js\nconst patcher = new daff.HighlightPatch(table1,table_diff);\npatcher.apply();\n// table1 should now equal table2\n```\n\nFor other languages, you should find sample code in\nthe packages on the [Releases](https://github.com/paulfitz/daff/releases/tag/v1.3.16) page.\n\nSupported languages\n-------------------\n\nThe `daff` library is written in [Haxe](http://haxe.org/), which\ncan be translated reasonably well into at least the following languages:\n\n * Javascript\n * Python\n * Java\n * C#\n * C++\n * Ruby (using an [unofficial haxe target](https://github.com/paulfitz/haxe) developed for `daff`)\n * PHP\n\nSome translations are done for you on the\n[Releases](https://github.com/paulfitz/daff/releases) page.\nTo make another translation, or to compile from source\nfirst follow the [Haxe language introduction](https://haxe.org/documentation/introduction/language-introduction.html) for the\nlanguage you care about.  At the time of writing, if you are on OSX, you should\ninstall haxe using `brew install haxe`.  Then do one of:\n\n```\nmake js\nmake php\nmake py\nmake java\nmake cs\nmake cpp\n```\n\nFor each language, the `daff` library expects to be handed an interface to tables you create, rather than creating them\nitself.  This is to avoid inefficient copies from one format to another.  You'll find a `SimpleTable` class you can use if\nyou find this awkward.\n\nOther possibilities:\n\n * There's a daff wrapper for R written by [Edwin de Jonge](https://github.com/edwindj), see https://github.com/edwindj/daff and http://cran.r-project.org/web/packages/daff\n * There's a hand-written ruby port by [James Smith](https://github.com/Floppy), see https://github.com/theodi/coopy-ruby\n\nAPI documentation\n-----------------\n\n * You can browse the `daff` classes at http://paulfitz.github.io/daff-doc/\n\nSponsors\n--------\n\nThe <a href=\"https://datacommons.coop\">Data Commons Co-op</a>,  \"perhaps the geekiest of all cooperative organizations on the planet,\" has given great moral support during the development of `daff`.\nDonate a multiple of `42.42` in your currency to let them know you care: <a href=\"https://datacommons.coop/donate/\">https://datacommons.coop/donate/</a>.\n\nReading material\n----------------\n\n * https://specs.frictionlessdata.io/tabular-diff : a specification of the diff format we use.\n * http://theodi.org/blog/csvhub-github-diffs-for-csv-files : using this library with github.\n * https://github.com/ropensci/unconf/issues/19 : a thread about diffing data in which daff shows up in at least four guises (see if you can spot them all).\n * http://theodi.org/blog/adapting-git-simple-data : using this library with gitlab.\n * http://okfnlabs.org/blog/2013/08/08/diffing-and-patching-data.html : a summary of where the library came from.\n * http://blog.okfn.org/2013/07/02/git-and-github-for-data/ : a post about storing small data in git/github.\n * http://blog.ouseful.info/2013/08/27/diff-or-chop-github-csv-data-files-and-openrefine/ : counterpoint - a post discussing tracked-changes rather than diffs.\n * http://blog.byronjsmith.com/makefile-shortcuts.html : a tutorial on using `make` for data, with daff in the mix. \"Since git considers changes on a per-line basis,\n   looking at diffs of comma-delimited and tab-delimited files can get obnoxious. The program daff fixes this problem.\"\n\n## License\n\ndaff is distributed under the MIT License.\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "data",
          "diff",
          "patch"
        ],
        "home_page": "https://github.com/paulfitz/daff",
        "author": "Paul Fitzpatrick",
        "author_email": "paulfitz@alum.mit.edu",
        "license": "MIT",
        "license_file": [
          "LICENSE.md"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Topic :: Utilities",
          "License :: OSI Approved :: MIT License"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/daff-1.4.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "msgpack",
        "version": "1.1.2",
        "dynamic": [
          "license-file"
        ],
        "summary": "MessagePack serializer",
        "description": "# MessagePack for Python\n\n[![Build Status](https://github.com/msgpack/msgpack-python/actions/workflows/wheel.yml/badge.svg)](https://github.com/msgpack/msgpack-python/actions/workflows/wheel.yml)\n[![Documentation Status](https://readthedocs.org/projects/msgpack-python/badge/?version=latest)](https://msgpack-python.readthedocs.io/en/latest/?badge=latest)\n\n## What is this?\n\n[MessagePack](https://msgpack.org/) is an efficient binary serialization format.\nIt lets you exchange data among multiple languages like JSON.\nBut it's faster and smaller.\nThis package provides CPython bindings for reading and writing MessagePack data.\n\n## Install\n\n```\n$ pip install msgpack\n```\n\n### Pure Python implementation\n\nThe extension module in msgpack (`msgpack._cmsgpack`) does not support PyPy.\n\nBut msgpack provides a pure Python implementation (`msgpack.fallback`) for PyPy.\n\n\n### Windows\n\nIf you can't use a binary distribution, you need to install Visual Studio\nor the Windows SDK on Windows.\nWithout the extension, the pure Python implementation on CPython runs slowly.\n\n\n## How to use\n\n### One-shot pack & unpack\n\nUse `packb` for packing and `unpackb` for unpacking.\nmsgpack provides `dumps` and `loads` as aliases for compatibility with\n`json` and `pickle`.\n\n`pack` and `dump` pack to a file-like object.\n`unpack` and `load` unpack from a file-like object.\n\n```pycon\n>>> import msgpack\n>>> msgpack.packb([1, 2, 3])\n'\\x93\\x01\\x02\\x03'\n>>> msgpack.unpackb(_)\n[1, 2, 3]\n```\n\nRead the docstring for options.\n\n\n### Streaming unpacking\n\n`Unpacker` is a \"streaming unpacker\". It unpacks multiple objects from one\nstream (or from bytes provided through its `feed` method).\n\n```py\nimport msgpack\nfrom io import BytesIO\n\nbuf = BytesIO()\nfor i in range(100):\n   buf.write(msgpack.packb(i))\n\nbuf.seek(0)\n\nunpacker = msgpack.Unpacker(buf)\nfor unpacked in unpacker:\n    print(unpacked)\n```\n\n\n### Packing/unpacking of custom data types\n\nIt is also possible to pack/unpack custom data types. Here is an example for\n`datetime.datetime`.\n\n```py\nimport datetime\nimport msgpack\n\nuseful_dict = {\n    \"id\": 1,\n    \"created\": datetime.datetime.now(),\n}\n\ndef decode_datetime(obj):\n    if '__datetime__' in obj:\n        obj = datetime.datetime.strptime(obj[\"as_str\"], \"%Y%m%dT%H:%M:%S.%f\")\n    return obj\n\ndef encode_datetime(obj):\n    if isinstance(obj, datetime.datetime):\n        return {'__datetime__': True, 'as_str': obj.strftime(\"%Y%m%dT%H:%M:%S.%f\")}\n    return obj\n\n\npacked_dict = msgpack.packb(useful_dict, default=encode_datetime)\nthis_dict_again = msgpack.unpackb(packed_dict, object_hook=decode_datetime)\n```\n\n`Unpacker`'s `object_hook` callback receives a dict; the\n`object_pairs_hook` callback may instead be used to receive a list of\nkey-value pairs.\n\nNOTE: msgpack can encode datetime with tzinfo into standard ext type for now.\nSee `datetime` option in `Packer` docstring.\n\n\n### Extended types\n\nIt is also possible to pack/unpack custom data types using the **ext** type.\n\n```pycon\n>>> import msgpack\n>>> import array\n>>> def default(obj):\n...     if isinstance(obj, array.array) and obj.typecode == 'd':\n...         return msgpack.ExtType(42, obj.tostring())\n...     raise TypeError(\"Unknown type: %r\" % (obj,))\n...\n>>> def ext_hook(code, data):\n...     if code == 42:\n...         a = array.array('d')\n...         a.fromstring(data)\n...         return a\n...     return ExtType(code, data)\n...\n>>> data = array.array('d', [1.2, 3.4])\n>>> packed = msgpack.packb(data, default=default)\n>>> unpacked = msgpack.unpackb(packed, ext_hook=ext_hook)\n>>> data == unpacked\nTrue\n```\n\n\n### Advanced unpacking control\n\nAs an alternative to iteration, `Unpacker` objects provide `unpack`,\n`skip`, `read_array_header`, and `read_map_header` methods. The former two\nread an entire message from the stream, respectively deserializing and returning\nthe result, or ignoring it. The latter two methods return the number of elements\nin the upcoming container, so that each element in an array, or key-value pair\nin a map, can be unpacked or skipped individually.\n\n\n## Notes\n\n### String and binary types in the old MessagePack spec\n\nEarly versions of msgpack didn't distinguish string and binary types.\nThe type for representing both string and binary types was named **raw**.\n\nYou can pack into and unpack from this old spec using `use_bin_type=False`\nand `raw=True` options.\n\n```pycon\n>>> import msgpack\n>>> msgpack.unpackb(msgpack.packb([b'spam', 'eggs'], use_bin_type=False), raw=True)\n[b'spam', b'eggs']\n>>> msgpack.unpackb(msgpack.packb([b'spam', 'eggs'], use_bin_type=True), raw=False)\n[b'spam', 'eggs']\n```\n\n### ext type\n\nTo use the **ext** type, pass a `msgpack.ExtType` object to the packer.\n\n```pycon\n>>> import msgpack\n>>> packed = msgpack.packb(msgpack.ExtType(42, b'xyzzy'))\n>>> msgpack.unpackb(packed)\nExtType(code=42, data='xyzzy')\n```\n\nYou can use it with `default` and `ext_hook`. See below.\n\n\n### Security\n\nWhen unpacking data received from an unreliable source, msgpack provides\ntwo security options.\n\n`max_buffer_size` (default: `100*1024*1024`) limits the internal buffer size.\nIt is also used to limit preallocated list sizes.\n\n`strict_map_key` (default: `True`) limits the type of map keys to bytes and str.\nWhile the MessagePack spec doesn't limit map key types,\nthere is a risk of a hash DoS.\nIf you need to support other types for map keys, use `strict_map_key=False`.\n\n\n### Performance tips\n\nCPython's GC starts when the number of allocated objects grows.\nThis means unpacking may trigger unnecessary GC.\nYou can use `gc.disable()` when unpacking a large message.\n\nA list is the default sequence type in Python.\nHowever, a tuple is lighter than a list.\nYou can use `use_list=False` while unpacking when performance is important.\n\n\n## Major breaking changes in the history\n\n### msgpack 0.5\n\nThe package name on PyPI was changed from `msgpack-python` to `msgpack` in 0.5.\n\nWhen upgrading from msgpack-0.4 or earlier, do `pip uninstall msgpack-python` before\n`pip install -U msgpack`.\n\n\n### msgpack 1.0\n\n* Python 2 support\n\n  * The extension module no longer supports Python 2.\n    The pure Python implementation (`msgpack.fallback`) is used for Python 2.\n  \n  * msgpack 1.0.6 drops official support of Python 2.7, as pip and\n    GitHub Action \"setup-python\" no longer supports Python 2.7.\n\n* Packer\n\n  * Packer uses `use_bin_type=True` by default.\n    Bytes are encoded in the bin type in MessagePack.\n  * The `encoding` option is removed. UTF-8 is always used.\n\n* Unpacker\n\n  * Unpacker uses `raw=False` by default. It assumes str values are valid UTF-8 strings\n    and decodes them to Python str (Unicode) objects.\n  * `encoding` option is removed.  You can use `raw=True` to support old format (e.g. unpack into bytes, not str).\n  * The default value of `max_buffer_size` is changed from 0 to 100 MiB to avoid DoS attacks.\n    You need to pass `max_buffer_size=0` if you have large but safe data.\n  * The default value of `strict_map_key` is changed to True to avoid hash DoS.\n    You need to pass `strict_map_key=False` if you have data that contain map keys\n    whose type is neither bytes nor str.\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "msgpack",
          "messagepack",
          "serializer",
          "serialization",
          "binary"
        ],
        "author_email": "Inada Naoki <songofacandy@gmail.com>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "COPYING"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Operating System :: OS Independent",
          "Topic :: File Formats",
          "Intended Audience :: Developers",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://msgpack.org/",
          "Documentation, https://msgpack-python.readthedocs.io/",
          "Repository, https://github.com/msgpack/msgpack-python/",
          "Tracker, https://github.com/msgpack/msgpack-python/issues",
          "Changelog, https://github.com/msgpack/msgpack-python/blob/main/ChangeLog.rst"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/msgpack-1.1.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "dbt-common",
        "version": "1.37.2",
        "summary": "The shared common utilities that dbt-core and adapter implementations use",
        "description": "## dbt-common\n\nThe shared common utilities for dbt-core and adapter implementations use\n\n### Releasing dbt-common\nTo release a new version of dbt-common to pypi, you'll need to: \n1. Run the [release workflow](https://github.com/dbt-labs/dbt-common/actions/workflows/release.yml) to bump the version, generate changelogs and release to pypi\n4. Bump the version of `dbt-common` in `dbt-core` and `dbt-adapters` if you're releasing a new major version or a pre-release: \n   * `dbt-core`: [setup.py](https://github.com/dbt-labs/dbt-core/blob/main/core/setup.py)\n   * `dbt-adapters`: [pyproject.toml](https://github.com/dbt-labs/dbt-adapters/blob/main/pyproject.toml)\n   * Adapter Implementations: \n     * `dbt-postgres`: [pyproject.toml](https://github.com/dbt-labs/dbt-postgres/blob/main/pyproject.toml)\n     * `dbt-snowflake`: [setup.py](https://github.com/dbt-labs/dbt-snowflake/blob/main/setup.py)\n     * `dbt-bigquery`: [setup.py](https://github.com/dbt-labs/dbt-bigquery/blob/main/setup.py)\n     * `dbt-redshift`: [setup.py](https://github.com/dbt-labs/dbt-redshift/blob/main/setup.py)\n     * `dbt-spark`: [setup.py](https://github.com/dbt-labs/dbt-spark/blob/main/setup.py)\n\n## Getting started\n\n- [Install dbt](https://docs.getdbt.com/docs/get-started/installation)\n- Read the [introduction](https://docs.getdbt.com/docs/introduction/) and [viewpoint](https://docs.getdbt.com/docs/about/viewpoint/)\n\n## Join the dbt Community\n\n- Be part of the conversation in the [dbt Community Slack](http://community.getdbt.com/)\n- Read more on the [dbt Community Discourse](https://discourse.getdbt.com)\n\n## Reporting bugs and contributing code\n\n- Want to report a bug or request a feature? Let us know and open [an issue](https://github.com/dbt-labs/dbt-common/issues/new/choose)\n- Want to help us build dbt? Check out the [Contributing Guide](https://github.com/dbt-labs/dbt-common/blob/HEAD/CONTRIBUTING.md)\n\n## Code of Conduct\n\nEveryone interacting in the dbt project's codebases, issue trackers, chat rooms, and mailing lists is expected to follow the [dbt Code of Conduct](https://community.getdbt.com/code-of-conduct).\n",
        "description_content_type": "text/markdown",
        "author_email": "dbt Labs <info@dbtlabs.com>",
        "maintainer_email": "dbt Labs <info@dbtlabs.com>",
        "license_expression": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 2 - Pre-Alpha",
          "License :: OSI Approved :: Apache Software License",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX :: Linux",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_dist": [
          "agate<1.10,>=1.7.0",
          "colorama<0.5,>=0.3.9",
          "dbt-protos<2.0.0,>=1.0.410",
          "deepdiff<9.0,>=7.0",
          "isodate<0.8,>=0.6",
          "jinja2<4,>=3.1.3",
          "jsonschema<5.0,>=4.0",
          "mashumaro[msgpack]<4.0,>=3.9",
          "pathspec<0.13,>=0.9",
          "protobuf<7.0,>=6.0",
          "python-dateutil<3.0,>=2.0",
          "requests<3.0.0",
          "typing-extensions<5.0,>=4.4",
          "check-wheel-contents; extra == 'build'",
          "twine; extra == 'build'",
          "wheel; extra == 'build'",
          "black<24.0,>=23.3; extra == 'lint'",
          "flake8; extra == 'lint'",
          "flake8-docstrings; extra == 'lint'",
          "flake8-pyproject; extra == 'lint'",
          "mypy<2.0,>=1.3; extra == 'lint'",
          "pytest<8.0,>=7.3; extra == 'lint'",
          "types-jinja2<3.0,>=2.11; extra == 'lint'",
          "types-jsonschema<5.0,>=4.17; extra == 'lint'",
          "types-protobuf<7.0,>=6.0; extra == 'lint'",
          "types-python-dateutil<3.0,>=2.8; extra == 'lint'",
          "types-pyyaml<7.0,>=6.0; extra == 'lint'",
          "types-requests; extra == 'lint'",
          "hypothesis<7.0,>=6.87; extra == 'test'",
          "pytest-cov<5.0,>=4.1; extra == 'test'",
          "pytest-mock; extra == 'test'",
          "pytest-xdist<4.0,>=3.2; extra == 'test'",
          "pytest<8.0,>=7.3; extra == 'test'"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Homepage, https://github.com/dbt-labs/dbt-common",
          "Repository, https://github.com/dbt-labs/dbt-common.git",
          "Issues, https://github.com/dbt-labs/dbt-common/issues",
          "Changelog, https://github.com/dbt-labs/dbt-common/blob/main/CHANGELOG.md"
        ],
        "provides_extra": [
          "build",
          "lint",
          "test"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/dbt_common-1.37.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "MarkupSafe",
        "version": "3.0.3",
        "dynamic": [
          "license-file"
        ],
        "summary": "Safely add untrusted strings to HTML/XML markup.",
        "description": "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/pallets/markupsafe/refs/heads/stable/docs/_static/markupsafe-name.svg\" alt=\"\" height=\"150\"></div>\n\n# MarkupSafe\n\nMarkupSafe implements a text object that escapes characters so it is\nsafe to use in HTML and XML. Characters that have special meanings are\nreplaced so that they display as the actual characters. This mitigates\ninjection attacks, meaning untrusted user input can safely be displayed\non a page.\n\n\n## Examples\n\n```pycon\n>>> from markupsafe import Markup, escape\n\n>>> # escape replaces special characters and wraps in Markup\n>>> escape(\"<script>alert(document.cookie);</script>\")\nMarkup('&lt;script&gt;alert(document.cookie);&lt;/script&gt;')\n\n>>> # wrap in Markup to mark text \"safe\" and prevent escaping\n>>> Markup(\"<strong>Hello</strong>\")\nMarkup('<strong>hello</strong>')\n\n>>> escape(Markup(\"<strong>Hello</strong>\"))\nMarkup('<strong>hello</strong>')\n\n>>> # Markup is a str subclass\n>>> # methods and operators escape their arguments\n>>> template = Markup(\"Hello <em>{name}</em>\")\n>>> template.format(name='\"World\"')\nMarkup('Hello <em>&#34;World&#34;</em>')\n```\n\n## Donate\n\nThe Pallets organization develops and supports MarkupSafe and other\npopular packages. In order to grow the community of contributors and\nusers, and allow the maintainers to devote more time to the projects,\n[please donate today][].\n\n[please donate today]: https://palletsprojects.com/donate\n\n## Contributing\n\nSee our [detailed contributing documentation][contrib] for many ways to\ncontribute, including reporting issues, requesting features, asking or answering\nquestions, and making PRs.\n\n[contrib]: https://palletsprojects.com/contributing/\n",
        "description_content_type": "text/markdown",
        "maintainer_email": "Pallets <contact@palletsprojects.com>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Topic :: Internet :: WWW/HTTP :: Dynamic Content",
          "Topic :: Text Processing :: Markup :: HTML",
          "Typing :: Typed"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Donate, https://palletsprojects.com/donate",
          "Documentation, https://markupsafe.palletsprojects.com/",
          "Changes, https://markupsafe.palletsprojects.com/page/changes/",
          "Source, https://github.com/pallets/markupsafe/",
          "Chat, https://discord.gg/pallets"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/markupsafe-3.0.3.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "jsonschema",
        "version": "4.26.0",
        "summary": "An implementation of JSON Schema validation for Python",
        "description": "==========\njsonschema\n==========\n\n|PyPI| |Pythons| |CI| |ReadTheDocs| |Precommit| |Zenodo|\n\n.. |PyPI| image:: https://img.shields.io/pypi/v/jsonschema.svg\n   :alt: PyPI version\n   :target: https://pypi.org/project/jsonschema/\n\n.. |Pythons| image:: https://img.shields.io/pypi/pyversions/jsonschema.svg\n   :alt: Supported Python versions\n   :target: https://pypi.org/project/jsonschema/\n\n.. |CI| image:: https://github.com/python-jsonschema/jsonschema/workflows/CI/badge.svg\n  :alt: Build status\n  :target: https://github.com/python-jsonschema/jsonschema/actions?query=workflow%3ACI\n\n.. |ReadTheDocs| image:: https://readthedocs.org/projects/python-jsonschema/badge/?version=stable&style=flat\n   :alt: ReadTheDocs status\n   :target: https://python-jsonschema.readthedocs.io/en/stable/\n\n.. |Precommit| image:: https://results.pre-commit.ci/badge/github/python-jsonschema/jsonschema/main.svg\n   :alt: pre-commit.ci status\n   :target: https://results.pre-commit.ci/latest/github/python-jsonschema/jsonschema/main\n\n.. |Zenodo| image:: https://zenodo.org/badge/3072629.svg\n   :alt: Zenodo DOI\n   :target: https://zenodo.org/badge/latestdoi/3072629\n\n\n``jsonschema`` is an implementation of the `JSON Schema <https://json-schema.org>`_ specification for Python.\n\n.. code:: python\n\n    >>> from jsonschema import validate\n\n    >>> # A sample schema, like what we'd get from json.load()\n    >>> schema = {\n    ...     \"type\" : \"object\",\n    ...     \"properties\" : {\n    ...         \"price\" : {\"type\" : \"number\"},\n    ...         \"name\" : {\"type\" : \"string\"},\n    ...     },\n    ... }\n\n    >>> # If no exception is raised by validate(), the instance is valid.\n    >>> validate(instance={\"name\" : \"Eggs\", \"price\" : 34.99}, schema=schema)\n\n    >>> validate(\n    ...     instance={\"name\" : \"Eggs\", \"price\" : \"Invalid\"}, schema=schema,\n    ... )                                   # doctest: +IGNORE_EXCEPTION_DETAIL\n    Traceback (most recent call last):\n        ...\n    ValidationError: 'Invalid' is not of type 'number'\n\nIt can also be used from the command line by installing `check-jsonschema <https://github.com/python-jsonschema/check-jsonschema>`_.\n\nFeatures\n--------\n\n* Full support for `Draft 2020-12 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft202012Validator>`_, `Draft 2019-09 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft201909Validator>`_, `Draft 7 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft7Validator>`_, `Draft 6 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft6Validator>`_, `Draft 4 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft4Validator>`_ and `Draft 3 <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/validators/#jsonschema.validators.Draft3Validator>`_\n\n* `Lazy validation <https://python-jsonschema.readthedocs.io/en/latest/api/jsonschema/protocols/#jsonschema.protocols.Validator.iter_errors>`_ that can iteratively report *all* validation errors.\n\n* `Programmatic querying <https://python-jsonschema.readthedocs.io/en/latest/errors/>`_ of which properties or items failed validation.\n\n\nInstallation\n------------\n\n``jsonschema`` is available on `PyPI <https://pypi.org/project/jsonschema/>`_. You can install using `pip <https://pip.pypa.io/en/stable/>`_:\n\n.. code:: bash\n\n    $ pip install jsonschema\n\n\nExtras\n======\n\nTwo extras are available when installing the package, both currently related to ``format`` validation:\n\n    * ``format``\n    * ``format-nongpl``\n\nThey can be used when installing in order to include additional dependencies, e.g.:\n\n.. code:: bash\n\n    $ pip install jsonschema'[format]'\n\nBe aware that the mere presence of these dependencies â€“ or even the specification of ``format`` checks in a schema â€“ do *not* activate format checks (as per the specification).\nPlease read the `format validation documentation <https://python-jsonschema.readthedocs.io/en/latest/validate/#validating-formats>`_ for further details.\n\nAbout\n-----\n\nI'm Julian Berman.\n\n``jsonschema`` is on `GitHub <https://github.com/python-jsonschema/jsonschema>`_.\n\nGet in touch, via GitHub or otherwise, if you've got something to contribute, it'd be most welcome!\n\nIf you feel overwhelmingly grateful, you can also `sponsor me <https://github.com/sponsors/Julian/>`_.\n\nAnd for companies who appreciate ``jsonschema`` and its continued support and growth, ``jsonschema`` is also now supportable via `TideLift <https://tidelift.com/subscription/pkg/pypi-jsonschema?utm_source=pypi-jsonschema&utm_medium=referral&utm_campaign=readme>`_.\n\n\nRelease Information\n-------------------\n\nv4.26.0\n=======\n\n* Decrease import time by delaying importing of ``urllib.request`` (#1416).\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "data validation",
          "json",
          "json schema",
          "jsonschema",
          "validation"
        ],
        "author_email": "Julian Berman <Julian+jsonschema@GrayVines.com>",
        "license_expression": "MIT",
        "license_file": [
          "COPYING"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: File Formats :: JSON",
          "Topic :: File Formats :: JSON :: JSON Schema"
        ],
        "requires_dist": [
          "attrs>=22.2.0",
          "jsonschema-specifications>=2023.03.6",
          "referencing>=0.28.4",
          "rpds-py>=0.25.0",
          "fqdn; extra == 'format'",
          "idna; extra == 'format'",
          "isoduration; extra == 'format'",
          "jsonpointer>1.13; extra == 'format'",
          "rfc3339-validator; extra == 'format'",
          "rfc3987; extra == 'format'",
          "uri-template; extra == 'format'",
          "webcolors>=1.11; extra == 'format'",
          "fqdn; extra == 'format-nongpl'",
          "idna; extra == 'format-nongpl'",
          "isoduration; extra == 'format-nongpl'",
          "jsonpointer>1.13; extra == 'format-nongpl'",
          "rfc3339-validator; extra == 'format-nongpl'",
          "rfc3986-validator>0.1.0; extra == 'format-nongpl'",
          "rfc3987-syntax>=1.1.0; extra == 'format-nongpl'",
          "uri-template; extra == 'format-nongpl'",
          "webcolors>=24.6.0; extra == 'format-nongpl'"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Homepage, https://github.com/python-jsonschema/jsonschema",
          "Documentation, https://python-jsonschema.readthedocs.io/",
          "Issues, https://github.com/python-jsonschema/jsonschema/issues/",
          "Funding, https://github.com/sponsors/Julian",
          "Tidelift, https://tidelift.com/subscription/pkg/pypi-jsonschema?utm_source=pypi-jsonschema&utm_medium=referral&utm_campaign=pypi-link",
          "Changelog, https://github.com/python-jsonschema/jsonschema/blob/main/CHANGELOG.rst",
          "Source, https://github.com/python-jsonschema/jsonschema"
        ],
        "provides_extra": [
          "format",
          "format-nongpl"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/jsonschema-4.26.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "more-itertools",
        "version": "10.8.0",
        "summary": "More routines for operating on iterables, beyond itertools",
        "description": "==============\nMore Itertools\n==============\n\n.. image:: https://readthedocs.org/projects/more-itertools/badge/?version=latest\n  :target: https://more-itertools.readthedocs.io/en/stable/\n\nPython's ``itertools`` library is a gem - you can compose elegant solutions\nfor a variety of problems with the functions it provides. In ``more-itertools``\nwe collect additional building blocks, recipes, and routines for working with\nPython iterables.\n\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Grouping               | `chunked <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.chunked>`_,                                                                               |\n|                        | `ichunked <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.ichunked>`_,                                                                             |\n|                        | `chunked_even <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.chunked_even>`_,                                                                     |\n|                        | `sliced <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.sliced>`_,                                                                                 |\n|                        | `constrained_batches <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.constrained_batches>`_,                                                       |\n|                        | `distribute <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.distribute>`_,                                                                         |\n|                        | `divide <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.divide>`_,                                                                                 |\n|                        | `split_at <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.split_at>`_,                                                                             |\n|                        | `split_before <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.split_before>`_,                                                                     |\n|                        | `split_after <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.split_after>`_,                                                                       |\n|                        | `split_into <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.split_into>`_,                                                                         |\n|                        | `split_when <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.split_when>`_,                                                                         |\n|                        | `bucket <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.bucket>`_,                                                                                 |\n|                        | `unzip <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.unzip>`_,                                                                                   |\n|                        | `batched <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.batched>`_,                                                                               |\n|                        | `grouper <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.grouper>`_,                                                                               |\n|                        | `partition <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.partition>`_,                                                                           |\n|                        | `transpose <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.transpose>`_                                                                            |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Lookahead and lookback | `spy <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.spy>`_,                                                                                       |\n|                        | `peekable <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.peekable>`_,                                                                             |\n|                        | `seekable <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.seekable>`_                                                                              |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Windowing              | `windowed <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.windowed>`_,                                                                             |\n|                        | `substrings <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.substrings>`_,                                                                         |\n|                        | `substrings_indexes <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.substrings_indexes>`_,                                                         |\n|                        | `stagger <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.stagger>`_,                                                                               |\n|                        | `windowed_complete <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.windowed_complete>`_,                                                           |\n|                        | `pairwise <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.pairwise>`_,                                                                             |\n|                        | `triplewise <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.triplewise>`_,                                                                         |\n|                        | `sliding_window <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.sliding_window>`_,                                                                 |\n|                        | `subslices <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.subslices>`_                                                                            |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Augmenting             | `count_cycle <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.count_cycle>`_,                                                                       |\n|                        | `intersperse <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.intersperse>`_,                                                                       |\n|                        | `padded <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.padded>`_,                                                                                 |\n|                        | `repeat_each <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.repeat_each>`_,                                                                       |\n|                        | `mark_ends <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.mark_ends>`_,                                                                           |\n|                        | `repeat_last <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.repeat_last>`_,                                                                       |\n|                        | `adjacent <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.adjacent>`_,                                                                             |\n|                        | `groupby_transform <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.groupby_transform>`_,                                                           |\n|                        | `pad_none <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.pad_none>`_,                                                                             |\n|                        | `ncycles <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.ncycles>`_                                                                                |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Combining              | `collapse <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.collapse>`_,                                                                             |\n|                        | `sort_together <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.sort_together>`_,                                                                   |\n|                        | `interleave <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.interleave>`_,                                                                         |\n|                        | `interleave_longest <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.interleave_longest>`_,                                                         |\n|                        | `interleave_evenly <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.interleave_evenly>`_,                                                           |\n|                        | `interleave_randomly <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.interleave_randomly>`_,                                                       |\n|                        | `zip_offset <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.zip_offset>`_,                                                                         |\n|                        | `zip_equal <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.zip_equal>`_,                                                                           |\n|                        | `zip_broadcast <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.zip_broadcast>`_,                                                                   |\n|                        | `flatten <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.flatten>`_,                                                                               |\n|                        | `roundrobin <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.roundrobin>`_,                                                                         |\n|                        | `prepend <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.prepend>`_,                                                                               |\n|                        | `value_chain <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.value_chain>`_,                                                                       |\n|                        | `partial_product <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.partial_product>`_                                                                |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Summarizing            | `ilen <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.ilen>`_,                                                                                     |\n|                        | `unique_to_each <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.unique_to_each>`_,                                                                 |\n|                        | `sample <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.sample>`_,                                                                                 |\n|                        | `consecutive_groups <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.consecutive_groups>`_,                                                         |\n|                        | `run_length <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.run_length>`_,                                                                         |\n|                        | `map_reduce <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.map_reduce>`_,                                                                         |\n|                        | `join_mappings <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.join_mappings>`_,                                                                   |\n|                        | `exactly_n <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.exactly_n>`_,                                                                           |\n|                        | `is_sorted <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.is_sorted>`_,                                                                           |\n|                        | `all_equal <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.all_equal>`_,                                                                           |\n|                        | `all_unique <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.all_unique>`_,                                                                         |\n|                        | `argmin <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.argmin>`_,                                                                                 |\n|                        | `argmax <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.argmax>`_,                                                                                 |\n|                        | `minmax <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.minmax>`_,                                                                                 |\n|                        | `first_true <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.first_true>`_,                                                                         |\n|                        | `quantify <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.quantify>`_,                                                                             |\n|                        | `iequals <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.iequals>`_                                                                                |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Selecting              | `islice_extended <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.islice_extended>`_,                                                               |\n|                        | `first <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.first>`_,                                                                                   |\n|                        | `last <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.last>`_,                                                                                     |\n|                        | `one <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.one>`_,                                                                                       |\n|                        | `only <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.only>`_,                                                                                     |\n|                        | `strictly_n <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.strictly_n>`_,                                                                         |\n|                        | `strip <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.strip>`_,                                                                                   |\n|                        | `lstrip <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.lstrip>`_,                                                                                 |\n|                        | `rstrip <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.rstrip>`_,                                                                                 |\n|                        | `filter_except <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.filter_except>`_,                                                                   |\n|                        | `map_except <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.map_except>`_,                                                                         |\n|                        | `filter_map <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.filter_map>`_,                                                                         |\n|                        | `iter_suppress <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.iter_suppress>`_,                                                                   |\n|                        | `nth_or_last <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.nth_or_last>`_,                                                                       |\n|                        | `extract <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.extract>`_,                                                                               |\n|                        | `unique_in_window <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.unique_in_window>`_,                                                             |\n|                        | `before_and_after <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.before_and_after>`_,                                                             |\n|                        | `nth <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.nth>`_,                                                                                       |\n|                        | `take <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.take>`_,                                                                                     |\n|                        | `tail <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.tail>`_,                                                                                     |\n|                        | `unique_everseen <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.unique_everseen>`_,                                                               |\n|                        | `unique_justseen <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.unique_justseen>`_,                                                               |\n|                        | `unique <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.unique>`_,                                                                                 |\n|                        | `duplicates_everseen <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.duplicates_everseen>`_,                                                       |\n|                        | `duplicates_justseen <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.duplicates_justseen>`_,                                                       |\n|                        | `classify_unique <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.classify_unique>`_,                                                               |\n|                        | `longest_common_prefix <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.longest_common_prefix>`_,                                                   |\n|                        | `takewhile_inclusive <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.takewhile_inclusive>`_                                                        |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Math                   | `dft <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.dft>`_,                                                                                       |\n|                        | `idft <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.idft>`_,                                                                                     |\n|                        | `convolve <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.convolve>`_,                                                                             |\n|                        | `dotproduct <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.dotproduct>`_,                                                                         |\n|                        | `matmul <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.matmul>`_,                                                                                 |\n|                        | `polynomial_from_roots <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.polynomial_from_roots>`_,                                                   |\n|                        | `polynomial_derivative <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.polynomial_derivative>`_,                                                   |\n|                        | `polynomial_eval <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.polynomial_eval>`_,                                                               |\n|                        | `sum_of_squares <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.sum_of_squares>`_,                                                                 |\n|                        | `running_median <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.running_median>`_,                                                                 |\n|                        | `totient <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.totient>`_                                                                                |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Integer math           | `factor <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.factor>`_,                                                                                 |\n|                        | `is_prime <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.is_prime>`_,                                                                             |\n|                        | `multinomial <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.multinomial>`_,                                                                       |\n|                        | `nth_prime <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.nth_prime>`_,                                                                           |\n|                        | `sieve <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.sieve>`_                                                                                    |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Combinatorics          | `circular_shifts <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.circular_shifts>`_,                                                               |\n|                        | `derangements <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.derangements>`_,                                                                     |\n|                        | `gray_product  <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.gray_product>`_,                                                                    |\n|                        | `outer_product  <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.outer_product>`_,                                                                  |\n|                        | `partitions <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.partitions>`_,                                                                         |\n|                        | `set_partitions <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.set_partitions>`_,                                                                 |\n|                        | `powerset <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.powerset>`_,                                                                             |\n|                        | `powerset_of_sets <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.powerset_of_sets>`_                                                              |\n|                        +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                        | `distinct_combinations <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.distinct_combinations>`_,                                                   |\n|                        | `distinct_permutations <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.distinct_permutations>`_                                                    |\n|                        +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                        | `combination_index <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.combination_index>`_,                                                           |\n|                        | `combination_with_replacement_index <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.combination_with_replacement_index>`_,                         |\n|                        | `permutation_index <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.permutation_index>`_,                                                           |\n|                        | `product_index <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.product_index>`_                                                                    |\n|                        +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                        | `nth_combination <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.nth_combination>`_,                                                               |\n|                        | `nth_combination_with_replacement <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.nth_combination_with_replacement>`_,                             |\n|                        | `nth_permutation <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.nth_permutation>`_,                                                               |\n|                        | `nth_product <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.nth_product>`_                                                                        |\n|                        +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                        | `random_combination <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.random_combination>`_,                                                         |\n|                        | `random_combination_with_replacement <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.random_combination_with_replacement>`_,                       |\n|                        | `random_permutation <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.random_permutation>`_,                                                         |\n|                        | `random_product <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.random_product>`_                                                                  |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Wrapping               | `always_iterable <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.always_iterable>`_,                                                               |\n|                        | `always_reversible <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.always_reversible>`_,                                                           |\n|                        | `countable <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.countable>`_,                                                                           |\n|                        | `consumer <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.consumer>`_,                                                                             |\n|                        | `with_iter <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.with_iter>`_,                                                                           |\n|                        | `iter_except <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.iter_except>`_                                                                        |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Others                 | `locate <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.locate>`_,                                                                                 |\n|                        | `rlocate <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.rlocate>`_,                                                                               |\n|                        | `replace <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.replace>`_,                                                                               |\n|                        | `numeric_range <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.numeric_range>`_,                                                                   |\n|                        | `side_effect <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.side_effect>`_,                                                                       |\n|                        | `iterate <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.iterate>`_,                                                                               |\n|                        | `loops <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.loops>`_,                                                                                   |\n|                        | `difference <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.difference>`_,                                                                         |\n|                        | `make_decorator <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.make_decorator>`_,                                                                 |\n|                        | `SequenceView <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.SequenceView>`_,                                                                     |\n|                        | `time_limited <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.time_limited>`_,                                                                     |\n|                        | `map_if <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.map_if>`_,                                                                                 |\n|                        | `iter_index <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.iter_index>`_,                                                                         |\n|                        | `consume <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.consume>`_,                                                                               |\n|                        | `tabulate <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.tabulate>`_,                                                                             |\n|                        | `repeatfunc <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.repeatfunc>`_,                                                                         |\n|                        | `reshape <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.reshape>`_,                                                                               |\n|                        | `doublestarmap <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.doublestarmap>`_                                                                    |\n+------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n\nGetting started\n===============\n\nTo get started, install the library with `pip <https://pip.pypa.io/en/stable/>`_:\n\n.. code-block:: shell\n\n    pip install more-itertools\n\nThe recipes from the `itertools docs <https://docs.python.org/3/library/itertools.html#itertools-recipes>`_\nare included in the top-level package:\n\n.. code-block:: python\n\n    >>> from more_itertools import flatten\n    >>> iterable = [(0, 1), (2, 3)]\n    >>> list(flatten(iterable))\n    [0, 1, 2, 3]\n\nSeveral new recipes are available as well:\n\n.. code-block:: python\n\n    >>> from more_itertools import chunked\n    >>> iterable = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n    >>> list(chunked(iterable, 3))\n    [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n\n    >>> from more_itertools import spy\n    >>> iterable = (x * x for x in range(1, 6))\n    >>> head, iterable = spy(iterable, n=3)\n    >>> list(head)\n    [1, 4, 9]\n    >>> list(iterable)\n    [1, 4, 9, 16, 25]\n\n\n\nFor the full listing of functions, see the `API documentation <https://more-itertools.readthedocs.io/en/stable/api.html>`_.\n\n\nLinks elsewhere\n===============\n\nBlog posts about ``more-itertools``:\n\n* `Yo, I heard you like decorators <https://www.bbayles.com/index/decorator_factory>`__\n* `Tour of Python Itertools <https://martinheinz.dev/blog/16>`__ (`Alternate <https://dev.to/martinheinz/tour-of-python-itertools-4122>`__)\n* `Real-World Python More Itertools <https://python.plainenglish.io/real-world-more-itertools-gideons-blog-a3901c607550>`_\n\n\nDevelopment\n===========\n\n``more-itertools`` is maintained by `@erikrose <https://github.com/erikrose>`_\nand `@bbayles <https://github.com/bbayles>`_, with help from `many others <https://github.com/more-itertools/more-itertools/graphs/contributors>`_.\nIf you have a problem or suggestion, please file a bug or pull request in this\nrepository. Thanks for contributing!\n\n\nVersion History\n===============\n\nThe version history can be found in `documentation <https://more-itertools.readthedocs.io/en/stable/versions.html>`_.\n\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "itertools",
          "iterator",
          "iteration",
          "filter",
          "peek",
          "peekable",
          "chunk",
          "chunked"
        ],
        "author_email": "Erik Rose <erikrose@grinchcentral.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Documentation, https://more-itertools.readthedocs.io/en/stable/",
          "Homepage, https://github.com/more-itertools/more-itertools"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/more_itertools-10.8.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "zipp",
        "version": "3.23.0",
        "dynamic": [
          "license-file"
        ],
        "summary": "Backport of pathlib-compatible object wrapper for zip files",
        "description": ".. image:: https://img.shields.io/pypi/v/zipp.svg\n   :target: https://pypi.org/project/zipp\n\n.. image:: https://img.shields.io/pypi/pyversions/zipp.svg\n\n.. image:: https://github.com/jaraco/zipp/actions/workflows/main.yml/badge.svg\n   :target: https://github.com/jaraco/zipp/actions?query=workflow%3A%22tests%22\n   :alt: tests\n\n.. image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json\n    :target: https://github.com/astral-sh/ruff\n    :alt: Ruff\n\n.. image:: https://readthedocs.org/projects/zipp/badge/?version=latest\n..    :target: https://zipp.readthedocs.io/en/latest/?badge=latest\n\n.. image:: https://img.shields.io/badge/skeleton-2025-informational\n   :target: https://blog.jaraco.com/skeleton\n\n.. image:: https://tidelift.com/badges/package/pypi/zipp\n   :target: https://tidelift.com/subscription/pkg/pypi-zipp?utm_source=pypi-zipp&utm_medium=readme\n\n\nA pathlib-compatible Zipfile object wrapper. Official backport of the standard library\n`Path object <https://docs.python.org/3.8/library/zipfile.html#path-objects>`_.\n\n\nCompatibility\n=============\n\nNew features are introduced in this third-party library and later merged\ninto CPython. The following table indicates which versions of this library\nwere contributed to different versions in the standard library:\n\n.. list-table::\n   :header-rows: 1\n\n   * - zipp\n     - stdlib\n   * - 3.18\n     - 3.13\n   * - 3.16\n     - 3.12\n   * - 3.5\n     - 3.11\n   * - 3.2\n     - 3.10\n   * - 3.3 ??\n     - 3.9\n   * - 1.0\n     - 3.8\n\n\nUsage\n=====\n\nUse ``zipp.Path`` in place of ``zipfile.Path`` on any Python.\n\nFor Enterprise\n==============\n\nAvailable as part of the Tidelift Subscription.\n\nThis project and the maintainers of thousands of other packages are working with Tidelift to deliver one enterprise subscription that covers all of the open source you use.\n\n`Learn more <https://tidelift.com/subscription/pkg/pypi-zipp?utm_source=pypi-zipp&utm_medium=referral&utm_campaign=github>`_.\n",
        "description_content_type": "text/x-rst",
        "author_email": "\"Jason R. Coombs\" <jaraco@jaraco.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only"
        ],
        "requires_dist": [
          "pytest!=8.1.*,>=6; extra == \"test\"",
          "jaraco.itertools; extra == \"test\"",
          "jaraco.functools; extra == \"test\"",
          "more_itertools; extra == \"test\"",
          "big-O; extra == \"test\"",
          "pytest-ignore-flaky; extra == \"test\"",
          "jaraco.test; extra == \"test\"",
          "sphinx>=3.5; extra == \"doc\"",
          "jaraco.packaging>=9.3; extra == \"doc\"",
          "rst.linker>=1.9; extra == \"doc\"",
          "furo; extra == \"doc\"",
          "sphinx-lint; extra == \"doc\"",
          "jaraco.tidelift>=1.4; extra == \"doc\"",
          "pytest-checkdocs>=2.4; extra == \"check\"",
          "pytest-ruff>=0.2.1; sys_platform != \"cygwin\" and extra == \"check\"",
          "pytest-cov; extra == \"cover\"",
          "pytest-enabler>=2.2; extra == \"enabler\"",
          "pytest-mypy; extra == \"type\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Source, https://github.com/jaraco/zipp"
        ],
        "provides_extra": [
          "test",
          "doc",
          "check",
          "cover",
          "enabler",
          "type"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/zipp-3.23.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "pathspec",
        "version": "0.12.1",
        "summary": "Utility library for gitignore style pattern matching of file paths.",
        "description": "\nPathSpec\n========\n\n*pathspec* is a utility library for pattern matching of file paths. So\nfar this only includes Git's wildmatch pattern matching which itself is\nderived from Rsync's wildmatch. Git uses wildmatch for its `gitignore`_\nfiles.\n\n.. _`gitignore`: http://git-scm.com/docs/gitignore\n\n\nTutorial\n--------\n\nSay you have a \"Projects\" directory and you want to back it up, but only\ncertain files, and ignore others depending on certain conditions::\n\n\t>>> import pathspec\n\t>>> # The gitignore-style patterns for files to select, but we're including\n\t>>> # instead of ignoring.\n\t>>> spec_text = \"\"\"\n\t...\n\t... # This is a comment because the line begins with a hash: \"#\"\n\t...\n\t... # Include several project directories (and all descendants) relative to\n\t... # the current directory. To reference a directory you must end with a\n\t... # slash: \"/\"\n\t... /project-a/\n\t... /project-b/\n\t... /project-c/\n\t...\n\t... # Patterns can be negated by prefixing with exclamation mark: \"!\"\n\t...\n\t... # Ignore temporary files beginning or ending with \"~\" and ending with\n\t... # \".swp\".\n\t... !~*\n\t... !*~\n\t... !*.swp\n\t...\n\t... # These are python projects so ignore compiled python files from\n\t... # testing.\n\t... !*.pyc\n\t...\n\t... # Ignore the build directories but only directly under the project\n\t... # directories.\n\t... !/*/build/\n\t...\n\t... \"\"\"\n\nWe want to use the ``GitWildMatchPattern`` class to compile our patterns. The\n``PathSpec`` class provides an interface around pattern implementations::\n\n\t>>> spec = pathspec.PathSpec.from_lines(pathspec.patterns.GitWildMatchPattern, spec_text.splitlines())\n\nThat may be a mouthful but it allows for additional patterns to be implemented\nin the future without them having to deal with anything but matching the paths\nsent to them. ``GitWildMatchPattern`` is the implementation of the actual\npattern which internally gets converted into a regular expression. ``PathSpec``\nis a simple wrapper around a list of compiled patterns.\n\nTo make things simpler, we can use the registered name for a pattern class\ninstead of always having to provide a reference to the class itself. The\n``GitWildMatchPattern`` class is registered as **gitwildmatch**::\n\n\t>>> spec = pathspec.PathSpec.from_lines('gitwildmatch', spec_text.splitlines())\n\nIf we wanted to manually compile the patterns we can just do the following::\n\n\t>>> patterns = map(pathspec.patterns.GitWildMatchPattern, spec_text.splitlines())\n\t>>> spec = PathSpec(patterns)\n\n``PathSpec.from_lines()`` is simply a class method which does just that.\n\nIf you want to load the patterns from file, you can pass the file instance\ndirectly as well::\n\n\t>>> with open('patterns.list', 'r') as fh:\n\t>>>     spec = pathspec.PathSpec.from_lines('gitwildmatch', fh)\n\nYou can perform matching on a whole directory tree with::\n\n\t>>> matches = spec.match_tree('path/to/directory')\n\nOr you can perform matching on a specific set of file paths with::\n\n\t>>> matches = spec.match_files(file_paths)\n\nOr check to see if an individual file matches::\n\n\t>>> is_matched = spec.match_file(file_path)\n\nThere is a specialized class, ``pathspec.GitIgnoreSpec``, which more closely\nimplements the behavior of **gitignore**. This uses ``GitWildMatchPattern``\npattern by default and handles some edge cases differently from the generic\n``PathSpec`` class. ``GitIgnoreSpec`` can be used without specifying the pattern\nfactory::\n\n\t>>> spec = pathspec.GitIgnoreSpec.from_lines(spec_text.splitlines())\n\n\nLicense\n-------\n\n*pathspec* is licensed under the `Mozilla Public License Version 2.0`_. See\n`LICENSE`_ or the `FAQ`_ for more information.\n\nIn summary, you may use *pathspec* with any closed or open source project\nwithout affecting the license of the larger work so long as you:\n\n- give credit where credit is due,\n\n- and release any custom changes made to *pathspec*.\n\n.. _`Mozilla Public License Version 2.0`: http://www.mozilla.org/MPL/2.0\n.. _`LICENSE`: LICENSE\n.. _`FAQ`: http://www.mozilla.org/MPL/2.0/FAQ.html\n\n\nSource\n------\n\nThe source code for *pathspec* is available from the GitHub repo\n`cpburnz/python-pathspec`_.\n\n.. _`cpburnz/python-pathspec`: https://github.com/cpburnz/python-pathspec\n\n\nInstallation\n------------\n\n*pathspec* is available for install through `PyPI`_::\n\n\tpip install pathspec\n\n*pathspec* can also be built from source. The following packages will be\nrequired:\n\n- `build`_ (>=0.6.0)\n\n*pathspec* can then be built and installed with::\n\n\tpython -m build\n\tpip install dist/pathspec-*-py3-none-any.whl\n\n.. _`PyPI`: http://pypi.python.org/pypi/pathspec\n.. _`build`: https://pypi.org/project/build/\n\n\nDocumentation\n-------------\n\nDocumentation for *pathspec* is available on `Read the Docs`_.\n\n.. _`Read the Docs`: https://python-path-specification.readthedocs.io\n\n\nOther Languages\n---------------\n\nThe related project `pathspec-ruby`_ (by *highb*) provides a similar library as\na `Ruby gem`_.\n\n.. _`pathspec-ruby`: https://github.com/highb/pathspec-ruby\n.. _`Ruby gem`: https://rubygems.org/gems/pathspec\n\n\n\nChange History\n==============\n\n\n0.12.1 (2023-12-10)\n-------------------\n\nBug fixes:\n\n- `Issue #84`_: PathSpec.match_file() returns None since 0.12.0.\n\n\n.. _`Issue #84`: https://github.com/cpburnz/python-pathspec/issues/84\n\n\n0.12.0 (2023-12-09)\n-------------------\n\nMajor changes:\n\n- Dropped support of EOL Python 3.7. See `Pull #82`_.\n\n\nAPI changes:\n\n- Signature of protected method `pathspec.pathspec.PathSpec._match_file()` (with a leading underscore) has been changed from `def _match_file(patterns: Iterable[Pattern], file: str) -> bool` to `def _match_file(patterns: Iterable[Tuple[int, Pattern]], file: str) -> Tuple[Optional[bool], Optional[int]]`.\n\nNew features:\n\n- Added `pathspec.pathspec.PathSpec.check_*()` methods. These methods behave similarly to `.match_*()` but return additional information in the `pathspec.util.CheckResult` objects (e.g., `CheckResult.index` indicates the index of the last pattern that matched the file).\n- Added `pathspec.pattern.RegexPattern.pattern` attribute which stores the original, uncompiled pattern.\n\nBug fixes:\n\n- `Issue #81`_: GitIgnoreSpec behaviors differ from git.\n- `Pull #83`_: Fix ReadTheDocs builds.\n\nImprovements:\n\n- Mark Python 3.12 as supported. See `Pull #82`_.\n- Improve test debugging.\n- Improve type hint on *on_error* parameter on `pathspec.pathspec.PathSpec.match_tree_entries()`.\n- Improve type hint on *on_error* parameter on `pathspec.util.iter_tree_entries()`.\n\n\n.. _`Issue #81`: https://github.com/cpburnz/python-pathspec/issues/81\n.. _`Pull #82`: https://github.com/cpburnz/python-pathspec/pull/82\n.. _`Pull #83`: https://github.com/cpburnz/python-pathspec/pull/83\n\n\n0.11.2 (2023-07-28)\n-------------------\n\nNew features:\n\n- `Issue #80`_: match_files with negated path spec. `pathspec.PathSpec.match_*()` now have a `negate` parameter to make using *.gitignore* logic easier and more efficient.\n\nBug fixes:\n\n- `Pull #76`_: Add edge case: patterns that end with an escaped space\n- `Issue #77`_/`Pull #78`_: Negate with caret symbol as with the exclamation mark.\n\n\n.. _`Pull #76`: https://github.com/cpburnz/python-pathspec/pull/76\n.. _`Issue #77`: https://github.com/cpburnz/python-pathspec/issues/77\n.. _`Pull #78`: https://github.com/cpburnz/python-pathspec/pull/78/\n.. _`Issue #80`: https://github.com/cpburnz/python-pathspec/issues/80\n\n\n0.11.1 (2023-03-14)\n-------------------\n\nBug fixes:\n\n- `Issue #74`_: Include directory should override exclude file.\n\nImprovements:\n\n- `Pull #75`_: Fix partially unknown PathLike type.\n- Convert `os.PathLike` to a string properly using `os.fspath`.\n\n\n.. _`Issue #74`: https://github.com/cpburnz/python-pathspec/issues/74\n.. _`Pull #75`: https://github.com/cpburnz/python-pathspec/pull/75\n\n\n0.11.0 (2023-01-24)\n-------------------\n\nMajor changes:\n\n- Changed build backend to `flit_core.buildapi`_ from `setuptools.build_meta`_. Building with `setuptools` through `setup.py` is still supported for distributions that need it. See `Issue #72`_.\n\nImprovements:\n\n- `Issue #72`_/`Pull #73`_: Please consider switching the build-system to flit_core to ease setuptools bootstrap.\n\n\n.. _`flit_core.buildapi`: https://flit.pypa.io/en/latest/index.html\n.. _`Issue #72`: https://github.com/cpburnz/python-pathspec/issues/72\n.. _`Pull #73`: https://github.com/cpburnz/python-pathspec/pull/73\n\n\n0.10.3 (2022-12-09)\n-------------------\n\nNew features:\n\n- Added utility function `pathspec.util.append_dir_sep()` to aid in distinguishing between directories and files on the file-system. See `Issue #65`_.\n\nBug fixes:\n\n- `Issue #66`_/`Pull #67`_: Package not marked as py.typed.\n- `Issue #68`_: Exports are considered private.\n- `Issue #70`_/`Pull #71`_: 'Self' string literal type is Unknown in pyright.\n\nImprovements:\n\n- `Issue #65`_: Checking directories via match_file() does not work on Path objects.\n\n\n.. _`Issue #65`: https://github.com/cpburnz/python-pathspec/issues/65\n.. _`Issue #66`: https://github.com/cpburnz/python-pathspec/issues/66\n.. _`Pull #67`: https://github.com/cpburnz/python-pathspec/pull/67\n.. _`Issue #68`: https://github.com/cpburnz/python-pathspec/issues/68\n.. _`Issue #70`: https://github.com/cpburnz/python-pathspec/issues/70\n.. _`Pull #71`: https://github.com/cpburnz/python-pathspec/pull/71\n\n\n0.10.2 (2022-11-12)\n-------------------\n\nBug fixes:\n\n- Fix failing tests on Windows.\n- Type hint on *root* parameter on `pathspec.pathspec.PathSpec.match_tree_entries()`.\n- Type hint on *root* parameter on `pathspec.pathspec.PathSpec.match_tree_files()`.\n- Type hint on *root* parameter on `pathspec.util.iter_tree_entries()`.\n- Type hint on *root* parameter on `pathspec.util.iter_tree_files()`.\n- `Issue #64`_: IndexError with my .gitignore file when trying to build a Python package.\n\nImprovements:\n\n- `Pull #58`_: CI: add GitHub Actions test workflow.\n\n\n.. _`Pull #58`: https://github.com/cpburnz/python-pathspec/pull/58\n.. _`Issue #64`: https://github.com/cpburnz/python-pathspec/issues/64\n\n\n0.10.1 (2022-09-02)\n-------------------\n\nBug fixes:\n\n- Fix documentation on `pathspec.pattern.RegexPattern.match_file()`.\n- `Pull #60`_: Remove redundant wheel dep from pyproject.toml.\n- `Issue #61`_: Dist failure for Fedora, CentOS, EPEL.\n- `Issue #62`_: Since version 0.10.0 pure wildcard does not work in some cases.\n\nImprovements:\n\n- Restore support for legacy installations using `setup.py`. See `Issue #61`_.\n\n\n.. _`Pull #60`: https://github.com/cpburnz/python-pathspec/pull/60\n.. _`Issue #61`: https://github.com/cpburnz/python-pathspec/issues/61\n.. _`Issue #62`: https://github.com/cpburnz/python-pathspec/issues/62\n\n\n0.10.0 (2022-08-30)\n-------------------\n\nMajor changes:\n\n- Dropped support of EOL Python 2.7, 3.5, 3.6. See `Issue #47`_.\n- The *gitwildmatch* pattern `dir/*` is now handled the same as `dir/`. This means `dir/*` will now match all descendants rather than only direct children. See `Issue #19`_.\n- Added `pathspec.GitIgnoreSpec` class (see new features).\n- Changed build system to `pyproject.toml`_ and build backend to `setuptools.build_meta`_ which may have unforeseen consequences.\n- Renamed GitHub project from `python-path-specification`_ to `python-pathspec`_. See `Issue #35`_.\n\nAPI changes:\n\n- Deprecated: `pathspec.util.match_files()` is an old function no longer used.\n- Deprecated: `pathspec.match_files()` is an old function no longer used.\n- Deprecated: `pathspec.util.normalize_files()` is no longer used.\n- Deprecated: `pathspec.util.iter_tree()` is an alias for `pathspec.util.iter_tree_files()`.\n- Deprecated: `pathspec.iter_tree()` is an alias for `pathspec.util.iter_tree_files()`.\n-\tDeprecated: `pathspec.pattern.Pattern.match()` is no longer used. Use or implement\n\t`pathspec.pattern.Pattern.match_file()`.\n\nNew features:\n\n- Added class `pathspec.gitignore.GitIgnoreSpec` (with alias `pathspec.GitIgnoreSpec`) to implement *gitignore* behavior not possible with standard `PathSpec` class. The particular *gitignore* behavior implemented is prioritizing patterns matching the file directly over matching an ancestor directory.\n\nBug fixes:\n\n- `Issue #19`_: Files inside an ignored sub-directory are not matched.\n- `Issue #41`_: Incorrectly (?) matches files inside directories that do match.\n- `Pull #51`_: Refactor deprecated unittest aliases for Python 3.11 compatibility.\n- `Issue #53`_: Symlink pathspec_meta.py breaks Windows.\n- `Issue #54`_: test_util.py uses os.symlink which can fail on Windows.\n- `Issue #55`_: Backslashes at start of pattern not handled correctly.\n- `Pull #56`_: pyproject.toml: include subpackages in setuptools config\n- `Issue #57`_: `!` doesn't exclude files in directories if the pattern doesn't have a trailing slash.\n\nImprovements:\n\n- Support Python 3.10, 3.11.\n- Modernize code to Python 3.7.\n- `Issue #52`_: match_files() is not a pure generator function, and it impacts tree_*() gravely.\n\n\n.. _`python-path-specification`: https://github.com/cpburnz/python-path-specification\n.. _`python-pathspec`: https://github.com/cpburnz/python-pathspec\n.. _`pyproject.toml`: https://pip.pypa.io/en/stable/reference/build-system/pyproject-toml/\n.. _`setuptools.build_meta`: https://setuptools.pypa.io/en/latest/build_meta.html\n.. _`Issue #19`: https://github.com/cpburnz/python-pathspec/issues/19\n.. _`Issue #35`: https://github.com/cpburnz/python-pathspec/issues/35\n.. _`Issue #41`: https://github.com/cpburnz/python-pathspec/issues/41\n.. _`Issue #47`: https://github.com/cpburnz/python-pathspec/issues/47\n.. _`Pull #51`: https://github.com/cpburnz/python-pathspec/pull/51\n.. _`Issue #52`: https://github.com/cpburnz/python-pathspec/issues/52\n.. _`Issue #53`: https://github.com/cpburnz/python-pathspec/issues/53\n.. _`Issue #54`: https://github.com/cpburnz/python-pathspec/issues/54\n.. _`Issue #55`: https://github.com/cpburnz/python-pathspec/issues/55\n.. _`Pull #56`: https://github.com/cpburnz/python-pathspec/pull/56\n.. _`Issue #57`: https://github.com/cpburnz/python-pathspec/issues/57\n\n\n0.9.0 (2021-07-17)\n------------------\n\n- `Issue #44`_/`Pull #50`_: Raise `GitWildMatchPatternError` for invalid git patterns.\n- `Pull #45`_: Fix for duplicate leading double-asterisk, and edge cases.\n- `Issue #46`_: Fix matching absolute paths.\n- API change: `util.normalize_files()` now returns a `Dict[str, List[pathlike]]` instead of a `Dict[str, pathlike]`.\n- Added type hinting.\n\n.. _`Issue #44`: https://github.com/cpburnz/python-pathspec/issues/44\n.. _`Pull #45`: https://github.com/cpburnz/python-pathspec/pull/45\n.. _`Issue #46`: https://github.com/cpburnz/python-pathspec/issues/46\n.. _`Pull #50`: https://github.com/cpburnz/python-pathspec/pull/50\n\n\n0.8.1 (2020-11-07)\n------------------\n\n- `Pull #43`_: Add support for addition operator.\n\n.. _`Pull #43`: https://github.com/cpburnz/python-pathspec/pull/43\n\n\n0.8.0 (2020-04-09)\n------------------\n\n- `Issue #30`_: Expose what patterns matched paths. Added `util.detailed_match_files()`.\n- `Issue #31`_: `match_tree()` doesn't return symlinks.\n- `Issue #34`_: Support `pathlib.Path`\\ s.\n- Add `PathSpec.match_tree_entries` and `util.iter_tree_entries()` to support directories and symlinks.\n- API change: `match_tree()` has been renamed to `match_tree_files()`. The old name `match_tree()` is still available as an alias.\n- API change: `match_tree_files()` now returns symlinks. This is a bug fix but it will change the returned results.\n\n.. _`Issue #30`: https://github.com/cpburnz/python-pathspec/issues/30\n.. _`Issue #31`: https://github.com/cpburnz/python-pathspec/issues/31\n.. _`Issue #34`: https://github.com/cpburnz/python-pathspec/issues/34\n\n\n0.7.0 (2019-12-27)\n------------------\n\n- `Pull #28`_: Add support for Python 3.8, and drop Python 3.4.\n- `Pull #29`_: Publish bdist wheel.\n\n.. _`Pull #28`: https://github.com/cpburnz/python-pathspec/pull/28\n.. _`Pull #29`: https://github.com/cpburnz/python-pathspec/pull/29\n\n\n0.6.0 (2019-10-03)\n------------------\n\n- `Pull #24`_: Drop support for Python 2.6, 3.2, and 3.3.\n- `Pull #25`_: Update README.rst.\n- `Pull #26`_: Method to escape gitwildmatch.\n\n.. _`Pull #24`: https://github.com/cpburnz/python-pathspec/pull/24\n.. _`Pull #25`: https://github.com/cpburnz/python-pathspec/pull/25\n.. _`Pull #26`: https://github.com/cpburnz/python-pathspec/pull/26\n\n\n0.5.9 (2018-09-15)\n------------------\n\n- Fixed file system error handling.\n\n\n0.5.8 (2018-09-15)\n------------------\n\n- Improved type checking.\n- Created scripts to test Python 2.6 because Tox removed support for it.\n- Improved byte string handling in Python 3.\n- `Issue #22`_: Handle dangling symlinks.\n\n.. _`Issue #22`: https://github.com/cpburnz/python-pathspec/issues/22\n\n\n0.5.7 (2018-08-14)\n------------------\n\n- `Issue #21`_: Fix collections deprecation warning.\n\n.. _`Issue #21`: https://github.com/cpburnz/python-pathspec/issues/21\n\n\n0.5.6 (2018-04-06)\n------------------\n\n- Improved unit tests.\n- Improved type checking.\n- `Issue #20`_: Support current directory prefix.\n\n.. _`Issue #20`: https://github.com/cpburnz/python-pathspec/issues/20\n\n\n0.5.5 (2017-09-09)\n------------------\n\n- Add documentation link to README.\n\n\n0.5.4 (2017-09-09)\n------------------\n\n- `Pull #17`_: Add link to Ruby implementation of *pathspec*.\n- Add sphinx documentation.\n\n.. _`Pull #17`: https://github.com/cpburnz/python-pathspec/pull/17\n\n\n0.5.3 (2017-07-01)\n------------------\n\n- `Issue #14`_: Fix byte strings for Python 3.\n- `Pull #15`_: Include \"LICENSE\" in source package.\n- `Issue #16`_: Support Python 2.6.\n\n.. _`Issue #14`: https://github.com/cpburnz/python-pathspec/issues/14\n.. _`Pull #15`: https://github.com/cpburnz/python-pathspec/pull/15\n.. _`Issue #16`: https://github.com/cpburnz/python-pathspec/issues/16\n\n\n0.5.2 (2017-04-04)\n------------------\n\n- Fixed change log.\n\n\n0.5.1 (2017-04-04)\n------------------\n\n- `Pull #13`_: Add equality methods to `PathSpec` and `RegexPattern`.\n\n.. _`Pull #13`: https://github.com/cpburnz/python-pathspec/pull/13\n\n\n0.5.0 (2016-08-22)\n------------------\n\n- `Issue #12`_: Add `PathSpec.match_file()`.\n- Renamed `gitignore.GitIgnorePattern` to `patterns.gitwildmatch.GitWildMatchPattern`.\n- Deprecated `gitignore.GitIgnorePattern`.\n\n.. _`Issue #12`: https://github.com/cpburnz/python-pathspec/issues/12\n\n\n0.4.0 (2016-07-15)\n------------------\n\n- `Issue #11`_: Support converting patterns into regular expressions without compiling them.\n- API change: Subclasses of `RegexPattern` should implement `pattern_to_regex()`.\n\n.. _`Issue #11`: https://github.com/cpburnz/python-pathspec/issues/11\n\n\n0.3.4 (2015-08-24)\n------------------\n\n- `Pull #7`_: Fixed non-recursive links.\n- `Pull #8`_: Fixed edge cases in gitignore patterns.\n- `Pull #9`_: Fixed minor usage documentation.\n- Fixed recursion detection.\n- Fixed trivial incompatibility with Python 3.2.\n\n.. _`Pull #7`: https://github.com/cpburnz/python-pathspec/pull/7\n.. _`Pull #8`: https://github.com/cpburnz/python-pathspec/pull/8\n.. _`Pull #9`: https://github.com/cpburnz/python-pathspec/pull/9\n\n\n0.3.3 (2014-11-21)\n------------------\n\n- Improved documentation.\n\n\n0.3.2 (2014-11-08)\n------------------\n\n- `Pull #5`_: Use tox for testing.\n- `Issue #6`_: Fixed matching Windows paths.\n- Improved documentation.\n- API change: `spec.match_tree()` and `spec.match_files()` now return iterators instead of sets.\n\n.. _`Pull #5`: https://github.com/cpburnz/python-pathspec/pull/5\n.. _`Issue #6`: https://github.com/cpburnz/python-pathspec/issues/6\n\n\n0.3.1 (2014-09-17)\n------------------\n\n- Updated README.\n\n\n0.3.0 (2014-09-17)\n------------------\n\n- `Pull #3`_: Fixed trailing slash in gitignore patterns.\n- `Pull #4`_: Fixed test for trailing slash in gitignore patterns.\n- Added registered patterns.\n\n.. _`Pull #3`: https://github.com/cpburnz/python-pathspec/pull/3\n.. _`Pull #4`: https://github.com/cpburnz/python-pathspec/pull/4\n\n\n0.2.2 (2013-12-17)\n------------------\n\n- Fixed setup.py.\n\n\n0.2.1 (2013-12-17)\n------------------\n\n- Added tests.\n- Fixed comment gitignore patterns.\n- Fixed relative path gitignore patterns.\n\n\n0.2.0 (2013-12-07)\n------------------\n\n- Initial release.\n\n",
        "description_content_type": "text/x-rst",
        "author_email": "\"Caleb P. Burns\" <cpburnz@gmail.com>",
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Utilities"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://python-path-specification.readthedocs.io/en/latest/index.html",
          "Issue Tracker, https://github.com/cpburnz/python-pathspec/issues",
          "Source Code, https://github.com/cpburnz/python-pathspec"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/pathspec-0.12.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "dbt-extractor",
        "version": "0.6.0",
        "summary": "A tool to analyze and extract information from Jinja used in dbt projects.",
        "description": "\n# dbt extractor\n## Understanding dbt-extractor\n\nThis repository contains a tool that processes the most common jinja value templates in dbt model files. The tool depends on tree-sitter and the tree-sitter-jinja2 library.\n\n![demo app](demo/demo.gif)\n\n## Getting started\n\n- Read the [introduction](https://docs.getdbt.com/docs/introduction/) and [viewpoint](https://docs.getdbt.com/docs/about/viewpoint/) of dbt\n\n## Strategy\n\nThe current strategy is for this processor to be 100% certain when it can accurately extract values from a given model file. Anything less than 100% certainty returns an exception so that the model can be rendered with python Jinja instead. \n\nThere are two cases we want to avoid because they would risk correctness to user's projects:\n1. Confidently extracting values that would not be extracted by python jinja (false positives)\n2. Confidently extracting a set of values that are missing values that python jinja would have extracted. (misses)\n\nIf we instead error when we could have confidently extracted values, there is no correctness risk to the user. Only an opportunity to expand the rules to encompass this class of cases as well.\n\nEven though jinja in dbt is not a typed language, the type checker statically determines whether or not the current implementation can confidently extract values without relying on python jinja rendering, which is when these errors would otherwise surface. This type checker will become more permissive over time as this tool expands to include more dbt and jinja features.\n\n## Architecture\n\nThis architecture is optimized for value extraction and for future flexibility. This architecture is expected to change, and is coded in fp-style stages to make those changes easier for the future.\n\nThis processor is composed of several stages:\n1. parser\n2. type checker\n3. extractor\n\nAdditionally, the following tools utilize the above processor:\n1. browser-based demo of dbt extraction as you type\n\nThe tree-sitter parser is located in the tree-sitter-jinja2 library. The rust bindings are used to traverse the concrete syntax tree that tree-sitter creates in order to create a typed abstract syntax tree in the type checking stage. The errors in the type checking stage are not raised to the user, and are instead used by developers to debug tests.\n\nThe parser is solely responsible for turning text into recognized values, while the type checker does arity checking, and enforces argument list types (e.g. nested function calls like `{{ config(my_ref=ref('table')) }}` will parse but not type check even though it is valid dbt syntax. The tool at this time doesn't have an agreed serialization to communicate refs as config values, but could in the future.)\n\nThe extractor uses the typed abstract syntax tree to easily identify all the refs, sources, and configs present and extract them.\n\n## Join the dbt Community\n\n- Be part of the conversation in the [dbt Community Slack](http://community.getdbt.com/)\n- Read more on the [dbt Community Discourse](https://discourse.getdbt.com)\n\n## Reporting bugs and contributing code\n\n- Want to report a bug or request a feature? Let us know on [Slack](http://community.getdbt.com/), or open [an issue](https://github.com/dbt-labs/dbt-extractor/issues/new)\n- Want to help us build `dbt-extractor`? Check out the [Contributing Guide](https://github.com/dbt-labs/dbt-extractor/blob/HEAD/CONTRIBUTING.md)\n\n## Code of Conduct\n\nEveryone interacting in the dbt project's codebases, issue trackers, chat rooms, and mailing lists is expected to follow the [dbt Code of Conduct](https://community.getdbt.com/code-of-conduct).\n\n",
        "description_content_type": "text/markdown; charset=UTF-8; variant=GFM",
        "home_page": "https://github.com/dbt-labs/dbt-parser-generator/",
        "author": "Nathaniel May <nathaniel.may@dbtlabs.com>, Peter Webb <peter.webb@dbtlabs.com>, dbt Labs <info@dbtlabs.com>",
        "author_email": "dbt Labs <info@dbtlabs.com>, Nathaniel May <nathaniel.may@dbtlabs.com>, Peter Webb <peter.webb@dbtlabs.com>",
        "license": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Programming Language :: Rust",
          "Development Status :: 5 - Production/Stable",
          "License :: OSI Approved :: Apache Software License",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: POSIX :: Linux"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Source Code, https://github.com/dbt-labs/dbt-parser-generator/"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/dbt_extractor-0.6.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "networkx",
        "version": "3.6.1",
        "dynamic": [
          "license-file"
        ],
        "platform": [
          "Linux",
          "Mac OSX",
          "Windows",
          "Unix"
        ],
        "summary": "Python package for creating and manipulating graphs and networks",
        "description": "NetworkX\n========\n\n\n.. image::\n    https://github.com/networkx/networkx/actions/workflows/test.yml/badge.svg?branch=main\n    :target: https://github.com/networkx/networkx/actions/workflows/test.yml\n\n.. image::\n    https://img.shields.io/pypi/v/networkx.svg?\n    :target: https://pypi.python.org/pypi/networkx\n\n.. image::\n    https://img.shields.io/pypi/l/networkx.svg?\n    :target: https://github.com/networkx/networkx/blob/main/LICENSE.txt\n\n.. image::\n    https://img.shields.io/pypi/pyversions/networkx.svg?\n    :target: https://pypi.python.org/pypi/networkx\n\n.. image::\n    https://img.shields.io/github/labels/networkx/networkx/good%20first%20issue?color=green&label=contribute\n    :target: https://github.com/networkx/networkx/contribute\n\n.. image::\n    https://insights.linuxfoundation.org/api/badge/health-score?project=networkx\n    :target: https://insights.linuxfoundation.org/project/networkx\n\n\nNetworkX is a Python package for the creation, manipulation,\nand study of the structure, dynamics, and functions\nof complex networks.\n\n- **Website (including documentation):** https://networkx.org\n- **Mailing list:** https://groups.google.com/forum/#!forum/networkx-discuss\n- **Source:** https://github.com/networkx/networkx\n- **Bug reports:** https://github.com/networkx/networkx/issues\n- **Report a security vulnerability:** https://tidelift.com/security\n- **Tutorial:** https://networkx.org/documentation/latest/tutorial.html\n- **GitHub Discussions:** https://github.com/networkx/networkx/discussions\n- **Discord (Scientific Python) invite link:** https://discord.com/invite/vur45CbwMz\n- **NetworkX meetings calendar (open to all):** https://scientific-python.org/calendars/networkx.ics\n\nSimple example\n--------------\n\nFind the shortest path between two nodes in an undirected graph:\n\n.. code:: pycon\n\n    >>> import networkx as nx\n    >>> G = nx.Graph()\n    >>> G.add_edge(\"A\", \"B\", weight=4)\n    >>> G.add_edge(\"B\", \"D\", weight=2)\n    >>> G.add_edge(\"A\", \"C\", weight=3)\n    >>> G.add_edge(\"C\", \"D\", weight=4)\n    >>> nx.shortest_path(G, \"A\", \"D\", weight=\"weight\")\n    ['A', 'B', 'D']\n\nInstall\n-------\n\nInstall the latest released version of NetworkX:\n\n.. code:: shell\n\n    $ pip install networkx\n\nInstall with all optional dependencies:\n\n.. code:: shell\n\n    $ pip install networkx[default]\n\nFor additional details,\nplease see the `installation guide <https://networkx.org/documentation/stable/install.html>`_.\n\nBugs\n----\n\nPlease report any bugs that you find `here <https://github.com/networkx/networkx/issues>`_.\nOr, even better, fork the repository on `GitHub <https://github.com/networkx/networkx>`_\nand create a pull request (PR). We welcome all changes, big or small, and we\nwill help you make the PR if you are new to `git` (just ask on the issue and/or\nsee the `contributor guide <https://networkx.org/documentation/latest/developer/contribute.html>`_).\n\nLicense\n-------\n\nReleased under the `3-clause BSD license <https://github.com/networkx/networkx/blob/main/LICENSE.txt>`_::\n\n    Copyright (c) 2004-2025, NetworkX Developers\n    Aric Hagberg <hagberg@lanl.gov>\n    Dan Schult <dschult@colgate.edu>\n    Pieter Swart <swart@lanl.gov>\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "Networks",
          "Graph Theory",
          "Mathematics",
          "network",
          "graph",
          "discrete mathematics",
          "math"
        ],
        "author_email": "Aric Hagberg <hagberg@lanl.gov>",
        "maintainer_email": "NetworkX Developers <networkx-discuss@googlegroups.com>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: Science/Research",
          "Operating System :: OS Independent",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: 3 :: Only",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Scientific/Engineering :: Bio-Informatics",
          "Topic :: Scientific/Engineering :: Information Analysis",
          "Topic :: Scientific/Engineering :: Mathematics",
          "Topic :: Scientific/Engineering :: Physics"
        ],
        "requires_dist": [
          "asv; extra == \"benchmarking\"",
          "virtualenv; extra == \"benchmarking\"",
          "numpy>=1.25; extra == \"default\"",
          "scipy>=1.11.2; extra == \"default\"",
          "matplotlib>=3.8; extra == \"default\"",
          "pandas>=2.0; extra == \"default\"",
          "pre-commit>=4.1; extra == \"developer\"",
          "mypy>=1.15; extra == \"developer\"",
          "sphinx>=8.0; extra == \"doc\"",
          "pydata-sphinx-theme>=0.16; extra == \"doc\"",
          "sphinx-gallery>=0.18; extra == \"doc\"",
          "numpydoc>=1.8.0; extra == \"doc\"",
          "pillow>=10; extra == \"doc\"",
          "texext>=0.6.7; extra == \"doc\"",
          "myst-nb>=1.1; extra == \"doc\"",
          "intersphinx-registry; extra == \"doc\"",
          "osmnx>=2.0.0; extra == \"example\"",
          "momepy>=0.7.2; extra == \"example\"",
          "contextily>=1.6; extra == \"example\"",
          "seaborn>=0.13; extra == \"example\"",
          "cairocffi>=1.7; extra == \"example\"",
          "igraph>=0.11; extra == \"example\"",
          "scikit-learn>=1.5; extra == \"example\"",
          "iplotx>=0.9.0; extra == \"example\"",
          "lxml>=4.6; extra == \"extra\"",
          "pygraphviz>=1.14; extra == \"extra\"",
          "pydot>=3.0.1; extra == \"extra\"",
          "sympy>=1.10; extra == \"extra\"",
          "build>=0.10; extra == \"release\"",
          "twine>=4.0; extra == \"release\"",
          "wheel>=0.40; extra == \"release\"",
          "changelist==0.5; extra == \"release\"",
          "pytest>=7.2; extra == \"test\"",
          "pytest-cov>=4.0; extra == \"test\"",
          "pytest-xdist>=3.0; extra == \"test\"",
          "pytest-mpl; extra == \"test-extras\"",
          "pytest-randomly; extra == \"test-extras\""
        ],
        "requires_python": "!=3.14.1,>=3.11",
        "project_url": [
          "Homepage, https://networkx.org/",
          "Bug Tracker, https://github.com/networkx/networkx/issues",
          "Documentation, https://networkx.org/documentation/stable/",
          "Source Code, https://github.com/networkx/networkx"
        ],
        "provides_extra": [
          "benchmarking",
          "default",
          "developer",
          "doc",
          "example",
          "extra",
          "release",
          "test",
          "test-extras"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/networkx-3.6.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "psycopg2-binary",
        "version": "2.9.11",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "home-page",
          "license",
          "license-file",
          "maintainer",
          "maintainer-email",
          "platform",
          "project-url",
          "requires-python",
          "summary"
        ],
        "platform": [
          "any"
        ],
        "summary": "psycopg2 - Python-PostgreSQL Database Adapter",
        "description": "Psycopg is the most popular PostgreSQL database adapter for the Python\nprogramming language.  Its main features are the complete implementation of\nthe Python DB API 2.0 specification and the thread safety (several threads can\nshare the same connection).  It was designed for heavily multi-threaded\napplications that create and destroy lots of cursors and make a large number\nof concurrent \"INSERT\"s or \"UPDATE\"s.\n\nPsycopg 2 is mostly implemented in C as a libpq wrapper, resulting in being\nboth efficient and secure.  It features client-side and server-side cursors,\nasynchronous communication and notifications, \"COPY TO/COPY FROM\" support.\nMany Python types are supported out-of-the-box and adapted to matching\nPostgreSQL data types; adaptation can be extended and customized thanks to a\nflexible objects adaptation system.\n\nPsycopg 2 is both Unicode and Python 3 friendly.\n\n.. Note::\n\n    The psycopg2 package is still widely used and actively maintained, but it\n    is not expected to receive new features.\n\n    `Psycopg 3`__ is the evolution of psycopg2 and is where `new features are\n    being developed`__: if you are starting a new project you should probably\n    start from 3!\n\n    .. __: https://pypi.org/project/psycopg/\n    .. __: https://www.psycopg.org/psycopg3/docs/index.html\n\n\nDocumentation\n-------------\n\nDocumentation is included in the ``doc`` directory and is `available online`__.\n\n.. __: https://www.psycopg.org/docs/\n\nFor any other resource (source code repository, bug tracker, mailing list)\nplease check the `project homepage`__.\n\n.. __: https://psycopg.org/\n\n\nInstallation\n------------\n\nBuilding Psycopg requires a few prerequisites (a C compiler, some development\npackages): please check the install_ and the faq_ documents in the ``doc`` dir\nor online for the details.\n\nIf prerequisites are met, you can install psycopg like any other Python\npackage, using ``pip`` to download it from PyPI_::\n\n    $ pip install psycopg2\n\nor using ``setup.py`` if you have downloaded the source package locally::\n\n    $ python setup.py build\n    $ sudo python setup.py install\n\nYou can also obtain a stand-alone package, not requiring a compiler or\nexternal libraries, by installing the `psycopg2-binary`_ package from PyPI::\n\n    $ pip install psycopg2-binary\n\nThe binary package is a practical choice for development and testing but in\nproduction it is advised to use the package built from sources.\n\n.. _PyPI: https://pypi.org/project/psycopg2/\n.. _psycopg2-binary: https://pypi.org/project/psycopg2-binary/\n.. _install: https://www.psycopg.org/docs/install.html#install-from-source\n.. _faq: https://www.psycopg.org/docs/faq.html#faq-compile\n\n:Build status: |gh-actions|\n\n.. |gh-actions| image:: https://github.com/psycopg/psycopg2/actions/workflows/tests.yml/badge.svg\n    :target: https://github.com/psycopg/psycopg2/actions/workflows/tests.yml\n    :alt: Build status\n",
        "home_page": "https://psycopg.org/",
        "author": "Federico Di Gregorio",
        "author_email": "fog@initd.org",
        "maintainer": "Daniele Varrazzo",
        "maintainer_email": "daniele.varrazzo@gmail.com",
        "license": "LGPL with exceptions",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: C",
          "Programming Language :: SQL",
          "Topic :: Database",
          "Topic :: Database :: Front-Ends",
          "Topic :: Software Development",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: Unix"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Homepage, https://psycopg.org/",
          "Changes, https://www.psycopg.org/docs/news.html",
          "Documentation, https://www.psycopg.org/docs/",
          "Code, https://github.com/psycopg/psycopg2",
          "Issue Tracker, https://github.com/psycopg/psycopg2/issues",
          "Download, https://pypi.org/project/psycopg2/"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/psycopg2_binary-2.9.11.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.3",
        "name": "annotated-types",
        "version": "0.7.0",
        "summary": "Reusable constraint types to use with typing.Annotated",
        "description": "# annotated-types\n\n[![CI](https://github.com/annotated-types/annotated-types/workflows/CI/badge.svg?event=push)](https://github.com/annotated-types/annotated-types/actions?query=event%3Apush+branch%3Amain+workflow%3ACI)\n[![pypi](https://img.shields.io/pypi/v/annotated-types.svg)](https://pypi.python.org/pypi/annotated-types)\n[![versions](https://img.shields.io/pypi/pyversions/annotated-types.svg)](https://github.com/annotated-types/annotated-types)\n[![license](https://img.shields.io/github/license/annotated-types/annotated-types.svg)](https://github.com/annotated-types/annotated-types/blob/main/LICENSE)\n\n[PEP-593](https://peps.python.org/pep-0593/) added `typing.Annotated` as a way of\nadding context-specific metadata to existing types, and specifies that\n`Annotated[T, x]` _should_ be treated as `T` by any tool or library without special\nlogic for `x`.\n\nThis package provides metadata objects which can be used to represent common\nconstraints such as upper and lower bounds on scalar values and collection sizes,\na `Predicate` marker for runtime checks, and\ndescriptions of how we intend these metadata to be interpreted. In some cases,\nwe also note alternative representations which do not require this package.\n\n## Install\n\n```bash\npip install annotated-types\n```\n\n## Examples\n\n```python\nfrom typing import Annotated\nfrom annotated_types import Gt, Len, Predicate\n\nclass MyClass:\n    age: Annotated[int, Gt(18)]                         # Valid: 19, 20, ...\n                                                        # Invalid: 17, 18, \"19\", 19.0, ...\n    factors: list[Annotated[int, Predicate(is_prime)]]  # Valid: 2, 3, 5, 7, 11, ...\n                                                        # Invalid: 4, 8, -2, 5.0, \"prime\", ...\n\n    my_list: Annotated[list[int], Len(0, 10)]           # Valid: [], [10, 20, 30, 40, 50]\n                                                        # Invalid: (1, 2), [\"abc\"], [0] * 20\n```\n\n## Documentation\n\n_While `annotated-types` avoids runtime checks for performance, users should not\nconstruct invalid combinations such as `MultipleOf(\"non-numeric\")` or `Annotated[int, Len(3)]`.\nDownstream implementors may choose to raise an error, emit a warning, silently ignore\na metadata item, etc., if the metadata objects described below are used with an\nincompatible type - or for any other reason!_\n\n### Gt, Ge, Lt, Le\n\nExpress inclusive and/or exclusive bounds on orderable values - which may be numbers,\ndates, times, strings, sets, etc. Note that the boundary value need not be of the\nsame type that was annotated, so long as they can be compared: `Annotated[int, Gt(1.5)]`\nis fine, for example, and implies that the value is an integer x such that `x > 1.5`.\n\nWe suggest that implementors may also interpret `functools.partial(operator.le, 1.5)`\nas being equivalent to `Gt(1.5)`, for users who wish to avoid a runtime dependency on\nthe `annotated-types` package.\n\nTo be explicit, these types have the following meanings:\n\n* `Gt(x)` - value must be \"Greater Than\" `x` - equivalent to exclusive minimum\n* `Ge(x)` - value must be \"Greater than or Equal\" to `x` - equivalent to inclusive minimum\n* `Lt(x)` - value must be \"Less Than\" `x` - equivalent to exclusive maximum\n* `Le(x)` - value must be \"Less than or Equal\" to `x` - equivalent to inclusive maximum\n\n### Interval\n\n`Interval(gt, ge, lt, le)` allows you to specify an upper and lower bound with a single\nmetadata object. `None` attributes should be ignored, and non-`None` attributes\ntreated as per the single bounds above.\n\n### MultipleOf\n\n`MultipleOf(multiple_of=x)` might be interpreted in two ways:\n\n1. Python semantics, implying `value % multiple_of == 0`, or\n2. [JSONschema semantics](https://json-schema.org/draft/2020-12/json-schema-validation.html#rfc.section.6.2.1),\n   where `int(value / multiple_of) == value / multiple_of`.\n\nWe encourage users to be aware of these two common interpretations and their\ndistinct behaviours, especially since very large or non-integer numbers make\nit easy to cause silent data corruption due to floating-point imprecision.\n\nWe encourage libraries to carefully document which interpretation they implement.\n\n### MinLen, MaxLen, Len\n\n`Len()` implies that `min_length <= len(value) <= max_length` - lower and upper bounds are inclusive.\n\nAs well as `Len()` which can optionally include upper and lower bounds, we also\nprovide `MinLen(x)` and `MaxLen(y)` which are equivalent to `Len(min_length=x)`\nand `Len(max_length=y)` respectively.\n\n`Len`, `MinLen`, and `MaxLen` may be used with any type which supports `len(value)`.\n\nExamples of usage:\n\n* `Annotated[list, MaxLen(10)]` (or `Annotated[list, Len(max_length=10))`) - list must have a length of 10 or less\n* `Annotated[str, MaxLen(10)]` - string must have a length of 10 or less\n* `Annotated[list, MinLen(3))` (or `Annotated[list, Len(min_length=3))`) - list must have a length of 3 or more\n* `Annotated[list, Len(4, 6)]` - list must have a length of 4, 5, or 6\n* `Annotated[list, Len(8, 8)]` - list must have a length of exactly 8\n\n#### Changed in v0.4.0\n\n* `min_inclusive` has been renamed to `min_length`, no change in meaning\n* `max_exclusive` has been renamed to `max_length`, upper bound is now **inclusive** instead of **exclusive**\n* The recommendation that slices are interpreted as `Len` has been removed due to ambiguity and different semantic\n  meaning of the upper bound in slices vs. `Len`\n\nSee [issue #23](https://github.com/annotated-types/annotated-types/issues/23) for discussion.\n\n### Timezone\n\n`Timezone` can be used with a `datetime` or a `time` to express which timezones\nare allowed. `Annotated[datetime, Timezone(None)]` must be a naive datetime.\n`Timezone[...]` ([literal ellipsis](https://docs.python.org/3/library/constants.html#Ellipsis))\nexpresses that any timezone-aware datetime is allowed. You may also pass a specific\ntimezone string or [`tzinfo`](https://docs.python.org/3/library/datetime.html#tzinfo-objects)\nobject such as `Timezone(timezone.utc)` or `Timezone(\"Africa/Abidjan\")` to express that you only\nallow a specific timezone, though we note that this is often a symptom of fragile design.\n\n#### Changed in v0.x.x\n\n* `Timezone` accepts [`tzinfo`](https://docs.python.org/3/library/datetime.html#tzinfo-objects) objects instead of\n  `timezone`, extending compatibility to [`zoneinfo`](https://docs.python.org/3/library/zoneinfo.html) and third party libraries.\n\n### Unit\n\n`Unit(unit: str)` expresses that the annotated numeric value is the magnitude of\na quantity with the specified unit. For example, `Annotated[float, Unit(\"m/s\")]`\nwould be a float representing a velocity in meters per second.\n\nPlease note that `annotated_types` itself makes no attempt to parse or validate\nthe unit string in any way. That is left entirely to downstream libraries,\nsuch as [`pint`](https://pint.readthedocs.io) or\n[`astropy.units`](https://docs.astropy.org/en/stable/units/).\n\nAn example of how a library might use this metadata:\n\n```python\nfrom annotated_types import Unit\nfrom typing import Annotated, TypeVar, Callable, Any, get_origin, get_args\n\n# given a type annotated with a unit:\nMeters = Annotated[float, Unit(\"m\")]\n\n\n# you can cast the annotation to a specific unit type with any\n# callable that accepts a string and returns the desired type\nT = TypeVar(\"T\")\ndef cast_unit(tp: Any, unit_cls: Callable[[str], T]) -> T | None:\n    if get_origin(tp) is Annotated:\n        for arg in get_args(tp):\n            if isinstance(arg, Unit):\n                return unit_cls(arg.unit)\n    return None\n\n\n# using `pint`\nimport pint\npint_unit = cast_unit(Meters, pint.Unit)\n\n\n# using `astropy.units`\nimport astropy.units as u\nastropy_unit = cast_unit(Meters, u.Unit)\n```\n\n### Predicate\n\n`Predicate(func: Callable)` expresses that `func(value)` is truthy for valid values.\nUsers should prefer the statically inspectable metadata above, but if you need\nthe full power and flexibility of arbitrary runtime predicates... here it is.\n\nFor some common constraints, we provide generic types:\n\n* `IsLower       = Annotated[T, Predicate(str.islower)]`\n* `IsUpper       = Annotated[T, Predicate(str.isupper)]`\n* `IsDigit       = Annotated[T, Predicate(str.isdigit)]`\n* `IsFinite      = Annotated[T, Predicate(math.isfinite)]`\n* `IsNotFinite   = Annotated[T, Predicate(Not(math.isfinite))]`\n* `IsNan         = Annotated[T, Predicate(math.isnan)]`\n* `IsNotNan      = Annotated[T, Predicate(Not(math.isnan))]`\n* `IsInfinite    = Annotated[T, Predicate(math.isinf)]`\n* `IsNotInfinite = Annotated[T, Predicate(Not(math.isinf))]`\n\nso that you can write e.g. `x: IsFinite[float] = 2.0` instead of the longer\n(but exactly equivalent) `x: Annotated[float, Predicate(math.isfinite)] = 2.0`.\n\nSome libraries might have special logic to handle known or understandable predicates,\nfor example by checking for `str.isdigit` and using its presence to both call custom\nlogic to enforce digit-only strings, and customise some generated external schema.\nUsers are therefore encouraged to avoid indirection like `lambda s: s.lower()`, in\nfavor of introspectable methods such as `str.lower` or `re.compile(\"pattern\").search`.\n\nTo enable basic negation of commonly used predicates like `math.isnan` without introducing introspection that makes it impossible for implementers to introspect the predicate we provide a `Not` wrapper that simply negates the predicate in an introspectable manner. Several of the predicates listed above are created in this manner.\n\nWe do not specify what behaviour should be expected for predicates that raise\nan exception.  For example `Annotated[int, Predicate(str.isdigit)]` might silently\nskip invalid constraints, or statically raise an error; or it might try calling it\nand then propagate or discard the resulting\n`TypeError: descriptor 'isdigit' for 'str' objects doesn't apply to a 'int' object`\nexception.  We encourage libraries to document the behaviour they choose.\n\n### Doc\n\n`doc()` can be used to add documentation information in `Annotated`, for function and method parameters, variables, class attributes, return types, and any place where `Annotated` can be used.\n\nIt expects a value that can be statically analyzed, as the main use case is for static analysis, editors, documentation generators, and similar tools.\n\nIt returns a `DocInfo` class with a single attribute `documentation` containing the value passed to `doc()`.\n\nThis is the early adopter's alternative form of the [`typing-doc` proposal](https://github.com/tiangolo/fastapi/blob/typing-doc/typing_doc.md).\n\n### Integrating downstream types with `GroupedMetadata`\n\nImplementers may choose to provide a convenience wrapper that groups multiple pieces of metadata.\nThis can help reduce verbosity and cognitive overhead for users.\nFor example, an implementer like Pydantic might provide a `Field` or `Meta` type that accepts keyword arguments and transforms these into low-level metadata:\n\n```python\nfrom dataclasses import dataclass\nfrom typing import Iterator\nfrom annotated_types import GroupedMetadata, Ge\n\n@dataclass\nclass Field(GroupedMetadata):\n    ge: int | None = None\n    description: str | None = None\n\n    def __iter__(self) -> Iterator[object]:\n        # Iterating over a GroupedMetadata object should yield annotated-types\n        # constraint metadata objects which describe it as fully as possible,\n        # and may include other unknown objects too.\n        if self.ge is not None:\n            yield Ge(self.ge)\n        if self.description is not None:\n            yield Description(self.description)\n```\n\nLibraries consuming annotated-types constraints should check for `GroupedMetadata` and unpack it by iterating over the object and treating the results as if they had been \"unpacked\" in the `Annotated` type.  The same logic should be applied to the [PEP 646 `Unpack` type](https://peps.python.org/pep-0646/), so that `Annotated[T, Field(...)]`, `Annotated[T, Unpack[Field(...)]]` and `Annotated[T, *Field(...)]` are all treated consistently.\n\nLibraries consuming annotated-types should also ignore any metadata they do not recongize that came from unpacking a `GroupedMetadata`, just like they ignore unrecognized metadata in `Annotated` itself.\n\nOur own `annotated_types.Interval` class is a `GroupedMetadata` which unpacks itself into `Gt`, `Lt`, etc., so this is not an abstract concern.  Similarly, `annotated_types.Len` is a `GroupedMetadata` which unpacks itself into `MinLen` (optionally) and `MaxLen`.\n\n### Consuming metadata\n\nWe intend to not be prescriptive as to _how_ the metadata and constraints are used, but as an example of how one might parse constraints from types annotations see our [implementation in `test_main.py`](https://github.com/annotated-types/annotated-types/blob/f59cf6d1b5255a0fe359b93896759a180bec30ae/tests/test_main.py#L94-L103).\n\nIt is up to the implementer to determine how this metadata is used.\nYou could use the metadata for runtime type checking, for generating schemas or to generate example data, amongst other use cases.\n\n## Design & History\n\nThis package was designed at the PyCon 2022 sprints by the maintainers of Pydantic\nand Hypothesis, with the goal of making it as easy as possible for end-users to\nprovide more informative annotations for use by runtime libraries.\n\nIt is deliberately minimal, and following PEP-593 allows considerable downstream\ndiscretion in what (if anything!) they choose to support. Nonetheless, we expect\nthat staying simple and covering _only_ the most common use-cases will give users\nand maintainers the best experience we can. If you'd like more constraints for your\ntypes - follow our lead, by defining them and documenting them downstream!\n",
        "description_content_type": "text/markdown",
        "author_email": "Adrian Garcia Badaracco <1755071+adriangb@users.noreply.github.com>, Samuel Colvin <s@muelcolvin.com>, Zac Hatfield-Dodds <zac@zhd.dev>",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Environment :: Console",
          "Environment :: MacOS X",
          "Intended Audience :: Developers",
          "Intended Audience :: Information Technology",
          "License :: OSI Approved :: MIT License",
          "Operating System :: POSIX :: Linux",
          "Operating System :: Unix",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Typing :: Typed"
        ],
        "requires_dist": [
          "typing-extensions>=4.0.0; python_version < '3.9'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Homepage, https://github.com/annotated-types/annotated-types",
          "Source, https://github.com/annotated-types/annotated-types",
          "Changelog, https://github.com/annotated-types/annotated-types/releases"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/annotated_types-0.7.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "agate",
        "version": "1.9.1",
        "summary": "A data analysis library that is optimized for humans instead of machines.",
        "description": ".. image:: https://github.com/wireservice/agate/workflows/CI/badge.svg\n    :target: https://github.com/wireservice/agate/actions\n    :alt: Build status\n\n.. image:: https://coveralls.io/repos/wireservice/agate/badge.svg?branch=master\n    :target: https://coveralls.io/r/wireservice/agate\n    :alt: Coverage status\n\n.. image:: https://img.shields.io/pypi/dm/agate.svg\n    :target: https://pypi.python.org/pypi/agate\n    :alt: PyPI downloads\n\n.. image:: https://img.shields.io/pypi/v/agate.svg\n    :target: https://pypi.python.org/pypi/agate\n    :alt: Version\n\n.. image:: https://img.shields.io/pypi/l/agate.svg\n    :target: https://pypi.python.org/pypi/agate\n    :alt: License\n\n.. image:: https://img.shields.io/pypi/pyversions/agate.svg\n    :target: https://pypi.python.org/pypi/agate\n    :alt: Support Python versions\n\nagate is a Python data analysis library that is optimized for humans instead of machines. It is an alternative to numpy and pandas that solves real-world problems with readable code.\n\nagate was previously known as journalism.\n\nImportant links:\n\n* Documentation:    https://agate.rtfd.org\n* Repository:       https://github.com/wireservice/agate\n* Issues:           https://github.com/wireservice/agate/issues\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://agate.readthedocs.org/",
        "author": "Christopher Groskopf",
        "author_email": "chrisgroskopf@gmail.com",
        "license": "MIT",
        "license_file": [
          "COPYING",
          "AUTHORS.rst"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Framework :: IPython",
          "Intended Audience :: Developers",
          "Intended Audience :: Science/Research",
          "License :: OSI Approved :: MIT License",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Scientific/Engineering :: Information Analysis",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "Babel >=2.0",
          "isodate >=0.5.4",
          "leather >=0.3.2",
          "parsedatetime !=2.5,>=2.1",
          "python-slugify >=1.2.1",
          "pytimeparse >=1.1.5",
          "tzdata >=2023.3 ; platform_system == \"Windows\"",
          "coverage >=3.7.1 ; extra == 'test'",
          "cssselect >=0.9.1 ; extra == 'test'",
          "lxml >=3.6.0 ; extra == 'test'",
          "pytest ; extra == 'test'",
          "pytest-cov ; extra == 'test'",
          "backports.zoneinfo ; (python_version < \"3.9\") and extra == 'test'",
          "PyICU >=2.4.2 ; (sys_platform == \"linux\") and extra == 'test'"
        ],
        "project_url": [
          "Source, https://github.com/wireservice/agate"
        ],
        "provides_extra": [
          "test"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/agate-1.9.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "numpy",
        "version": "2.4.1",
        "summary": "Fundamental package for array computing in Python",
        "description": "<h1 align=\"center\">\n<img src=\"https://raw.githubusercontent.com/numpy/numpy/main/branding/logo/primary/numpylogo.svg\" width=\"300\">\n</h1><br>\n\n\n[![Powered by NumFOCUS](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A)](\nhttps://numfocus.org)\n[![PyPI Downloads](https://img.shields.io/pypi/dm/numpy.svg?label=PyPI%20downloads)](\nhttps://pypi.org/project/numpy/)\n[![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/numpy.svg?label=Conda%20downloads)](\nhttps://anaconda.org/conda-forge/numpy)\n[![Stack Overflow](https://img.shields.io/badge/stackoverflow-Ask%20questions-blue.svg)](\nhttps://stackoverflow.com/questions/tagged/numpy)\n[![Nature Paper](https://img.shields.io/badge/DOI-10.1038%2Fs41586--020--2649--2-blue)](\nhttps://doi.org/10.1038/s41586-020-2649-2)\n[![LFX Health Score](https://insights.linuxfoundation.org/api/badge/health-score?project=numpy)](https://insights.linuxfoundation.org/project/numpy)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/numpy/numpy/badge)](https://securityscorecards.dev/viewer/?uri=github.com/numpy/numpy)\n[![Typing](https://img.shields.io/pypi/types/numpy)](https://pypi.org/project/numpy/)\n\n\nNumPy is the fundamental package for scientific computing with Python.\n\n- **Website:** https://numpy.org\n- **Documentation:** https://numpy.org/doc\n- **Mailing list:** https://mail.python.org/mailman/listinfo/numpy-discussion\n- **Source code:** https://github.com/numpy/numpy\n- **Contributing:** https://numpy.org/devdocs/dev/index.html\n- **Bug reports:** https://github.com/numpy/numpy/issues\n- **Report a security vulnerability:** https://tidelift.com/docs/security\n\nIt provides:\n\n- a powerful N-dimensional array object\n- sophisticated (broadcasting) functions\n- tools for integrating C/C++ and Fortran code\n- useful linear algebra, Fourier transform, and random number capabilities\n\nTesting:\n\nNumPy requires `pytest` and `hypothesis`.  Tests can then be run after installation with:\n\n    python -c \"import numpy, sys; sys.exit(numpy.test() is False)\"\n\nCode of Conduct\n----------------------\n\nNumPy is a community-driven open source project developed by a diverse group of\n[contributors](https://numpy.org/teams/). The NumPy leadership has made a strong\ncommitment to creating an open, inclusive, and positive community. Please read the\n[NumPy Code of Conduct](https://numpy.org/code-of-conduct/) for guidance on how to interact\nwith others in a way that makes our community thrive.\n\nCall for Contributions\n----------------------\n\nThe NumPy project welcomes your expertise and enthusiasm!\n\nSmall improvements or fixes are always appreciated. If you are considering larger contributions\nto the source code, please contact us through the [mailing\nlist](https://mail.python.org/mailman/listinfo/numpy-discussion) first.\n\nWriting code isnâ€™t the only way to contribute to NumPy. You can also:\n- review pull requests\n- help us stay on top of new and old issues\n- develop tutorials, presentations, and other educational materials\n- maintain and improve [our website](https://github.com/numpy/numpy.org)\n- develop graphic design for our brand assets and promotional materials\n- translate website content\n- help with outreach and onboard new contributors\n- write grant proposals and help with other fundraising efforts\n\nFor more information about the ways you can contribute to NumPy, visit [our website](https://numpy.org/contribute/). \nIf youâ€™re unsure where to start or how your skills fit in, reach out! You can\nask on the mailing list or here, on GitHub, by opening a new issue or leaving a\ncomment on a relevant issue that is already open.\n\nOur preferred channels of communication are all public, but if youâ€™d like to\nspeak to us in private first, contact our community coordinators at\nnumpy-team@googlegroups.com or on Slack (write numpy-team@googlegroups.com for\nan invitation).\n\nWe also have a biweekly community call, details of which are announced on the\nmailing list. You are very welcome to join.\n\nIf you are new to contributing to open source, [this\nguide](https://opensource.guide/how-to-contribute/) helps explain why, what,\nand how to successfully get involved.\n",
        "description_content_type": "text/markdown",
        "author": "Travis E. Oliphant et al.",
        "maintainer_email": "NumPy Developers <numpy-discussion@python.org>",
        "license_expression": "BSD-3-Clause AND 0BSD AND MIT AND Zlib AND CC0-1.0",
        "license_file": [
          "LICENSE.txt",
          "numpy/_core/include/numpy/libdivide/LICENSE.txt",
          "numpy/_core/src/common/pythoncapi-compat/COPYING",
          "numpy/_core/src/highway/LICENSE",
          "numpy/_core/src/multiarray/dragon4_LICENSE.txt",
          "numpy/_core/src/npysort/x86-simd-sort/LICENSE.md",
          "numpy/_core/src/umath/svml/LICENSE",
          "numpy/fft/pocketfft/LICENSE.md",
          "numpy/linalg/lapack_lite/LICENSE.txt",
          "numpy/ma/LICENSE",
          "numpy/random/LICENSE.md",
          "numpy/random/src/distributions/LICENSE.md",
          "numpy/random/src/mt19937/LICENSE.md",
          "numpy/random/src/pcg64/LICENSE.md",
          "numpy/random/src/philox/LICENSE.md",
          "numpy/random/src/sfc64/LICENSE.md",
          "numpy/random/src/splitmix64/LICENSE.md"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Science/Research",
          "Intended Audience :: Developers",
          "Programming Language :: C",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: Implementation :: CPython",
          "Topic :: Software Development",
          "Topic :: Scientific/Engineering",
          "Typing :: Typed",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX",
          "Operating System :: Unix",
          "Operating System :: MacOS"
        ],
        "requires_python": ">=3.11",
        "project_url": [
          "homepage, https://numpy.org",
          "documentation, https://numpy.org/doc/",
          "source, https://github.com/numpy/numpy",
          "download, https://pypi.org/project/numpy/#files",
          "tracker, https://github.com/numpy/numpy/issues",
          "release notes, https://numpy.org/doc/stable/release"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/numpy-2.4.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "packaging",
        "version": "25.0",
        "summary": "Core utilities for Python packages",
        "description": "packaging\n=========\n\n.. start-intro\n\nReusable core utilities for various Python Packaging\n`interoperability specifications <https://packaging.python.org/specifications/>`_.\n\nThis library provides utilities that implement the interoperability\nspecifications which have clearly one correct behaviour (eg: :pep:`440`)\nor benefit greatly from having a single shared implementation (eg: :pep:`425`).\n\n.. end-intro\n\nThe ``packaging`` project includes the following: version handling, specifiers,\nmarkers, requirements, tags, utilities.\n\nDocumentation\n-------------\n\nThe `documentation`_ provides information and the API for the following:\n\n- Version Handling\n- Specifiers\n- Markers\n- Requirements\n- Tags\n- Utilities\n\nInstallation\n------------\n\nUse ``pip`` to install these utilities::\n\n    pip install packaging\n\nThe ``packaging`` library uses calendar-based versioning (``YY.N``).\n\nDiscussion\n----------\n\nIf you run into bugs, you can file them in our `issue tracker`_.\n\nYou can also join ``#pypa`` on Freenode to ask questions or get involved.\n\n\n.. _`documentation`: https://packaging.pypa.io/\n.. _`issue tracker`: https://github.com/pypa/packaging/issues\n\n\nCode of Conduct\n---------------\n\nEveryone interacting in the packaging project's codebases, issue trackers, chat\nrooms, and mailing lists is expected to follow the `PSF Code of Conduct`_.\n\n.. _PSF Code of Conduct: https://github.com/pypa/.github/blob/main/CODE_OF_CONDUCT.md\n\nContributing\n------------\n\nThe ``CONTRIBUTING.rst`` file outlines how to contribute to this project as\nwell as how to report a potential security issue. The documentation for this\nproject also covers information about `project development`_ and `security`_.\n\n.. _`project development`: https://packaging.pypa.io/en/latest/development/\n.. _`security`: https://packaging.pypa.io/en/latest/security/\n\nProject History\n---------------\n\nPlease review the ``CHANGELOG.rst`` file or the `Changelog documentation`_ for\nrecent changes and project history.\n\n.. _`Changelog documentation`: https://packaging.pypa.io/en/latest/changelog/\n\n",
        "description_content_type": "text/x-rst",
        "author_email": "Donald Stufft <donald@stufft.io>",
        "license_file": [
          "LICENSE",
          "LICENSE.APACHE",
          "LICENSE.BSD"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "License :: OSI Approved :: BSD License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Typing :: Typed"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Documentation, https://packaging.pypa.io/",
          "Source, https://github.com/pypa/packaging"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/packaging-25.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "leather",
        "version": "0.4.1",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "license",
          "license-file",
          "provides-extra",
          "summary"
        ],
        "summary": "Python charting for 80% of humans.",
        "description": ".. image:: https://github.com/wireservice/leather/workflows/CI/badge.svg\n    :target: https://github.com/wireservice/leather/actions\n    :alt: Build status\n\n.. image:: https://coveralls.io/repos/wireservice/leather/badge.svg?branch=master\n    :target: https://coveralls.io/r/wireservice/leather\n    :alt: Coverage status\n\n.. image:: https://img.shields.io/pypi/dw/leather.svg\n    :target: https://pypi.python.org/pypi/leather\n    :alt: PyPI downloads\n\n.. image:: https://img.shields.io/pypi/v/leather.svg\n    :target: https://pypi.python.org/pypi/leather\n    :alt: Version\n\n.. image:: https://img.shields.io/pypi/l/leather.svg\n    :target: https://pypi.python.org/pypi/leather\n    :alt: License\n\n.. image:: https://img.shields.io/pypi/pyversions/leather.svg\n    :target: https://pypi.python.org/pypi/leather\n    :alt: Support Python versions\n\nLeather is the Python charting library for those who need charts *now* and don't care if they're perfect.\n\nLeather isn't picky. It's rough. It gets dirty. It looks sexy just hanging on the back of a chair. Leather doesn't need your accessories. Leather is how Snake Plissken would make charts.\n\nGet it?\n\nImportant links:\n\n* Documentation:    https://leather.rtfd.io\n* Repository:       https://github.com/wireservice/leather\n* Issues:           https://github.com/wireservice/leather/issues\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://leather.readthedocs.io/",
        "author": "Christopher Groskopf",
        "author_email": "chrisgroskopf@gmail.com",
        "license": "MIT",
        "license_file": [
          "COPYING"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Framework :: IPython",
          "Intended Audience :: Developers",
          "Intended Audience :: Science/Research",
          "License :: OSI Approved :: MIT License",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Multimedia :: Graphics",
          "Topic :: Scientific/Engineering :: Information Analysis",
          "Topic :: Scientific/Engineering :: Visualization",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_dist": [
          "pytest; extra == \"test\"",
          "pytest-cov; extra == \"test\"",
          "lxml>=3.6.0; extra == \"test\"",
          "cssselect>=0.9.1; extra == \"test\""
        ],
        "provides_extra": [
          "test"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/leather-0.4.1.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "idna",
        "version": "3.11",
        "summary": "Internationalized Domain Names in Applications (IDNA)",
        "description": "Internationalized Domain Names in Applications (IDNA)\n=====================================================\n\nSupport for `Internationalized Domain Names in\nApplications (IDNA) <https://tools.ietf.org/html/rfc5891>`_\nand `Unicode IDNA Compatibility Processing\n<https://unicode.org/reports/tr46/>`_.\n\nThe latest versions of these standards supplied here provide\nmore comprehensive language coverage and reduce the potential of\nallowing domains with known security vulnerabilities. This library\nis a suitable replacement for the â€œencodings.idnaâ€\nmodule that comes with the Python standard library, but which\nonly supports an older superseded IDNA specification from 2003.\n\nBasic functions are simply executed:\n\n.. code-block:: pycon\n\n    >>> import idna\n    >>> idna.encode('ãƒ‰ãƒ¡ã‚¤ãƒ³.ãƒ†ã‚¹ãƒˆ')\n    b'xn--eckwd4c7c.xn--zckzah'\n    >>> print(idna.decode('xn--eckwd4c7c.xn--zckzah'))\n    ãƒ‰ãƒ¡ã‚¤ãƒ³.ãƒ†ã‚¹ãƒˆ\n\n\nInstallation\n------------\n\nThis package is available for installation from PyPI via the\ntypical mechanisms, such as:\n\n.. code-block:: bash\n\n    $ python3 -m pip install idna\n\n\nUsage\n-----\n\nFor typical usage, the ``encode`` and ``decode`` functions will take a\ndomain name argument and perform a conversion to ASCII compatible encoding\n(known as A-labels), or to Unicode strings (known as U-labels)\nrespectively.\n\n.. code-block:: pycon\n\n    >>> import idna\n    >>> idna.encode('ãƒ‰ãƒ¡ã‚¤ãƒ³.ãƒ†ã‚¹ãƒˆ')\n    b'xn--eckwd4c7c.xn--zckzah'\n    >>> print(idna.decode('xn--eckwd4c7c.xn--zckzah'))\n    ãƒ‰ãƒ¡ã‚¤ãƒ³.ãƒ†ã‚¹ãƒˆ\n\nConversions can be applied at a per-label basis using the ``ulabel`` or\n``alabel`` functions if necessary:\n\n.. code-block:: pycon\n\n    >>> idna.alabel('æµ‹è¯•')\n    b'xn--0zwm56d'\n\n\nCompatibility Mapping (UTS #46)\n+++++++++++++++++++++++++++++++\n\nThis library provides support for `Unicode IDNA Compatibility\nProcessing <https://unicode.org/reports/tr46/>`_ which normalizes input from\ndifferent potential ways a user may input a domain prior to performing the IDNA\nconversion operations. This functionality, known as a \n`mapping <https://tools.ietf.org/html/rfc5895>`_, is considered by the\nspecification to be a local user-interface issue distinct from IDNA\nconversion functionality.\n\nFor example, â€œKÃ¶nigsgÃ¤ÃŸchenâ€ is not a permissible label as *LATIN\nCAPITAL LETTER K* is not allowed (nor are capital letters in general).\nUTS 46 will convert this into lower case prior to applying the IDNA\nconversion.\n\n.. code-block:: pycon\n\n    >>> import idna\n    >>> idna.encode('KÃ¶nigsgÃ¤ÃŸchen')\n    ...\n    idna.core.InvalidCodepoint: Codepoint U+004B at position 1 of 'KÃ¶nigsgÃ¤ÃŸchen' not allowed\n    >>> idna.encode('KÃ¶nigsgÃ¤ÃŸchen', uts46=True)\n    b'xn--knigsgchen-b4a3dun'\n    >>> print(idna.decode('xn--knigsgchen-b4a3dun'))\n    kÃ¶nigsgÃ¤ÃŸchen\n\n\nExceptions\n----------\n\nAll errors raised during the conversion following the specification\nshould raise an exception derived from the ``idna.IDNAError`` base\nclass.\n\nMore specific exceptions that may be generated as ``idna.IDNABidiError``\nwhen the error reflects an illegal combination of left-to-right and\nright-to-left characters in a label; ``idna.InvalidCodepoint`` when\na specific codepoint is an illegal character in an IDN label (i.e.\nINVALID); and ``idna.InvalidCodepointContext`` when the codepoint is\nillegal based on its position in the string (i.e. it is CONTEXTO or CONTEXTJ\nbut the contextual requirements are not satisfied.)\n\nBuilding and Diagnostics\n------------------------\n\nThe IDNA and UTS 46 functionality relies upon pre-calculated lookup\ntables for performance. These tables are derived from computing against\neligibility criteria in the respective standards using the command-line\nscript ``tools/idna-data``.\n\nThis tool will fetch relevant codepoint data from the Unicode repository\nand perform the required calculations to identify eligibility. There are\nthree main modes:\n\n* ``idna-data make-libdata``. Generates ``idnadata.py`` and\n  ``uts46data.py``, the pre-calculated lookup tables used for IDNA and\n  UTS 46 conversions. Implementers who wish to track this library against\n  a different Unicode version may use this tool to manually generate a\n  different version of the ``idnadata.py`` and ``uts46data.py`` files.\n\n* ``idna-data make-table``. Generate a table of the IDNA disposition\n  (e.g. PVALID, CONTEXTJ, CONTEXTO) in the format found in Appendix\n  B.1 of RFC 5892 and the pre-computed tables published by `IANA\n  <https://www.iana.org/>`_.\n\n* ``idna-data U+0061``. Prints debugging output on the various\n  properties associated with an individual Unicode codepoint (in this\n  case, U+0061), that are used to assess the IDNA and UTS 46 status of a\n  codepoint. This is helpful in debugging or analysis.\n\nThe tool accepts a number of arguments, described using ``idna-data\n-h``. Most notably, the ``--version`` argument allows the specification\nof the version of Unicode to be used in computing the table data. For\nexample, ``idna-data --version 9.0.0 make-libdata`` will generate\nlibrary data against Unicode 9.0.0.\n\n\nAdditional Notes\n----------------\n\n* **Packages**. The latest tagged release version is published in the\n  `Python Package Index <https://pypi.org/project/idna/>`_.\n\n* **Version support**. This library supports Python 3.8 and higher.\n  As this library serves as a low-level toolkit for a variety of\n  applications, many of which strive for broad compatibility with older\n  Python versions, there is no rush to remove older interpreter support.\n  Support for older versions are likely to be removed from new releases\n  as automated tests can no longer easily be run, i.e. once the Python\n  version is officially end-of-life.\n\n* **Testing**. The library has a test suite based on each rule of the\n  IDNA specification, as well as tests that are provided as part of the\n  Unicode Technical Standard 46, `Unicode IDNA Compatibility Processing\n  <https://unicode.org/reports/tr46/>`_.\n\n* **Emoji**. It is an occasional request to support emoji domains in\n  this library. Encoding of symbols like emoji is expressly prohibited by\n  the technical standard IDNA 2008 and emoji domains are broadly phased\n  out across the domain industry due to associated security risks. For\n  now, applications that need to support these non-compliant labels\n  may wish to consider trying the encode/decode operation in this library\n  first, and then falling back to using `encodings.idna`. See `the Github\n  project <https://github.com/kjd/idna/issues/18>`_ for more discussion.\n\n* **Transitional processing**. Unicode 16.0.0 removed transitional\n  processing so the `transitional` argument for the encode() method\n  no longer has any effect and will be removed at a later date.\n\n",
        "description_content_type": "text/x-rst",
        "author_email": "Kim Davies <kim+pypi@gumleaf.org>",
        "license_expression": "BSD-3-Clause",
        "license_file": [
          "LICENSE.md"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Intended Audience :: System Administrators",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet :: Name Service (DNS)",
          "Topic :: Software Development :: Libraries :: Python Modules",
          "Topic :: Utilities"
        ],
        "requires_dist": [
          "ruff >= 0.6.2 ; extra == \"all\"",
          "mypy >= 1.11.2 ; extra == \"all\"",
          "pytest >= 8.3.2 ; extra == \"all\"",
          "flake8 >= 7.1.1 ; extra == \"all\""
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Changelog, https://github.com/kjd/idna/blob/master/HISTORY.rst",
          "Issue tracker, https://github.com/kjd/idna/issues",
          "Source, https://github.com/kjd/idna"
        ],
        "provides_extra": [
          "all"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/idna-3.11.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "python-slugify",
        "version": "8.0.4",
        "summary": "A Python slugify application that also handles Unicode",
        "description": "# Python Slugify\n\n**A Python slugify application that handles unicode**.\n\n[![status-image]][status-link]\n[![version-image]][version-link]\n[![coverage-image]][coverage-link]\n\n# Overview\n\n**Best attempt** to create slugs from unicode strings while keeping it **DRY**.\n\n# Notice\n\nThis module, by default installs and uses [text-unidecode](https://github.com/kmike/text-unidecode) _(GPL & Perl Artistic)_ for its decoding needs.\n\nHowever, there is an alternative decoding package called [Unidecode](https://github.com/avian2/unidecode) _(GPL)_. It can be installed as `python-slugify[unidecode]` for those who prefer it. `Unidecode` is believed to be more [advanced](https://github.com/un33k/python-slugify/wiki/Python-Slugify-Wiki#notes-on-unidecode).\n\n### `Official` Support Matrix\n\n| Python         | Slugify            |\n| -------------- | ------------------ |\n| `>= 2.7 < 3.6` | `< 5.0.0`          |\n| `>= 3.6 < 3.7` | `>= 5.0.0 < 7.0.0` |\n| `>= 3.7`       | `>= 7.0.0`         |\n\n# How to install\n\n    easy_install python-slugify |OR| easy_install python-slugify[unidecode]\n    -- OR --\n    pip install python-slugify |OR| pip install python-slugify[unidecode]\n\n# Options\n\n```python\ndef slugify(\n    text: str,\n    entities: bool = True,\n    decimal: bool = True,\n    hexadecimal: bool = True,\n    max_length: int = 0,\n    word_boundary: bool = False,\n    separator: str = DEFAULT_SEPARATOR,\n    save_order: bool = False,\n    stopwords: Iterable[str] = (),\n    regex_pattern: str | None = None,\n    lowercase: bool = True,\n    replacements: Iterable[Iterable[str]] = (),\n    allow_unicode: bool = False,\n) -> str:\n  \"\"\"\n  Make a slug from the given text.\n  :param text (str): initial text\n  :param entities (bool): converts html entities to unicode (foo &amp; bar -> foo-bar)\n  :param decimal (bool): converts html decimal to unicode (&#381; -> Å½ -> z)\n  :param hexadecimal (bool): converts html hexadecimal to unicode (&#x17D; -> Å½ -> z)\n  :param max_length (int): output string length\n  :param word_boundary (bool): truncates to end of full words (length may be shorter than max_length)\n  :param save_order (bool): if parameter is True and max_length > 0 return whole words in the initial order\n  :param separator (str): separator between words\n  :param stopwords (iterable): words to discount\n  :param regex_pattern (str): regex pattern for disallowed characters\n  :param lowercase (bool): activate case sensitivity by setting it to False\n  :param replacements (iterable): list of replacement rules e.g. [['|', 'or'], ['%', 'percent']]\n  :param allow_unicode (bool): allow unicode characters\n  :return (str): slugify text\n  \"\"\"\n```\n\n# How to use\n\n```python\nfrom slugify import slugify\n\ntxt = \"This is a test ---\"\nr = slugify(txt)\nself.assertEqual(r, \"this-is-a-test\")\n\ntxt = 'å½±å¸«å—Ž'\nr = slugify(txt)\nself.assertEqual(r, \"ying-shi-ma\")\n\ntxt = 'å½±å¸«å—Ž'\nr = slugify(txt, allow_unicode=True)\nself.assertEqual(r, \"å½±å¸«å—Ž\")\n\ntxt = 'C\\'est dÃ©jÃ  l\\'Ã©tÃ©.'\nr = slugify(txt)\nself.assertEqual(r, \"c-est-deja-l-ete\")\n\ntxt = 'NÃ­n hÇŽo. WÇ’ shÃ¬ zhÅng guÃ³ rÃ©n'\nr = slugify(txt)\nself.assertEqual(r, \"nin-hao-wo-shi-zhong-guo-ren\")\n\ntxt = 'ÐšÐ¾Ð¼Ð¿ÑŒÑŽÑ‚ÐµÑ€'\nr = slugify(txt)\nself.assertEqual(r, \"kompiuter\")\n\ntxt = 'jaja---lol-mÃ©mÃ©mÃ©oo--a'\nr = slugify(txt, max_length=9)\nself.assertEqual(r, \"jaja-lol\")\n\ntxt = 'jaja---lol-mÃ©mÃ©mÃ©oo--a'\nr = slugify(txt, max_length=15, word_boundary=True)\nself.assertEqual(r, \"jaja-lol-a\")\n\ntxt = 'jaja---lol-mÃ©mÃ©mÃ©oo--a'\nr = slugify(txt, max_length=20, word_boundary=True, separator=\".\")\nself.assertEqual(r, \"jaja.lol.mememeoo.a\")\n\ntxt = 'one two three four five'\nr = slugify(txt, max_length=13, word_boundary=True, save_order=True)\nself.assertEqual(r, \"one-two-three\")\n\ntxt = 'the quick brown fox jumps over the lazy dog'\nr = slugify(txt, stopwords=['the'])\nself.assertEqual(r, 'quick-brown-fox-jumps-over-lazy-dog')\n\ntxt = 'the quick brown fox jumps over the lazy dog in a hurry'\nr = slugify(txt, stopwords=['the', 'in', 'a', 'hurry'])\nself.assertEqual(r, 'quick-brown-fox-jumps-over-lazy-dog')\n\ntxt = 'thIs Has a stopword Stopword'\nr = slugify(txt, stopwords=['Stopword'], lowercase=False)\nself.assertEqual(r, 'thIs-Has-a-stopword')\n\ntxt = \"___This is a test___\"\nregex_pattern = r'[^-a-z0-9_]+'\nr = slugify(txt, regex_pattern=regex_pattern)\nself.assertEqual(r, \"___this-is-a-test___\")\n\ntxt = \"___This is a test___\"\nregex_pattern = r'[^-a-z0-9_]+'\nr = slugify(txt, separator='_', regex_pattern=regex_pattern)\nself.assertNotEqual(r, \"_this_is_a_test_\")\n\ntxt = '10 | 20 %'\nr = slugify(txt, replacements=[['|', 'or'], ['%', 'percent']])\nself.assertEqual(r, \"10-or-20-percent\")\n\ntxt = 'ÃœBER Ãœber German Umlaut'\nr = slugify(txt, replacements=[['Ãœ', 'UE'], ['Ã¼', 'ue']])\nself.assertEqual(r, \"ueber-ueber-german-umlaut\")\n\ntxt = 'i love ðŸ¦„'\nr = slugify(txt, allow_unicode=True)\nself.assertEqual(r, \"i-love\")\n\ntxt = 'i love ðŸ¦„'\nr = slugify(txt, allow_unicode=True, regex_pattern=r'[^ðŸ¦„]+')\nself.assertEqual(r, \"ðŸ¦„\")\n\n```\n\nFor more examples, have a look at the [test.py](test.py) file.\n\n# Command Line Options\n\nWith the package, a command line tool called `slugify` is also installed.\n\nIt allows convenient command line access to all the features the `slugify` function supports. Call it with `-h` for help.\n\nThe command can take its input directly on the command line or from STDIN (when the `--stdin` flag is passed):\n\n```\n$ echo \"Taking input from STDIN\" | slugify --stdin\ntaking-input-from-stdin\n```\n\n```\n$ slugify taking input from the command line\ntaking-input-from-the-command-line\n```\n\nPlease note that when a multi-valued option such as `--stopwords` or `--replacements` is passed, you need to use `--` as separator before you start with the input:\n\n```\n$ slugify --stopwords the in a hurry -- the quick brown fox jumps over the lazy dog in a hurry\nquick-brown-fox-jumps-over-lazy-dog\n```\n\n# Running the tests\n\nTo run the tests against the current environment:\n\n    python test.py\n\n# Contribution\n\nPlease read the ([wiki](https://github.com/un33k/python-slugify/wiki/Python-Slugify-Wiki)) page prior to raising any PRs.\n\n# License\n\nReleased under a ([MIT](LICENSE)) license.\n\n### Notes on GPL dependencies\nThough the dependencies may be GPL licensed, `python-slugify` itself is not considered a derivative work and will remain under the MIT license.  \nIf you wish to avoid installation of any GPL licensed packages, please note that the default dependency `text-unidecode` explicitly lets you choose to use the [Artistic License](https://opensource.org/license/artistic-perl-1-0-2/) instead. Use without concern.\n\n# Version\n\nX.Y.Z Version\n\n    `MAJOR` version -- when you make incompatible API changes,\n    `MINOR` version -- when you add functionality in a backwards-compatible manner, and\n    `PATCH` version -- when you make backwards-compatible bug fixes.\n\n[status-image]: https://github.com/un33k/python-slugify/actions/workflows/ci.yml/badge.svg\n[status-link]: https://github.com/un33k/python-slugify/actions/workflows/ci.yml\n[version-image]: https://img.shields.io/pypi/v/python-slugify.svg\n[version-link]: https://pypi.python.org/pypi/python-slugify\n[coverage-image]: https://coveralls.io/repos/un33k/python-slugify/badge.svg\n[coverage-link]: https://coveralls.io/r/un33k/python-slugify\n[download-image]: https://img.shields.io/pypi/dm/python-slugify.svg\n[download-link]: https://pypi.python.org/pypi/python-slugify\n\n# Sponsors\n\n[Neekware Inc.](http://neekware.com)\n",
        "description_content_type": "text/markdown",
        "home_page": "https://github.com/un33k/python-slugify",
        "author": "Val Neekman",
        "author_email": "info@neekware.com",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "Natural Language :: English",
          "License :: OSI Approved :: MIT License",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12"
        ],
        "requires_dist": [
          "text-unidecode (>=1.3)",
          "Unidecode (>=1.1.1) ; extra == 'unidecode'"
        ],
        "requires_python": ">=3.7",
        "provides_extra": [
          "unidecode"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/python_slugify-8.0.4.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "requests",
        "version": "2.32.5",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "description-content-type",
          "home-page",
          "license",
          "license-file",
          "project-url",
          "provides-extra",
          "requires-dist",
          "requires-python",
          "summary"
        ],
        "summary": "Python HTTP for Humans.",
        "description": "# Requests\n\n**Requests** is a simple, yet elegant, HTTP library.\n\n```python\n>>> import requests\n>>> r = requests.get('https://httpbin.org/basic-auth/user/pass', auth=('user', 'pass'))\n>>> r.status_code\n200\n>>> r.headers['content-type']\n'application/json; charset=utf8'\n>>> r.encoding\n'utf-8'\n>>> r.text\n'{\"authenticated\": true, ...'\n>>> r.json()\n{'authenticated': True, ...}\n```\n\nRequests allows you to send HTTP/1.1 requests extremely easily. Thereâ€™s no need to manually add query strings to your URLs, or to form-encode your `PUT` & `POST` data â€” but nowadays, just use the `json` method!\n\nRequests is one of the most downloaded Python packages today, pulling in around `30M downloads / week`â€” according to GitHub, Requests is currently [depended upon](https://github.com/psf/requests/network/dependents?package_id=UGFja2FnZS01NzA4OTExNg%3D%3D) by `1,000,000+` repositories. You may certainly put your trust in this code.\n\n[![Downloads](https://static.pepy.tech/badge/requests/month)](https://pepy.tech/project/requests)\n[![Supported Versions](https://img.shields.io/pypi/pyversions/requests.svg)](https://pypi.org/project/requests)\n[![Contributors](https://img.shields.io/github/contributors/psf/requests.svg)](https://github.com/psf/requests/graphs/contributors)\n\n## Installing Requests and Supported Versions\n\nRequests is available on PyPI:\n\n```console\n$ python -m pip install requests\n```\n\nRequests officially supports Python 3.9+.\n\n## Supported Features & Bestâ€“Practices\n\nRequests is ready for the demands of building robust and reliable HTTPâ€“speaking applications, for the needs of today.\n\n- Keep-Alive & Connection Pooling\n- International Domains and URLs\n- Sessions with Cookie Persistence\n- Browser-style TLS/SSL Verification\n- Basic & Digest Authentication\n- Familiar `dict`â€“like Cookies\n- Automatic Content Decompression and Decoding\n- Multi-part File Uploads\n- SOCKS Proxy Support\n- Connection Timeouts\n- Streaming Downloads\n- Automatic honoring of `.netrc`\n- Chunked HTTP Requests\n\n## API Reference and User Guide available on [Read the Docs](https://requests.readthedocs.io)\n\n[![Read the Docs](https://raw.githubusercontent.com/psf/requests/main/ext/ss.png)](https://requests.readthedocs.io)\n\n## Cloning the repository\n\nWhen cloning the Requests repository, you may need to add the `-c\nfetch.fsck.badTimezone=ignore` flag to avoid an error about a bad commit timestamp (see\n[this issue](https://github.com/psf/requests/issues/2690) for more background):\n\n```shell\ngit clone -c fetch.fsck.badTimezone=ignore https://github.com/psf/requests.git\n```\n\nYou can also apply this setting to your global Git config:\n\n```shell\ngit config --global fetch.fsck.badTimezone ignore\n```\n\n---\n\n[![Kenneth Reitz](https://raw.githubusercontent.com/psf/requests/main/ext/kr.png)](https://kennethreitz.org) [![Python Software Foundation](https://raw.githubusercontent.com/psf/requests/main/ext/psf.png)](https://www.python.org/psf)\n",
        "description_content_type": "text/markdown",
        "home_page": "https://requests.readthedocs.io",
        "author": "Kenneth Reitz",
        "author_email": "me@kennethreitz.org",
        "license": "Apache-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Apache Software License",
          "Natural Language :: English",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet :: WWW/HTTP",
          "Topic :: Software Development :: Libraries"
        ],
        "requires_dist": [
          "charset_normalizer<4,>=2",
          "idna<4,>=2.5",
          "urllib3<3,>=1.21.1",
          "certifi>=2017.4.17",
          "PySocks!=1.5.7,>=1.5.6; extra == \"socks\"",
          "chardet<6,>=3.0.2; extra == \"use-chardet-on-py3\""
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Documentation, https://requests.readthedocs.io",
          "Source, https://github.com/psf/requests"
        ],
        "provides_extra": [
          "security",
          "socks",
          "use-chardet-on-py3"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/requests-2.32.5.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "tzdata",
        "version": "2025.3",
        "dynamic": [
          "license-file"
        ],
        "summary": "Provider of IANA time zone data",
        "description": "tzdata: Python package providing IANA time zone data\n====================================================\n\nThis is a Python package containing ``zic``-compiled binaries for the IANA time\nzone database. It is intended to be a fallback for systems that do not have\nsystem time zone data installed (or don't have it installed in a standard\nlocation), as a part of `PEP 615 <https://www.python.org/dev/peps/pep-0615/>`_\n\nThis repository generates a ``pip``-installable package, published on PyPI as\n`tzdata <https://pypi.org/project/tzdata>`_.\n\nFor more information, see `the documentation <https://tzdata.readthedocs.io>`_.\n",
        "description_content_type": "text/x-rst",
        "home_page": "https://github.com/python/tzdata",
        "author": "Python Software Foundation",
        "author_email": "datetime-sig@python.org",
        "license": "Apache-2.0",
        "license_file": [
          "LICENSE",
          "licenses/LICENSE_APACHE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 3"
        ],
        "requires_python": ">=2",
        "project_url": [
          "Bug Reports, https://github.com/python/tzdata/issues",
          "Source, https://github.com/python/tzdata",
          "Documentation, https://tzdata.readthedocs.io"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/tzdata-2025.3.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "sqlparse",
        "version": "0.5.4",
        "summary": "A non-validating SQL parser.",
        "description": "python-sqlparse - Parse SQL statements\n======================================\n\n|buildstatus|_\n|coverage|_\n|docs|_\n|packageversion|_\n\n.. docincludebegin\n\nsqlparse is a non-validating SQL parser for Python.\nIt provides support for parsing, splitting and formatting SQL statements.\n\nThe module is compatible with Python 3.8+ and released under the terms of the\n`New BSD license <https://opensource.org/licenses/BSD-3-Clause>`_.\n\nVisit the project page at https://github.com/andialbrecht/sqlparse for\nfurther information about this project.\n\n\nQuick Start\n-----------\n\n.. code-block:: sh\n\n   $ pip install sqlparse\n\n.. code-block:: python\n\n   >>> import sqlparse\n\n   >>> # Split a string containing two SQL statements:\n   >>> raw = 'select * from foo; select * from bar;'\n   >>> statements = sqlparse.split(raw)\n   >>> statements\n   ['select * from foo;', 'select * from bar;']\n\n   >>> # Format the first statement and print it out:\n   >>> first = statements[0]\n   >>> print(sqlparse.format(first, reindent=True, keyword_case='upper'))\n   SELECT *\n   FROM foo;\n\n   >>> # Parsing a SQL statement:\n   >>> parsed = sqlparse.parse('select * from foo')[0]\n   >>> parsed.tokens\n   [<DML 'select' at 0x7f22c5e15368>, <Whitespace ' ' at 0x7f22c5e153b0>, <Wildcard '*' â€¦ ]\n   >>>\n\nPre-commit Hook\n---------------\n\nsqlparse can be used as a `pre-commit <https://pre-commit.com/>`_ hook\nto automatically format SQL files before committing:\n\n.. code-block:: yaml\n\n   repos:\n     - repo: https://github.com/andialbrecht/sqlparse\n       rev: 0.5.4  # Use the latest version\n       hooks:\n         - id: sqlformat\n           # Optional: Add more formatting options\n           # IMPORTANT: --in-place is required, already included by default\n           args: [--in-place, --reindent, --keywords, upper]\n\nThen install the hook:\n\n.. code-block:: sh\n\n   $ pre-commit install\n\nYour SQL files will now be automatically formatted on each commit.\n\n**Note**: The hook uses ``--in-place --reindent`` by default. If you override\nthe ``args``, you **must** include ``--in-place`` for the hook to work.\n\nLinks\n-----\n\nProject page\n   https://github.com/andialbrecht/sqlparse\n\nBug tracker\n   https://github.com/andialbrecht/sqlparse/issues\n\nDocumentation\n   https://sqlparse.readthedocs.io/\n\nOnline Demo\n   https://sqlformat.org/\n\n\nsqlparse is licensed under the BSD license.\n\nParts of the code are based on pygments written by Georg Brandl and others.\npygments-Homepage: http://pygments.org/\n\n.. |buildstatus| image:: https://github.com/andialbrecht/sqlparse/actions/workflows/python-app.yml/badge.svg\n.. _buildstatus: https://github.com/andialbrecht/sqlparse/actions/workflows/python-app.yml\n.. |coverage| image:: https://codecov.io/gh/andialbrecht/sqlparse/branch/master/graph/badge.svg\n.. _coverage: https://codecov.io/gh/andialbrecht/sqlparse\n.. |docs| image:: https://readthedocs.org/projects/sqlparse/badge/?version=latest\n.. _docs: https://sqlparse.readthedocs.io/en/latest/?badge=latest\n.. |packageversion| image:: https://img.shields.io/pypi/v/sqlparse?color=%2334D058&label=pypi%20package\n.. _packageversion: https://pypi.org/project/sqlparse\n",
        "description_content_type": "text/x-rst",
        "author_email": "Andi Albrecht <albrecht.andi@gmail.com>",
        "license_file": [
          "AUTHORS",
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Database",
          "Topic :: Software Development"
        ],
        "requires_dist": [
          "build; extra == 'dev'",
          "sphinx; extra == 'doc'"
        ],
        "requires_python": ">=3.8",
        "project_url": [
          "Home, https://github.com/andialbrecht/sqlparse",
          "Documentation, https://sqlparse.readthedocs.io/",
          "Release Notes, https://sqlparse.readthedocs.io/en/latest/changes.html",
          "Source, https://github.com/andialbrecht/sqlparse",
          "Tracker, https://github.com/andialbrecht/sqlparse/issues"
        ],
        "provides_extra": [
          "dev",
          "doc"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/sqlparse-0.5.4.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "colorama",
        "version": "0.4.6",
        "summary": "Cross-platform colored terminal text.",
        "description": ".. image:: https://img.shields.io/pypi/v/colorama.svg\n    :target: https://pypi.org/project/colorama/\n    :alt: Latest Version\n\n.. image:: https://img.shields.io/pypi/pyversions/colorama.svg\n    :target: https://pypi.org/project/colorama/\n    :alt: Supported Python versions\n\n.. image:: https://github.com/tartley/colorama/actions/workflows/test.yml/badge.svg\n    :target: https://github.com/tartley/colorama/actions/workflows/test.yml\n    :alt: Build Status\n\nColorama\n========\n\nMakes ANSI escape character sequences (for producing colored terminal text and\ncursor positioning) work under MS Windows.\n\n.. |donate| image:: https://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif\n  :target: https://www.paypal.com/cgi-bin/webscr?cmd=_donations&business=2MZ9D2GMLYCUJ&item_name=Colorama&currency_code=USD\n  :alt: Donate with Paypal\n\n`PyPI for releases <https://pypi.org/project/colorama/>`_ |\n`Github for source <https://github.com/tartley/colorama>`_ |\n`Colorama for enterprise on Tidelift <https://github.com/tartley/colorama/blob/master/ENTERPRISE.md>`_\n\nIf you find Colorama useful, please |donate| to the authors. Thank you!\n\nInstallation\n------------\n\nTested on CPython 2.7, 3.7, 3.8, 3.9 and 3.10 and Pypy 2.7 and 3.8.\n\nNo requirements other than the standard library.\n\n.. code-block:: bash\n\n    pip install colorama\n    # or\n    conda install -c anaconda colorama\n\nDescription\n-----------\n\nANSI escape character sequences have long been used to produce colored terminal\ntext and cursor positioning on Unix and Macs. Colorama makes this work on\nWindows, too, by wrapping ``stdout``, stripping ANSI sequences it finds (which\nwould appear as gobbledygook in the output), and converting them into the\nappropriate win32 calls to modify the state of the terminal. On other platforms,\nColorama does nothing.\n\nThis has the upshot of providing a simple cross-platform API for printing\ncolored terminal text from Python, and has the happy side-effect that existing\napplications or libraries which use ANSI sequences to produce colored output on\nLinux or Macs can now also work on Windows, simply by calling\n``colorama.just_fix_windows_console()`` (since v0.4.6) or ``colorama.init()``\n(all versions, but may have other side-effects â€“ see below).\n\nAn alternative approach is to install ``ansi.sys`` on Windows machines, which\nprovides the same behaviour for all applications running in terminals. Colorama\nis intended for situations where that isn't easy (e.g., maybe your app doesn't\nhave an installer.)\n\nDemo scripts in the source code repository print some colored text using\nANSI sequences. Compare their output under Gnome-terminal's built in ANSI\nhandling, versus on Windows Command-Prompt using Colorama:\n\n.. image:: https://github.com/tartley/colorama/raw/master/screenshots/ubuntu-demo.png\n    :width: 661\n    :height: 357\n    :alt: ANSI sequences on Ubuntu under gnome-terminal.\n\n.. image:: https://github.com/tartley/colorama/raw/master/screenshots/windows-demo.png\n    :width: 668\n    :height: 325\n    :alt: Same ANSI sequences on Windows, using Colorama.\n\nThese screenshots show that, on Windows, Colorama does not support ANSI 'dim\ntext'; it looks the same as 'normal text'.\n\nUsage\n-----\n\nInitialisation\n..............\n\nIf the only thing you want from Colorama is to get ANSI escapes to work on\nWindows, then run:\n\n.. code-block:: python\n\n    from colorama import just_fix_windows_console\n    just_fix_windows_console()\n\nIf you're on a recent version of Windows 10 or better, and your stdout/stderr\nare pointing to a Windows console, then this will flip the magic configuration\nswitch to enable Windows' built-in ANSI support.\n\nIf you're on an older version of Windows, and your stdout/stderr are pointing to\na Windows console, then this will wrap ``sys.stdout`` and/or ``sys.stderr`` in a\nmagic file object that intercepts ANSI escape sequences and issues the\nappropriate Win32 calls to emulate them.\n\nIn all other circumstances, it does nothing whatsoever. Basically the idea is\nthat this makes Windows act like Unix with respect to ANSI escape handling.\n\nIt's safe to call this function multiple times. It's safe to call this function\non non-Windows platforms, but it won't do anything. It's safe to call this\nfunction when one or both of your stdout/stderr are redirected to a file â€“ it\nwon't do anything to those streams.\n\nAlternatively, you can use the older interface with more features (but also more\npotential footguns):\n\n.. code-block:: python\n\n    from colorama import init\n    init()\n\nThis does the same thing as ``just_fix_windows_console``, except for the\nfollowing differences:\n\n- It's not safe to call ``init`` multiple times; you can end up with multiple\n  layers of wrapping and broken ANSI support.\n\n- Colorama will apply a heuristic to guess whether stdout/stderr support ANSI,\n  and if it thinks they don't, then it will wrap ``sys.stdout`` and\n  ``sys.stderr`` in a magic file object that strips out ANSI escape sequences\n  before printing them. This happens on all platforms, and can be convenient if\n  you want to write your code to emit ANSI escape sequences unconditionally, and\n  let Colorama decide whether they should actually be output. But note that\n  Colorama's heuristic is not particularly clever.\n\n- ``init`` also accepts explicit keyword args to enable/disable various\n  functionality â€“ see below.\n\nTo stop using Colorama before your program exits, simply call ``deinit()``.\nThis will restore ``stdout`` and ``stderr`` to their original values, so that\nColorama is disabled. To resume using Colorama again, call ``reinit()``; it is\ncheaper than calling ``init()`` again (but does the same thing).\n\nMost users should depend on ``colorama >= 0.4.6``, and use\n``just_fix_windows_console``. The old ``init`` interface will be supported\nindefinitely for backwards compatibility, but we don't plan to fix any issues\nwith it, also for backwards compatibility.\n\nColored Output\n..............\n\nCross-platform printing of colored text can then be done using Colorama's\nconstant shorthand for ANSI escape sequences. These are deliberately\nrudimentary, see below.\n\n.. code-block:: python\n\n    from colorama import Fore, Back, Style\n    print(Fore.RED + 'some red text')\n    print(Back.GREEN + 'and with a green background')\n    print(Style.DIM + 'and in dim text')\n    print(Style.RESET_ALL)\n    print('back to normal now')\n\n...or simply by manually printing ANSI sequences from your own code:\n\n.. code-block:: python\n\n    print('\\033[31m' + 'some red text')\n    print('\\033[39m') # and reset to default color\n\n...or, Colorama can be used in conjunction with existing ANSI libraries\nsuch as the venerable `Termcolor <https://pypi.org/project/termcolor/>`_\nthe fabulous `Blessings <https://pypi.org/project/blessings/>`_,\nor the incredible `_Rich <https://pypi.org/project/rich/>`_.\n\nIf you wish Colorama's Fore, Back and Style constants were more capable,\nthen consider using one of the above highly capable libraries to generate\ncolors, etc, and use Colorama just for its primary purpose: to convert\nthose ANSI sequences to also work on Windows:\n\nSIMILARLY, do not send PRs adding the generation of new ANSI types to Colorama.\nWe are only interested in converting ANSI codes to win32 API calls, not\nshortcuts like the above to generate ANSI characters.\n\n.. code-block:: python\n\n    from colorama import just_fix_windows_console\n    from termcolor import colored\n\n    # use Colorama to make Termcolor work on Windows too\n    just_fix_windows_console()\n\n    # then use Termcolor for all colored text output\n    print(colored('Hello, World!', 'green', 'on_red'))\n\nAvailable formatting constants are::\n\n    Fore: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.\n    Back: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.\n    Style: DIM, NORMAL, BRIGHT, RESET_ALL\n\n``Style.RESET_ALL`` resets foreground, background, and brightness. Colorama will\nperform this reset automatically on program exit.\n\nThese are fairly well supported, but not part of the standard::\n\n    Fore: LIGHTBLACK_EX, LIGHTRED_EX, LIGHTGREEN_EX, LIGHTYELLOW_EX, LIGHTBLUE_EX, LIGHTMAGENTA_EX, LIGHTCYAN_EX, LIGHTWHITE_EX\n    Back: LIGHTBLACK_EX, LIGHTRED_EX, LIGHTGREEN_EX, LIGHTYELLOW_EX, LIGHTBLUE_EX, LIGHTMAGENTA_EX, LIGHTCYAN_EX, LIGHTWHITE_EX\n\nCursor Positioning\n..................\n\nANSI codes to reposition the cursor are supported. See ``demos/demo06.py`` for\nan example of how to generate them.\n\nInit Keyword Args\n.................\n\n``init()`` accepts some ``**kwargs`` to override default behaviour.\n\ninit(autoreset=False):\n    If you find yourself repeatedly sending reset sequences to turn off color\n    changes at the end of every print, then ``init(autoreset=True)`` will\n    automate that:\n\n    .. code-block:: python\n\n        from colorama import init\n        init(autoreset=True)\n        print(Fore.RED + 'some red text')\n        print('automatically back to default color again')\n\ninit(strip=None):\n    Pass ``True`` or ``False`` to override whether ANSI codes should be\n    stripped from the output. The default behaviour is to strip if on Windows\n    or if output is redirected (not a tty).\n\ninit(convert=None):\n    Pass ``True`` or ``False`` to override whether to convert ANSI codes in the\n    output into win32 calls. The default behaviour is to convert if on Windows\n    and output is to a tty (terminal).\n\ninit(wrap=True):\n    On Windows, Colorama works by replacing ``sys.stdout`` and ``sys.stderr``\n    with proxy objects, which override the ``.write()`` method to do their work.\n    If this wrapping causes you problems, then this can be disabled by passing\n    ``init(wrap=False)``. The default behaviour is to wrap if ``autoreset`` or\n    ``strip`` or ``convert`` are True.\n\n    When wrapping is disabled, colored printing on non-Windows platforms will\n    continue to work as normal. To do cross-platform colored output, you can\n    use Colorama's ``AnsiToWin32`` proxy directly:\n\n    .. code-block:: python\n\n        import sys\n        from colorama import init, AnsiToWin32\n        init(wrap=False)\n        stream = AnsiToWin32(sys.stderr).stream\n\n        # Python 2\n        print >>stream, Fore.BLUE + 'blue text on stderr'\n\n        # Python 3\n        print(Fore.BLUE + 'blue text on stderr', file=stream)\n\nRecognised ANSI Sequences\n.........................\n\nANSI sequences generally take the form::\n\n    ESC [ <param> ; <param> ... <command>\n\nWhere ``<param>`` is an integer, and ``<command>`` is a single letter. Zero or\nmore params are passed to a ``<command>``. If no params are passed, it is\ngenerally synonymous with passing a single zero. No spaces exist in the\nsequence; they have been inserted here simply to read more easily.\n\nThe only ANSI sequences that Colorama converts into win32 calls are::\n\n    ESC [ 0 m       # reset all (colors and brightness)\n    ESC [ 1 m       # bright\n    ESC [ 2 m       # dim (looks same as normal brightness)\n    ESC [ 22 m      # normal brightness\n\n    # FOREGROUND:\n    ESC [ 30 m      # black\n    ESC [ 31 m      # red\n    ESC [ 32 m      # green\n    ESC [ 33 m      # yellow\n    ESC [ 34 m      # blue\n    ESC [ 35 m      # magenta\n    ESC [ 36 m      # cyan\n    ESC [ 37 m      # white\n    ESC [ 39 m      # reset\n\n    # BACKGROUND\n    ESC [ 40 m      # black\n    ESC [ 41 m      # red\n    ESC [ 42 m      # green\n    ESC [ 43 m      # yellow\n    ESC [ 44 m      # blue\n    ESC [ 45 m      # magenta\n    ESC [ 46 m      # cyan\n    ESC [ 47 m      # white\n    ESC [ 49 m      # reset\n\n    # cursor positioning\n    ESC [ y;x H     # position cursor at x across, y down\n    ESC [ y;x f     # position cursor at x across, y down\n    ESC [ n A       # move cursor n lines up\n    ESC [ n B       # move cursor n lines down\n    ESC [ n C       # move cursor n characters forward\n    ESC [ n D       # move cursor n characters backward\n\n    # clear the screen\n    ESC [ mode J    # clear the screen\n\n    # clear the line\n    ESC [ mode K    # clear the line\n\nMultiple numeric params to the ``'m'`` command can be combined into a single\nsequence::\n\n    ESC [ 36 ; 45 ; 1 m     # bright cyan text on magenta background\n\nAll other ANSI sequences of the form ``ESC [ <param> ; <param> ... <command>``\nare silently stripped from the output on Windows.\n\nAny other form of ANSI sequence, such as single-character codes or alternative\ninitial characters, are not recognised or stripped. It would be cool to add\nthem though. Let me know if it would be useful for you, via the Issues on\nGitHub.\n\nStatus & Known Problems\n-----------------------\n\nI've personally only tested it on Windows XP (CMD, Console2), Ubuntu\n(gnome-terminal, xterm), and OS X.\n\nSome valid ANSI sequences aren't recognised.\n\nIf you're hacking on the code, see `README-hacking.md`_. ESPECIALLY, see the\nexplanation there of why we do not want PRs that allow Colorama to generate new\ntypes of ANSI codes.\n\nSee outstanding issues and wish-list:\nhttps://github.com/tartley/colorama/issues\n\nIf anything doesn't work for you, or doesn't do what you expected or hoped for,\nI'd love to hear about it on that issues list, would be delighted by patches,\nand would be happy to grant commit access to anyone who submits a working patch\nor two.\n\n.. _README-hacking.md: README-hacking.md\n\nLicense\n-------\n\nCopyright Jonathan Hartley & Arnon Yaari, 2013-2020. BSD 3-Clause license; see\nLICENSE file.\n\nProfessional support\n--------------------\n\n.. |tideliftlogo| image:: https://cdn2.hubspot.net/hubfs/4008838/website/logos/logos_for_download/Tidelift_primary-shorthand-logo.png\n   :alt: Tidelift\n   :target: https://tidelift.com/subscription/pkg/pypi-colorama?utm_source=pypi-colorama&utm_medium=referral&utm_campaign=readme\n\n.. list-table::\n   :widths: 10 100\n\n   * - |tideliftlogo|\n     - Professional support for colorama is available as part of the\n       `Tidelift Subscription`_.\n       Tidelift gives software development teams a single source for purchasing\n       and maintaining their software, with professional grade assurances from\n       the experts who know it best, while seamlessly integrating with existing\n       tools.\n\n.. _Tidelift Subscription: https://tidelift.com/subscription/pkg/pypi-colorama?utm_source=pypi-colorama&utm_medium=referral&utm_campaign=readme\n\nThanks\n------\n\nSee the CHANGELOG for more thanks!\n\n* Marc Schlaich (schlamar) for a ``setup.py`` fix for Python2.5.\n* Marc Abramowitz, reported & fixed a crash on exit with closed ``stdout``,\n  providing a solution to issue #7's setuptools/distutils debate,\n  and other fixes.\n* User 'eryksun', for guidance on correctly instantiating ``ctypes.windll``.\n* Matthew McCormick for politely pointing out a longstanding crash on non-Win.\n* Ben Hoyt, for a magnificent fix under 64-bit Windows.\n* Jesse at Empty Square for submitting a fix for examples in the README.\n* User 'jamessp', an observant documentation fix for cursor positioning.\n* User 'vaal1239', Dave Mckee & Lackner Kristof for a tiny but much-needed Win7\n  fix.\n* Julien Stuyck, for wisely suggesting Python3 compatible updates to README.\n* Daniel Griffith for multiple fabulous patches.\n* Oscar Lesta for a valuable fix to stop ANSI chars being sent to non-tty\n  output.\n* Roger Binns, for many suggestions, valuable feedback, & bug reports.\n* Tim Golden for thought and much appreciated feedback on the initial idea.\n* User 'Zearin' for updates to the README file.\n* John Szakmeister for adding support for light colors\n* Charles Merriam for adding documentation to demos\n* Jurko for a fix on 64-bit Windows CPython2.5 w/o ctypes\n* Florian Bruhin for a fix when stdout or stderr are None\n* Thomas Weininger for fixing ValueError on Windows\n* Remi Rampin for better Github integration and fixes to the README file\n* Simeon Visser for closing a file handle using 'with' and updating classifiers\n  to include Python 3.3 and 3.4\n* Andy Neff for fixing RESET of LIGHT_EX colors.\n* Jonathan Hartley for the initial idea and implementation.\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "ansi",
          "color",
          "colour",
          "crossplatform",
          "terminal",
          "text",
          "windows",
          "xplatform"
        ],
        "author_email": "Jonathan Hartley <tartley@tartley.com>",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Environment :: Console",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Terminals"
        ],
        "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,!=3.5.*,!=3.6.*,>=2.7",
        "project_url": [
          "Homepage, https://github.com/tartley/colorama"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/colorama-0.4.6.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "six",
        "version": "1.17.0",
        "summary": "Python 2 and 3 compatibility utilities",
        "description": ".. image:: https://img.shields.io/pypi/v/six.svg\n   :target: https://pypi.org/project/six/\n   :alt: six on PyPI\n\n.. image:: https://readthedocs.org/projects/six/badge/?version=latest\n   :target: https://six.readthedocs.io/\n   :alt: six's documentation on Read the Docs\n\n.. image:: https://img.shields.io/badge/license-MIT-green.svg\n   :target: https://github.com/benjaminp/six/blob/master/LICENSE\n   :alt: MIT License badge\n\nSix is a Python 2 and 3 compatibility library.  It provides utility functions\nfor smoothing over the differences between the Python versions with the goal of\nwriting Python code that is compatible on both Python versions.  See the\ndocumentation for more information on what is provided.\n\nSix supports Python 2.7 and 3.3+.  It is contained in only one Python\nfile, so it can be easily copied into your project. (The copyright and license\nnotice must be retained.)\n\nOnline documentation is at https://six.readthedocs.io/.\n\nBugs can be reported to https://github.com/benjaminp/six.  The code can also\nbe found there.\n",
        "home_page": "https://github.com/benjaminp/six",
        "author": "Benjamin Peterson",
        "author_email": "benjamin@python.org",
        "license": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Programming Language :: Python :: 2",
          "Programming Language :: Python :: 3",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: MIT License",
          "Topic :: Software Development :: Libraries",
          "Topic :: Utilities"
        ],
        "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*"
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/six-1.17.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "duckdb",
        "version": "1.4.3",
        "summary": "DuckDB in-process database",
        "description": "<div align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/duckdb/duckdb/refs/heads/main/logo/DuckDB_Logo-horizontal.svg\">\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/duckdb/duckdb/refs/heads/main/logo/DuckDB_Logo-horizontal-dark-mode.svg\">\n    <img alt=\"DuckDB logo\" src=\"https://raw.githubusercontent.com/duckdb/duckdb/refs/heads/main/logo/DuckDB_Logo-horizontal.svg\" height=\"100\">\n  </picture>\n</div>\n<br />\n<p align=\"center\">\n  <a href=\"https://discord.gg/tcvwpjfnZx\"><img src=\"https://shields.io/discord/909674491309850675\" alt=\"Discord\" /></a>\n  <a href=\"https://pypi.org/project/duckdb/\"><img src=\"https://img.shields.io/pypi/v/duckdb.svg\" alt=\"PyPI Latest Release\"/></a>\n</p>\n<br />\n<p align=\"center\">\n  <a href=\"https://duckdb.org\">DuckDB.org</a>\n  |\n  <a href=\"https://duckdb.org/docs/stable/guides/python/install\">User Guide (Python)</a>\n  -\n  <a href=\"https://duckdb.org/docs/stable/clients/python/overview\">API Docs (Python)</a>\n</p>\n\n# DuckDB: A Fast, In-Process, Portable, Open Source, Analytical Database System\n\n* **Simple**: DuckDB is easy to install and deploy. It has zero external dependencies and runs in-process in its host application or as a single binary.\n* **Portable**: DuckDB runs on Linux, macOS, Windows, Android, iOS and all popular hardware architectures. It has idiomatic client APIs for major programming languages.\n* **Feature-rich**: DuckDB offers a rich SQL dialect. It can read and write file formats such as CSV, Parquet, and JSON, to and from the local file system and remote endpoints such as S3 buckets.\n* **Fast**: DuckDB runs analytical queries at blazing speed thanks to its columnar engine, which supports parallel execution and can process larger-than-memory workloads.\n* **Extensible**: DuckDB is extensible by third-party features such as new data types, functions, file formats and new SQL syntax. User contributions are available as community extensions.\n* **Free**: DuckDB and its core extensions are open-source under the permissive MIT License. The intellectual property of the project is held by the DuckDB Foundation.\n\n## Installation\n\nInstall the latest release of DuckDB directly from [PyPI](https://pypi.org/project/duckdb/):\n\n```bash\npip install duckdb\n```\n\nInstall with all optional dependencies:\n\n```bash\npip install 'duckdb[all]'\n```\n\n## Contributing\n\nSee the [CONTRIBUTING.md](CONTRIBUTING.md) for instructions on how to set up a development environment.\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "DuckDB",
          "Database",
          "SQL",
          "OLAP"
        ],
        "author": "DuckDB Foundation",
        "maintainer": "DuckDB Foundation",
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "License :: OSI Approved :: MIT License",
          "Operating System :: OS Independent",
          "Topic :: Database",
          "Topic :: Database :: Database Engines/Servers",
          "Topic :: Scientific/Engineering",
          "Intended Audience :: Developers",
          "Intended Audience :: Education",
          "Intended Audience :: Information Technology",
          "Intended Audience :: Science/Research",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: C++"
        ],
        "requires_dist": [
          "ipython; extra == \"all\"",
          "fsspec; extra == \"all\"",
          "numpy; extra == \"all\"",
          "pandas; extra == \"all\"",
          "pyarrow; extra == \"all\"",
          "adbc-driver-manager; extra == \"all\""
        ],
        "requires_python": ">=3.9.0",
        "project_url": [
          "Documentation, https://duckdb.org/docs/stable/clients/python/overview",
          "Source, https://github.com/duckdb/duckdb-python",
          "Issues, https://github.com/duckdb/duckdb-python/issues",
          "Changelog, https://github.com/duckdb/duckdb-python/releases"
        ],
        "provides_extra": [
          "all"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/duckdb-1.4.3.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "isodate",
        "version": "0.7.2",
        "summary": "An ISO 8601 date/time/duration parser and formatter",
        "description": "\nISO 8601 date/time parser\n=========================\n\n.. image:: https://travis-ci.org/gweis/isodate.svg?branch=master\n    :target: https://travis-ci.org/gweis/isodate\n    :alt: Travis-CI\n.. image:: https://coveralls.io/repos/gweis/isodate/badge.svg?branch=master\n    :target: https://coveralls.io/r/gweis/isodate?branch=master\n    :alt: Coveralls\n.. image:: https://img.shields.io/pypi/v/isodate.svg\n    :target: https://pypi.python.org/pypi/isodate/\n    :alt: Latest Version\n.. image:: https://img.shields.io/pypi/l/isodate.svg\n    :target: https://pypi.python.org/pypi/isodate/\n    :alt: License\n\n\nThis module implements ISO 8601 date, time and duration parsing.\nThe implementation follows ISO8601:2004 standard, and implements only\ndate/time representations mentioned in the standard. If something is not\nmentioned there, then it is treated as non existent, and not as an allowed\noption.\n\nFor instance, ISO8601:2004 never mentions 2 digit years. So, it is not\nintended by this module to support 2 digit years. (while it may still\nbe valid as ISO date, because it is not explicitly forbidden.)\nAnother example is, when no time zone information is given for a time,\nthen it should be interpreted as local time, and not UTC.\n\nAs this module maps ISO 8601 dates/times to standard Python data types, like\n*date*, *time*, *datetime* and *timedelta*, it is not possible to convert\nall possible ISO 8601 dates/times. For instance, dates before 0001-01-01 are\nnot allowed by the Python *date* and *datetime* classes. Additionally\nfractional seconds are limited to microseconds. That means if the parser finds\nfor instance nanoseconds it will round it down to microseconds.\n\nDocumentation\n-------------\n\nThe following parsing methods are available.\n   * parse_time:\n        parses an ISO 8601 time string into a *time* object\n   * parse_date:\n        parses an ISO 8601 date string into a *date* object\n   * parse_datetime:\n        parses an ISO 8601 date-time string into a *datetime* object\n   * parse_duration:\n        parses an ISO 8601 duration string into a *timedelta* or *Duration*\n        object.\n   * parse_tzinfo:\n        parses the time zone info part of an ISO 8601 string into a\n        *tzinfo* object.\n\nAs ISO 8601 allows to define durations in years and months, and *timedelta*\ndoes not handle years and months, this module provides a *Duration* class,\nwhich can be used almost like a *timedelta* object (with some limitations).\nHowever, a *Duration* object can be converted into a *timedelta* object.\n\nThere are also ISO formatting methods for all supported data types. Each\n*xxx_isoformat* method accepts a format parameter. The default format is\nalways the ISO 8601 expanded format. This is the same format used by\n*datetime.isoformat*:\n\n    * time_isoformat:\n        Intended to create ISO time strings with default format\n        *hh:mm:ssZ*.\n    * date_isoformat:\n        Intended to create ISO date strings with default format\n        *yyyy-mm-dd*.\n    * datetime_isoformat:\n        Intended to create ISO date-time strings with default format\n        *yyyy-mm-ddThh:mm:ssZ*.\n    * duration_isoformat:\n        Intended to create ISO duration strings with default format\n        *PnnYnnMnnDTnnHnnMnnS*.\n    * tz_isoformat:\n        Intended to create ISO time zone strings with default format\n        *hh:mm*.\n    * strftime:\n        A re-implementation mostly compatible with Python's *strftime*, but\n        supports only those format strings, which can also be used for dates\n        prior 1900. This method also understands how to format *datetime* and\n        *Duration* instances.\n\nInstallation\n------------\n\nThis module can easily be installed with Python standard installation methods.\n\nUse *pip install isodate*.\n\nLimitations\n-----------\n\n   * The parser accepts several date/time representation which should be invalid\n     according to ISO 8601 standard.\n\n     1. for date and time together, this parser accepts a mixture of basic and extended format.\n        e.g. the date could be in basic format, while the time is accepted in extended format.\n        It also allows short dates and times in date-time strings.\n     2. For incomplete dates, the first day is chosen. e.g. 19th century results in a date of\n        1901-01-01.\n     3. negative *Duration* and *timedelta* value are not fully supported yet.\n\nFurther information\n-------------------\n\nThe doc strings and unit tests should provide rather detailed information about\nthe methods and their limitations.\n\nThe source release provides a *setup.py* script,\nwhich can be used to run the unit tests included.\n\nSource code is available at `<https://github.com/gweis/isodate>`_.\n\n\nCHANGES\n=======\n\n0.7.3 (unreleased)\n------------------\n\n- no changes yet\n\n\n0.7.2 (2024-10-08)\n------------------\n\n- drop end of life python versions\n- Don't match garbage characters at the end of parsed strings #16 (Gabriel de Perthuis)\n\n\nPotentially breaking changes:\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- Fractional seconds are cut off to microseconds (always round down)\n- Allow control over return type of parse_duration #64 (Felix Claessen)\n- Python >= 3.7 required\n\n\n0.6.1 (2021-12-13)\n------------------\n\n- support python 3.10 (Hugo van Kemenade)\n- last version to support py 2.7\n\n\n0.6.0 (2017-10-13)\n------------------\n\n- support incomplete month date (Fabien Loffredo)\n- rely on duck typing when doing duration maths\n- support ':' as separator in fractional time zones (usrenmae)\n\n\n0.5.4 (2015-08-06)\n------------------\n\n- Fix parsing of Periods (Fabien Bochu)\n- Make Duration objects hashable (Geoffrey Fairchild)\n- Add multiplication to duration (Reinoud Elhorst)\n\n\n0.5.1 (2014-11-07)\n------------------\n\n- fixed pickling of Duration objects\n- raise ISO8601Error when there is no 'T' separator in datetime strings (Adrian Coveney)\n\n\n0.5.0 (2014-02-23)\n------------------\n\n- ISO8601Error are subclasses of ValueError now (Michael Hrivnak)\n- improve compatibility across various python variants and versions\n- raise exceptions when using fractional years and months in date\n  maths with durations\n- renamed method todatetime on Duraction objects to totimedelta\n\n\n0.4.9 (2012-10-30)\n------------------\n\n- support pickling FixedOffset instances\n- make sure parsed fractional seconds are in microseconds\n- add leading zeros when formattig microseconds (Jarom Loveridge)\n\n\n0.4.8 (2012-05-04)\n------------------\n\n- fixed incompatibility of unittests with python 2.5 and 2.6 (runs fine on 2.7\n  and 3.2)\n\n\n0.4.7 (2012-01-26)\n------------------\n\n- fixed tzinfo formatting (never pass None into tzinfo.utcoffset())\n\n\n0.4.6 (2012-01-06)\n------------------\n\n- added Python 3 compatibility via 2to3\n\n0.4.5 (2012-01-06)\n------------------\n\n- made setuptools dependency optional\n\n0.4.4 (2011-04-16)\n------------------\n\n- Fixed formatting of microseconds for datetime objects\n\n0.4.3 (2010-10-29)\n------------------\n\n- Fixed problem with %P formatting and fractions (supplied by David Brooks)\n\n0.4.2 (2010-10-28)\n------------------\n\n- Implemented unary - for Duration (supplied by David Brooks)\n- Output fractional seconds with '%P' format. (partly supplied by David Brooks)\n\n0.4.1 (2010-10-13)\n------------------\n\n- fixed bug in comparison between timedelta and Duration.\n- fixed precision problem with microseconds (reported by Tommi Virtanen)\n\n0.4.0 (2009-02-09)\n------------------\n\n- added method to parse ISO 8601 time zone strings\n- added methods to create ISO 8601 conforming strings\n\n0.3.0 (2009-1-05)\n------------------\n\n- Initial release\n\n\nTODOs\n=====\n\nThis to do list contains some thoughts and ideas about missing features, and\nparts to think about, whether to implement them or not. This list is probably\nnot complete.\n\nMissing features:\n-----------------\n\n    * time formatting does not allow to create fractional representations.\n    * parser for ISO intervals.\n    * currently microseconds are always padded to a length of 6 characters.\n      trailing 0s should be optional\n\nDocumentation:\n--------------\n\n    * parse_datetime:\n       - complete documentation to show what this function allows, but ISO forbids.\n         and vice verse.\n       - support other separators between date and time than 'T'\n\n    * parse_date:\n       - yeardigits should be always greater than 4\n       - dates before 0001-01-01 are not supported\n\n    * parse_duration:\n       - alternative formats are not fully supported due to parse_date restrictions\n       - standard duration format is fully supported but not very restrictive.\n\n    * Duration:\n       - support fractional years and month in calculations\n       - implement w3c order relation? (`<http://www.w3.org/TR/xmlschema-2/#duration-order>`_)\n       - refactor to have duration mathematics only at one place.\n       - localize __str__ method (does timedelta do this?)\n       - when is a Duration negative?\n       - normalize Durations. months [00-12] and years ]-inf,+inf[\n",
        "description_content_type": "text/x-rst",
        "author": "Gerhard Weis",
        "license": "Copyright (c) 2021, Hugo van Kemenade and contributors\nCopyright (c) 2009-2018, Gerhard Weis and contributors\nCopyright (c) 2009, Gerhard Weis\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n    * Neither the name of the <organization> nor the\n      names of its contributors may be used to endorse or promote products\n      derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 4 - Beta",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: BSD License",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet",
          "Topic :: Software Development :: Libraries :: Python Modules"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Homepage, https://github.com/gweis/isodate/"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/isodate-0.7.2.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "certifi",
        "version": "2026.1.4",
        "dynamic": [
          "author",
          "author-email",
          "classifier",
          "description",
          "home-page",
          "license",
          "license-file",
          "project-url",
          "requires-python",
          "summary"
        ],
        "summary": "Python package for providing Mozilla's CA Bundle.",
        "description": "Certifi: Python SSL Certificates\n================================\n\nCertifi provides Mozilla's carefully curated collection of Root Certificates for\nvalidating the trustworthiness of SSL certificates while verifying the identity\nof TLS hosts. It has been extracted from the `Requests`_ project.\n\nInstallation\n------------\n\n``certifi`` is available on PyPI. Simply install it with ``pip``::\n\n    $ pip install certifi\n\nUsage\n-----\n\nTo reference the installed certificate authority (CA) bundle, you can use the\nbuilt-in function::\n\n    >>> import certifi\n\n    >>> certifi.where()\n    '/usr/local/lib/python3.7/site-packages/certifi/cacert.pem'\n\nOr from the command line::\n\n    $ python -m certifi\n    /usr/local/lib/python3.7/site-packages/certifi/cacert.pem\n\nEnjoy!\n\n.. _`Requests`: https://requests.readthedocs.io/en/master/\n\nAddition/Removal of Certificates\n--------------------------------\n\nCertifi does not support any addition/removal or other modification of the\nCA trust store content. This project is intended to provide a reliable and\nhighly portable root of trust to python deployments. Look to upstream projects\nfor methods to use alternate trust.\n",
        "home_page": "https://github.com/certifi/python-certifi",
        "author": "Kenneth Reitz",
        "author_email": "me@kennethreitz.com",
        "license": "MPL-2.0",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "Intended Audience :: Developers",
          "License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)",
          "Natural Language :: English",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.7",
          "Programming Language :: Python :: 3.8",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14"
        ],
        "requires_python": ">=3.7",
        "project_url": [
          "Source, https://github.com/certifi/python-certifi"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/certifi-2026.1.4.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "rpds-py",
        "version": "0.30.0",
        "summary": "Python bindings to Rust's persistent data structures (rpds)",
        "description": "===========\n``rpds.py``\n===========\n\n|PyPI| |Pythons| |CI|\n\n.. |PyPI| image:: https://img.shields.io/pypi/v/rpds-py.svg\n  :alt: PyPI version\n  :target: https://pypi.org/project/rpds-py/\n\n.. |Pythons| image:: https://img.shields.io/pypi/pyversions/rpds-py.svg\n  :alt: Supported Python versions\n  :target: https://pypi.org/project/rpds-py/\n\n.. |CI| image:: https://github.com/crate-py/rpds/workflows/CI/badge.svg\n  :alt: Build status\n  :target: https://github.com/crate-py/rpds/actions?query=workflow%3ACI\n\n.. |ReadTheDocs| image:: https://readthedocs.org/projects/referencing/badge/?version=stable&style=flat\n   :alt: ReadTheDocs status\n   :target: https://referencing.readthedocs.io/en/stable/\n\n\nPython bindings to the `Rust rpds crate <https://docs.rs/rpds/>`_ for persistent data structures.\n\nWhat's here is quite minimal (in transparency, it was written initially to support replacing ``pyrsistent`` in the `referencing library <https://github.com/python-jsonschema/referencing>`_).\nIf you see something missing (which is very likely), a PR is definitely welcome to add it.\n\nInstallation\n------------\n\nThe distribution on PyPI is named ``rpds.py`` (equivalently ``rpds-py``), and thus can be installed via e.g.:\n\n.. code:: sh\n\n    $ pip install rpds-py\n\nNote that if you install ``rpds-py`` from source, you will need a Rust toolchain installed, as it is a build-time dependency.\nAn example of how to do so in a ``Dockerfile`` can be found `here <https://github.com/bowtie-json-schema/bowtie/blob/e77fd93598cb6e7dc1b8b1f53c00e5aa410c201a/implementations/python-jsonschema/Dockerfile#L1-L8>`_.\n\nIf you believe you are on a common platform which should have wheels built (i.e. and not need to compile from source), feel free to file an issue or pull request modifying the GitHub action used here to build wheels via ``maturin``.\n\nUsage\n-----\n\nMethods in general are named similarly to their ``rpds`` counterparts (rather than ``pyrsistent``\\ 's conventions, though probably a full drop-in ``pyrsistent``\\ -compatible wrapper module is a good addition at some point).\n\n.. code:: python\n\n    >>> from rpds import HashTrieMap, HashTrieSet, List\n\n    >>> m = HashTrieMap({\"foo\": \"bar\", \"baz\": \"quux\"})\n    >>> m.insert(\"spam\", 37) == HashTrieMap({\"foo\": \"bar\", \"baz\": \"quux\", \"spam\": 37})\n    True\n    >>> m.remove(\"foo\") == HashTrieMap({\"baz\": \"quux\"})\n    True\n\n    >>> s = HashTrieSet({\"foo\", \"bar\", \"baz\", \"quux\"})\n    >>> s.insert(\"spam\") == HashTrieSet({\"foo\", \"bar\", \"baz\", \"quux\", \"spam\"})\n    True\n    >>> s.remove(\"foo\") == HashTrieSet({\"bar\", \"baz\", \"quux\"})\n    True\n\n    >>> L = List([1, 3, 5])\n    >>> L.push_front(-1) == List([-1, 1, 3, 5])\n    True\n    >>> L.rest == List([3, 5])\n    True\n\n",
        "description_content_type": "text/x-rst; charset=UTF-8",
        "keywords": [
          "data structures",
          "rust",
          "persistent"
        ],
        "author_email": "Julian Berman <Julian+rpds@GrayVines.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Rust",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Documentation, https://rpds.readthedocs.io/",
          "Homepage, https://github.com/crate-py/rpds",
          "Issues, https://github.com/crate-py/rpds/issues/",
          "Funding, https://github.com/sponsors/Julian",
          "Tidelift, https://tidelift.com/subscription/pkg/pypi-rpds-py?utm_source=pypi-rpds-py&utm_medium=referral&utm_campaign=pypi-link",
          "Source, https://github.com/crate-py/rpds",
          "Upstream, https://github.com/orium/rpds"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/rpds_py-0.30.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "referencing",
        "version": "0.37.0",
        "summary": "JSON Referencing + Python",
        "description": "===============\n``referencing``\n===============\n\n|PyPI| |Pythons| |CI| |ReadTheDocs| |pre-commit|\n\n.. |PyPI| image:: https://img.shields.io/pypi/v/referencing.svg\n  :alt: PyPI version\n  :target: https://pypi.org/project/referencing/\n\n.. |Pythons| image:: https://img.shields.io/pypi/pyversions/referencing.svg\n  :alt: Supported Python versions\n  :target: https://pypi.org/project/referencing/\n\n.. |CI| image:: https://github.com/python-jsonschema/referencing/workflows/CI/badge.svg\n  :alt: Build status\n  :target: https://github.com/python-jsonschema/referencing/actions?query=workflow%3ACI\n\n.. |ReadTheDocs| image:: https://readthedocs.org/projects/referencing/badge/?version=stable&style=flat\n   :alt: ReadTheDocs status\n   :target: https://referencing.readthedocs.io/en/stable/\n\n.. |pre-commit| image:: https://results.pre-commit.ci/badge/github/python-jsonschema/referencing/main.svg\n  :alt: pre-commit.ci status\n  :target: https://results.pre-commit.ci/latest/github/python-jsonschema/referencing/main\n\n\nAn implementation-agnostic implementation of JSON reference resolution.\n\nSee `the documentation <https://referencing.readthedocs.io/>`_ for more details.\n",
        "description_content_type": "text/x-rst",
        "keywords": [
          "asyncapi",
          "json",
          "jsonschema",
          "openapi",
          "referencing"
        ],
        "author_email": "Julian Berman <Julian+referencing@GrayVines.com>",
        "license_expression": "MIT",
        "license_file": [
          "COPYING"
        ],
        "classifier": [
          "Development Status :: 3 - Alpha",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: File Formats :: JSON",
          "Topic :: File Formats :: JSON :: JSON Schema"
        ],
        "requires_dist": [
          "attrs>=22.2.0",
          "rpds-py>=0.7.0",
          "typing-extensions>=4.4.0; python_version < '3.13'"
        ],
        "requires_python": ">=3.10",
        "project_url": [
          "Documentation, https://referencing.readthedocs.io/",
          "Homepage, https://github.com/python-jsonschema/referencing",
          "Issues, https://github.com/python-jsonschema/referencing/issues/",
          "Funding, https://github.com/sponsors/Julian",
          "Tidelift, https://tidelift.com/subscription/pkg/pypi-referencing?utm_source=pypi-referencing&utm_medium=referral&utm_campaign=pypi-link",
          "Changelog, https://referencing.readthedocs.io/en/stable/changes/",
          "Source, https://github.com/python-jsonschema/referencing"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/referencing-0.37.0.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "dbt-adapters",
        "version": "1.22.5",
        "summary": "The set of adapter protocols and base functionality that supports integration with dbt-core",
        "description": "<p align=\"center\">\n    <img\n        src=\"https://raw.githubusercontent.com/dbt-labs/dbt/ec7dee39f793aa4f7dd3dae37282cc87664813e4/etc/dbt-logo-full.svg\"\n        alt=\"dbt logo\"\n        width=\"500\"\n    />\n</p>\n\n<p align=\"center\">\n    <a href=\"https://pypi.org/project/dbt-adapters/\">\n        <img src=\"https://badge.fury.io/py/dbt-adapters.svg\" />\n    </a>\n    <a target=\"_blank\" href=\"https://pypi.org/project/dbt-adapters/\" style=\"background:none\">\n        <img src=\"https://img.shields.io/pypi/pyversions/dbt-adapters\">\n    </a>\n    <a href=\"https://github.com/psf/black\">\n        <img src=\"https://img.shields.io/badge/code%20style-black-000000.svg\" />\n    </a>\n    <a href=\"https://github.com/python/mypy\">\n        <img src=\"https://www.mypy-lang.org/static/mypy_badge.svg\" />\n    </a>\n    <a href=\"https://pepy.tech/project/dbt-athena\">\n        <img src=\"https://static.pepy.tech/badge/dbt-adapters/month\" />\n    </a>\n</p>\n\n# Adapters\n\nThere are two major adapter types: [base](/dbt-adapters/src/dbt/adapters/base/impl.py) and [sql](/dbt-adapters/src/dbt/adapters/sql/impl.py).\n\n## `base`\n\n`BaseAdapter` defines the base functionality an adapter is required to implement in order to function with `dbt-core`.\nThere are several methods which have default implementations as well as methods that require the concrete adapter to implement them.\n\n## `sql`\n\n`SQLAdapter` inherits from `BaseAdapter`, updates default implementations to work with SQL-based platforms,\nand defines additional required methods to support those defaults.\n\n# Components\n\nAn adapter is composed of several components.\n\n- connections\n- dialect\n- relation caching\n- integration with `dbt-core`\n\nThe first two are platform-specific and require significant implementation in a concrete adapter.\nThe last two are largely implemented in `dbt-adapters` with minor adjustments in a concrete adapter.\n\n## Connections\n\nThis component is responsible for creating and managing connections to storage and compute.\n\n#### Files\n- `dbt/adapters/{base|sql}/connections.py`\n\n## Dialect\n\nThis component is responsible for translating a request from `dbt-core` into a specific set of actions on the platform.\n\n#### Files\n- `dbt/adapters/base/column.py`\n- `dbt/adapters/base/query_headers.py`\n- `dbt/adapters/base/relation.py`\n- `dbt/adapters/relation_configs/*`\n- `dbt/adapters/clients/jinja.py`\n- `dbt/include/global_project/*`\n\n## Relation caching\n\nThis component is responsible for managing a local cache of relations, relation metadata, and dependencies between relations.\n\n#### Files\n- `dbt/adapters/cache.py`\n\n## Integration with `dbt-core`\n\nThis component is responsible for managing the interface between `dbt-core` and a concrete adapter.\n\n#### Files\n- `dbt/adapters/{base|sql}/impl.py`\n- `dbt/adapters/base/meta.py`\n- `dbt/adapters/base/plugin.py`\n- `dbt/adapters/capability.py`\n- `dbt/adapters/factory.py`\n- `dbt/adapters/protocol.py`\n- `dbt/adapters/contracts/*`\n- `dbt/adapters/events/*`\n- `dbt/adapters/exceptions/*`\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "adapter",
          "adapters",
          "database",
          "dbt",
          "dbt Cloud",
          "dbt Core",
          "dbt Labs",
          "dbt-core",
          "elt"
        ],
        "author_email": "dbt Labs <info@dbtlabs.com>",
        "maintainer_email": "dbt Labs <info@dbtlabs.com>",
        "license_file": [
          "LICENSE"
        ],
        "classifier": [
          "Development Status :: 5 - Production/Stable",
          "License :: OSI Approved :: Apache Software License",
          "Operating System :: MacOS :: MacOS X",
          "Operating System :: Microsoft :: Windows",
          "Operating System :: POSIX :: Linux",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_dist": [
          "agate<2.0,>=1.0",
          "dbt-common<2.0,>=1.36",
          "dbt-protos<2.0,>=1.0.291",
          "mashumaro[msgpack]<3.15,>=3.9",
          "protobuf<7.0,>=6.0",
          "pytz>=2015.7",
          "typing-extensions<5.0,>=4.0"
        ],
        "requires_python": ">=3.10.0",
        "project_url": [
          "Homepage, https://github.com/dbt-labs/dbt-adapters/tree/main/dbt-adapters",
          "Documentation, https://docs.getdbt.com",
          "Repository, https://github.com/dbt-labs/dbt-adapters.git#subdirectory=dbt-adapters",
          "Issues, https://github.com/dbt-labs/dbt-adapters/issues",
          "Changelog, https://github.com/dbt-labs/dbt-adapters/blob/main/dbt-adapters/CHANGELOG.md"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/dbt_adapters-1.22.5.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.4",
        "name": "urllib3",
        "version": "2.6.3",
        "summary": "HTTP library with thread-safe connection pooling, file post, and more.",
        "description": "<h1 align=\"center\">\n\n![urllib3](https://github.com/urllib3/urllib3/raw/main/docs/_static/banner_github.svg)\n\n</h1>\n\n<p align=\"center\">\n  <a href=\"https://pypi.org/project/urllib3\"><img alt=\"PyPI Version\" src=\"https://img.shields.io/pypi/v/urllib3.svg?maxAge=86400\" /></a>\n  <a href=\"https://pypi.org/project/urllib3\"><img alt=\"Python Versions\" src=\"https://img.shields.io/pypi/pyversions/urllib3.svg?maxAge=86400\" /></a>\n  <a href=\"https://discord.gg/urllib3\"><img alt=\"Join our Discord\" src=\"https://img.shields.io/discord/756342717725933608?color=%237289da&label=discord\" /></a>\n  <a href=\"https://github.com/urllib3/urllib3/actions?query=workflow%3ACI\"><img alt=\"Coverage Status\" src=\"https://img.shields.io/badge/coverage-100%25-success\" /></a>\n  <a href=\"https://github.com/urllib3/urllib3/actions/workflows/ci.yml?query=branch%3Amain\"><img alt=\"Build Status on GitHub\" src=\"https://github.com/urllib3/urllib3/actions/workflows/ci.yml/badge.svg?branch:main&workflow:CI\" /></a>\n  <a href=\"https://urllib3.readthedocs.io\"><img alt=\"Documentation Status\" src=\"https://readthedocs.org/projects/urllib3/badge/?version=latest\" /></a><br>\n  <a href=\"https://deps.dev/pypi/urllib3\"><img alt=\"OpenSSF Scorecard\" src=\"https://api.securityscorecards.dev/projects/github.com/urllib3/urllib3/badge\" /></a>\n  <a href=\"https://slsa.dev\"><img alt=\"SLSA 3\" src=\"https://slsa.dev/images/gh-badge-level3.svg\" /></a>\n  <a href=\"https://bestpractices.coreinfrastructure.org/projects/6227\"><img alt=\"CII Best Practices\" src=\"https://bestpractices.coreinfrastructure.org/projects/6227/badge\" /></a>\n</p>\n\nurllib3 is a powerful, *user-friendly* HTTP client for Python.\nurllib3 brings many critical features that are missing from the Python\nstandard libraries:\n\n- Thread safety.\n- Connection pooling.\n- Client-side SSL/TLS verification.\n- File uploads with multipart encoding.\n- Helpers for retrying requests and dealing with HTTP redirects.\n- Support for gzip, deflate, brotli, and zstd encoding.\n- Proxy support for HTTP and SOCKS.\n- 100% test coverage.\n\n... and many more features, but most importantly: Our maintainers have a 15+\nyear track record of maintaining urllib3 with the highest code standards and\nattention to security and safety.\n\n[Much of the Python ecosystem already uses urllib3](https://urllib3.readthedocs.io/en/stable/#who-uses)\nand you should too.\n\n\n## Installing\n\nurllib3 can be installed with [pip](https://pip.pypa.io):\n\n```bash\n$ python -m pip install urllib3\n```\n\nAlternatively, you can grab the latest source code from [GitHub](https://github.com/urllib3/urllib3):\n\n```bash\n$ git clone https://github.com/urllib3/urllib3.git\n$ cd urllib3\n$ pip install .\n```\n\n## Getting Started\n\nurllib3 is easy to use:\n\n```python3\n>>> import urllib3\n>>> resp = urllib3.request(\"GET\", \"http://httpbin.org/robots.txt\")\n>>> resp.status\n200\n>>> resp.data\nb\"User-agent: *\\nDisallow: /deny\\n\"\n```\n\nurllib3 has usage and reference documentation at [urllib3.readthedocs.io](https://urllib3.readthedocs.io).\n\n\n## Community\n\nurllib3 has a [community Discord channel](https://discord.gg/urllib3) for asking questions and\ncollaborating with other contributors. Drop by and say hello ðŸ‘‹\n\n\n## Contributing\n\nurllib3 happily accepts contributions. Please see our\n[contributing documentation](https://urllib3.readthedocs.io/en/latest/contributing.html)\nfor some tips on getting started.\n\n\n## Security Disclosures\n\nTo report a security vulnerability, please use the\n[Tidelift security contact](https://tidelift.com/security).\nTidelift will coordinate the fix and disclosure with maintainers.\n\n\n## Maintainers\n\nMeet our maintainers since 2008:\n\n- Current Lead: [@illia-v](https://github.com/illia-v) (Illia Volochii)\n- [@sethmlarson](https://github.com/sethmlarson) (Seth M. Larson)\n- [@pquentin](https://github.com/pquentin) (Quentin Pradet)\n- [@theacodes](https://github.com/theacodes) (Thea Flowers)\n- [@haikuginger](https://github.com/haikuginger) (Jess Shapiro)\n- [@lukasa](https://github.com/lukasa) (Cory Benfield)\n- [@sigmavirus24](https://github.com/sigmavirus24) (Ian Stapleton Cordasco)\n- [@shazow](https://github.com/shazow) (Andrey Petrov)\n\nðŸ‘‹\n\n\n## Sponsorship\n\nIf your company benefits from this library, please consider [sponsoring its\ndevelopment](https://urllib3.readthedocs.io/en/latest/sponsors.html).\n\n\n## For Enterprise\n\nProfessional support for urllib3 is available as part of the [Tidelift\nSubscription][1]. Tidelift gives software development teams a single source for\npurchasing and maintaining their software, with professional grade assurances\nfrom the experts who know it best, while seamlessly integrating with existing\ntools.\n\n[1]: https://tidelift.com/subscription/pkg/pypi-urllib3?utm_source=pypi-urllib3&utm_medium=referral&utm_campaign=readme\n",
        "description_content_type": "text/markdown",
        "keywords": [
          "filepost",
          "http",
          "httplib",
          "https",
          "pooling",
          "ssl",
          "threadsafe",
          "urllib"
        ],
        "author_email": "Andrey Petrov <andrey.petrov@shazow.net>",
        "maintainer_email": "Seth Michael Larson <sethmichaellarson@gmail.com>, Quentin Pradet <quentin@pradet.me>, Illia Volochii <illia.volochii@gmail.com>",
        "license_expression": "MIT",
        "license_file": [
          "LICENSE.txt"
        ],
        "classifier": [
          "Environment :: Web Environment",
          "Intended Audience :: Developers",
          "Operating System :: OS Independent",
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3 :: Only",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13",
          "Programming Language :: Python :: 3.14",
          "Programming Language :: Python :: Free Threading :: 2 - Beta",
          "Programming Language :: Python :: Implementation :: CPython",
          "Programming Language :: Python :: Implementation :: PyPy",
          "Topic :: Internet :: WWW/HTTP",
          "Topic :: Software Development :: Libraries"
        ],
        "requires_dist": [
          "brotli>=1.2.0; (platform_python_implementation == 'CPython') and extra == 'brotli'",
          "brotlicffi>=1.2.0.0; (platform_python_implementation != 'CPython') and extra == 'brotli'",
          "h2<5,>=4; extra == 'h2'",
          "pysocks!=1.5.7,<2.0,>=1.5.6; extra == 'socks'",
          "backports-zstd>=1.0.0; (python_version < '3.14') and extra == 'zstd'"
        ],
        "requires_python": ">=3.9",
        "project_url": [
          "Changelog, https://github.com/urllib3/urllib3/blob/main/CHANGES.rst",
          "Documentation, https://urllib3.readthedocs.io",
          "Code, https://github.com/urllib3/urllib3",
          "Issue tracker, https://github.com/urllib3/urllib3/issues"
        ],
        "provides_extra": [
          "brotli",
          "h2",
          "socks",
          "zstd"
        ]
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/urllib3-2.6.3.dist-info",
      "installer": "pip",
      "requested": false
    },
    {
      "metadata": {
        "metadata_version": "2.1",
        "name": "protobuf",
        "version": "6.33.4",
        "description": "UNKNOWN\n",
        "home_page": "https://developers.google.com/protocol-buffers/",
        "author": "protobuf@googlegroups.com",
        "author_email": "protobuf@googlegroups.com",
        "license": "3-Clause BSD License",
        "classifier": [
          "Programming Language :: Python",
          "Programming Language :: Python :: 3",
          "Programming Language :: Python :: 3.9",
          "Programming Language :: Python :: 3.10",
          "Programming Language :: Python :: 3.11",
          "Programming Language :: Python :: 3.12",
          "Programming Language :: Python :: 3.13"
        ],
        "requires_python": ">=3.9"
      },
      "metadata_location": "/home/jules/.pyenv/versions/3.12.12/lib/python3.12/site-packages/protobuf-6.33.4.dist-info",
      "installer": "pip",
      "requested": false
    }
  ],
  "environment": {
    "implementation_name": "cpython",
    "implementation_version": "3.12.12",
    "os_name": "posix",
    "platform_machine": "x86_64",
    "platform_release": "6.8.0",
    "platform_system": "Linux",
    "platform_version": "#1 SMP PREEMPT_DYNAMIC Fri Oct 31 08:51:12 UTC 2025",
    "python_full_version": "3.12.12",
    "platform_python_implementation": "CPython",
    "python_version": "3.12",
    "sys_platform": "linux"
  }
}
