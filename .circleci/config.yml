version: 2.1

jobs:
  download_population:
    docker:
      - image: cimg/python:3.13
    steps:
      - checkout
      # Install rclone via curl
      - run:
          name: Install rclone
          command: |
            curl https://rclone.org/install.sh | sudo bash
      # Restore pip cache
      - restore_cache:
          keys:
            - pip-cache-{{ checksum "requirements.txt" }}
      # Install pip modules from requirements.txt
      - run:
          name: Install pip modules
          command: pip install -r requirements.txt
      # Save pip cache for subsequent builds
      - save_cache:
          paths:
            - ~/.cache/pip
          key: pip-cache-{{ checksum "requirements.txt" }}
      # Run the population download script
      - run:
          name: Download Population Data
          command: python download_population.py

  download_wdi:
    docker:
      - image: cimg/python:3.13
    steps:
      - checkout
      # Install rclone
      - run:
          name: Install rclone
          command: |
            curl https://rclone.org/install.sh | sudo bash
      # Restore pip cache
      - restore_cache:
          keys:
            - pip-cache-{{ checksum "requirements.txt" }}
      # Install pip modules
      - run:
          name: Install pip modules
          command: pip install -r requirements.txt
      # Save pip cache
      - save_cache:
          paths:
            - ~/.cache/pip
          key: pip-cache-{{ checksum "requirements.txt" }}
      # Run the WDI download script
      - run:
          name: Download WDI Data
          command: python download_wdi.py

  transform_and_load:
    docker:
      - image: cimg/python:3.13
    steps:
      - checkout

      # Install rclone (if needed by your scripts)
      - run:
          name: Install rclone
          command: |
            curl https://rclone.org/install.sh | sudo bash

      # Restore pip cache
      - restore_cache:
          keys:
            - pip-cache-{{ checksum "requirements.txt" }}
      - run:
          name: Install pip modules
          command: pip install -r requirements.txt
      - save_cache:
          paths:
            - ~/.cache/pip
          key: pip-cache-{{ checksum "requirements.txt" }}
      # Run the populate script (which reads from Cloudflare R2)
      - run:
          name: Populate Databases
          command: python populate.py --use-duckdb
      # Run dbt deps inside the wdi directory
      - run:
          name: Run dbt deps
          command: |
            pushd wdi
            dbt deps
            popd
      # Run dbt run inside the wdi directory
      - run:
          name: Run dbt run
          command: |
            pushd wdi
            dbt run --target prod
            popd
      # Generate dbt docs inside the wdi directory
      - run:
          name: Generate dbt docs
          command: |
            pushd wdi
            dbt docs generate --target prod --static
            popd
      # Upload the generated static_index.html to R2 docs folder
      - run:
          name: Upload dbt docs static index to R2
          command: rclone copy wdi/target/static_index.html r2:wdi/docs --checksum
      # Install sqlite3 so that the sqlite3 command is available for export
      - run:
          name: Install sqlite3
          command: sudo apt-get update && sudo apt-get install -y sqlite3
      # Install latest Node.js (LTS)
      - run:
          name: Install latest Node.js
          command: |
            curl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash -
            sudo apt-get install -y nodejs
      # Step 1: Export DuckDB marts tables as Parquet files
      - run:
          name: Export mart tables to Parquet
          command: |
            python export_parquet.py exported_files.json
      # Step 2: Determine changes and sync remote Parquet files
      - run:
          name: Sync changed Parquet files to R2
          command: |
            python sync_remote_parquet.py exported_files.json changed_tables.json
      # Step 3: Update D1 using changed tables (if any)
      - run:
          name: Update D1 tables
          command: |
            if [ -s changed_tables.json ]; then
              python update_d1.py changed_tables.json --remote
            else
              echo "No changes detected; skipping D1 update."
            fi

workflows:
  download_transform_load:
    jobs:
      - download_population
      - download_wdi
      - transform_and_load:
          requires:
            - download_population
            - download_wdi