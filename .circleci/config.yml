version: 2.1

jobs:
  download_population:
    docker:
      - image: cimg/python:3.13
    steps:
      - checkout
      # Install rclone via curl
      - run:
          name: Install rclone
          command: |
            curl https://rclone.org/install.sh | sudo bash
      # Restore pip cache
      - restore_cache:
          keys:
            - pip-cache-{{ checksum "requirements.txt" }}
      # Install pip modules from requirements.txt
      - run:
          name: Install pip modules
          command: pip install -r requirements.txt
      # Save pip cache for subsequent builds
      - save_cache:
          paths:
            - ~/.cache/pip
          key: pip-cache-{{ checksum "requirements.txt" }}
      # Run the population download script
      - run:
          name: Download Population Data
          command: python download_population.py

  download_wdi:
    docker:
      - image: cimg/python:3.13
    steps:
      - checkout
      # Install rclone
      - run:
          name: Install rclone
          command: |
            curl https://rclone.org/install.sh | sudo bash
      # Restore pip cache
      - restore_cache:
          keys:
            - pip-cache-{{ checksum "requirements.txt" }}
      # Install pip modules
      - run:
          name: Install pip modules
          command: pip install -r requirements.txt
      # Save pip cache
      - save_cache:
          paths:
            - ~/.cache/pip
          key: pip-cache-{{ checksum "requirements.txt" }}
      # Run the WDI download script
      - run:
          name: Download WDI Data
          command: python download_wdi.py

  transform_and_load:
    docker:
      - image: cimg/python:3.13
    steps:
      - checkout

      # Install rclone (if needed by your scripts)
      - run:
          name: Install rclone
          command: |
            curl https://rclone.org/install.sh | sudo bash

      # Restore pip cache
      - restore_cache:
          keys:
            - pip-cache-{{ checksum "requirements.txt" }}
      # Install pip modules
      - run:
          name: Install pip modules
          command: pip install -r requirements.txt
      # Save pip cache
      - save_cache:
          paths:
            - ~/.cache/pip
          key: pip-cache-{{ checksum "requirements.txt" }}

      # Run the populate script (which reads from Cloudflare R2)
      - run:
          name: Populate Databases
          command: python populate.py --use-duckdb

      # Run dbt deps inside the wdi directory
      - run:
          name: Run dbt deps
          command: |
            pushd wdi
            dbt deps
            popd

      # Run dbt run inside the wdi directory
      - run:
          name: Run dbt run
          command: |
            pushd wdi
            dbt run --target prod
            popd

      # Generate dbt docs inside the wdi directory
      - run:
          name: Generate dbt docs
          command: |
            pushd wdi
            dbt docs generate --target prod --static
            popd

      # Upload the generated static_index.html to R2 docs folder
      - run:
          name: Upload dbt docs static index to R2
          command: rclone copy wdi/target/static_index.html r2:wdi/docs --checksum

      # Install sqlite3 so that the sqlite3 command is available for export
      - run:
          name: Install sqlite3
          command: sudo apt-get update && sudo apt-get install -y sqlite3

      # Install latest Node.js (LTS)
      - run:
          name: Install latest Node.js
          command: |
            curl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash -
            sudo apt-get install -y nodejs

      # Run the DuckDB to SQLite export script
      - run:
          name: Export DuckDB to R2 and D1
          command: python duckdbexport.py --remote-d1


workflows:
  download_transform_load:
    jobs:
      - download_population
      - download_wdi
      - transform_and_load:
          requires:
            - download_population
            - download_wdi